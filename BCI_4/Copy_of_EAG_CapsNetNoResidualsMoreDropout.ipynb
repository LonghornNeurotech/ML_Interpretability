{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup**"
      ],
      "metadata": {
        "id": "IsVDgYMUrr4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "vr5CuOneq05Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nz2dMawDvfr2"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "import torch\n",
        "import scipy\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader as DL\n",
        "from torch.utils.data import TensorDataset as TData\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import scipy\n",
        "from torch.utils.data import TensorDataset as TData\n",
        "from torch.utils.data import DataLoader as DL\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "V096vAkB5XTG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "8-R-VT9HdCP9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run model, first make a new folder in the files tab to the left, naming it EEGData. Running the following code will process the data and set up the train and test dataloaders for you"
      ],
      "metadata": {
        "id": "sJNaP1Wbq4_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Use np.load to read the .npy file\n",
        "dataset = pd.read_csv(\"BCICIV_2a_all_patients.csv\") # loading in the csv dataset with pandas\n",
        "# If you want to convert it to a pandas DataFrame, you can do this:\n"
      ],
      "metadata": {
        "id": "tl1zwbM2c10B",
        "collapsed": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checks if cuda is available, then sets device to GPU\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "device # should say cuda if gpu is enabled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gomsnNGx5qbT",
        "outputId": "0f7e28ab-cfdd-45c7-ef47-ad8f07cf563f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8JAry-C6XsH",
        "outputId": "167e10d1-3fa7-4e78-e040-d74654948cdf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        patient   time   label  epoch    EEG-Fz     EEG-0     EEG-1     EEG-2  \\\n",
            "0             1 -0.100  tongue      8 -1.681412  2.245496 -0.158350  1.163765   \n",
            "1             1 -0.096  tongue      8  0.420417  0.587559  1.650510  0.970672   \n",
            "2             1 -0.092  tongue      8  0.551365  1.499758  0.121302  2.859433   \n",
            "3             1 -0.088  tongue      8  3.054916 -1.807238  1.843603  2.286812   \n",
            "4             1 -0.084  tongue      8  2.506710 -2.453101  0.221178  0.127278   \n",
            "...         ...    ...     ...    ...       ...       ...       ...       ...   \n",
            "492043        9  0.684    foot    638  7.375522  4.646781  3.071135  4.665561   \n",
            "492044        9  0.688    foot    638  7.268988  1.952357  5.503664  3.484809   \n",
            "492045        9  0.692    foot    638  4.581222  3.463809  4.427226  4.752120   \n",
            "492046        9  0.696    foot    638  3.504784  4.096355  2.960162  3.187401   \n",
            "492047        9  0.700    foot    638  3.751144  0.436465  0.765116  0.064620   \n",
            "\n",
            "           EEG-3     EEG-4  ...     EEG-8     EEG-9    EEG-10    EEG-11  \\\n",
            "0      -1.523659 -0.575267  ...  0.758116  3.441785  0.305517  1.137473   \n",
            "1       1.505904  0.891796  ...  1.541586 -0.071620  0.258909 -1.448198   \n",
            "2       2.613414  4.636026  ...  2.649097 -2.137938 -1.612096 -1.610218   \n",
            "3       5.995872  6.651295  ...  6.031554 -5.249621 -2.672998 -3.452370   \n",
            "4       4.519931  6.249573  ...  7.827097 -5.309546 -2.488783 -3.707608   \n",
            "...          ...       ...  ...       ...       ...       ...       ...   \n",
            "492043  1.087962  0.932088  ... -2.314982  2.922773 -3.176987 -4.865313   \n",
            "492044  3.227522 -2.738899  ... -2.665657  4.085770 -0.500318 -5.655441   \n",
            "492045  1.906943 -2.496978  ... -5.206939  6.915582 -1.088475 -4.534613   \n",
            "492046  2.148864 -3.182791  ... -5.306815  6.620394 -1.286006 -5.806364   \n",
            "492047  1.223349 -3.473541  ... -4.718658  5.304254 -0.600193 -8.099066   \n",
            "\n",
            "          EEG-12    EEG-13    EEG-14    EEG-Pz    EEG-15    EEG-16  \n",
            "0      -1.275763 -2.898359  0.656704 -2.010063 -1.613804 -1.942455  \n",
            "1       0.142472 -1.968405 -1.733655 -2.935578 -3.125256 -4.674610  \n",
            "2      -0.410173 -0.274957 -4.776535 -5.099551 -2.798995 -5.862021  \n",
            "3       0.189081  1.593829 -6.081577 -5.476860 -2.932163 -6.874095  \n",
            "4       1.447515  4.268278 -4.383690 -4.218426 -1.331932 -5.322692  \n",
            "...          ...       ...       ...       ...       ...       ...  \n",
            "492043 -1.569414  3.600733 -1.113059 -4.249327 -1.402272 -6.307621  \n",
            "492044 -1.871261  2.517636 -1.805531 -4.453518 -1.801775 -5.974702  \n",
            "492045 -3.094184  1.148229 -2.247203 -4.895190 -1.803994 -5.879265  \n",
            "492046 -2.705778  2.269057 -0.540439 -3.530222 -0.194886 -1.486953  \n",
            "492047 -0.994574  4.468542  4.002797 -0.256518  3.420615  3.837532  \n",
            "\n",
            "[492048 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(columns=['EEG-Fz','EEG-2', 'EEG-14', 'EEG-Pz', 'EEG-15', 'EEG-16'])\n",
        "\n",
        "\n",
        "new_order = ['patient', 'time', 'label', 'epoch', 'EEG-5', 'EEG-0', 'EEG-C3', 'EEG-9',\n",
        "       'EEG-10', 'EEG-6', 'EEG-1', 'EEG-Cz', 'EEG-11', 'EEG-12',\n",
        "      'EEG-7', 'EEG-3', 'EEG-4', 'EEG-C4', 'EEG-13', 'EEG-8']\n",
        "dataset = dataset[new_order]\n",
        "\n",
        "dataset.head() # first five rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "RrvCzfED5uHM",
        "outputId": "643fd9b7-0e8d-4def-aec9-1709732372f5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   patient   time   label  epoch     EEG-5     EEG-0    EEG-C3     EEG-9  \\\n",
              "0        1 -0.100  tongue      8  3.299057  2.245496  3.928189  3.441785   \n",
              "1        1 -0.096  tongue      8  3.838386  0.587559  2.514392 -0.071620   \n",
              "2        1 -0.092  tongue      8  2.162693  1.499758  1.522294 -2.137938   \n",
              "3        1 -0.088  tongue      8  2.078354 -1.807238 -1.980015 -5.249621   \n",
              "4        1 -0.084  tongue      8  0.309444 -2.453101 -3.358299 -5.309546   \n",
              "\n",
              "     EEG-10     EEG-6     EEG-1    EEG-Cz    EEG-11    EEG-12     EEG-7  \\\n",
              "0  0.305517  0.673606 -0.158350  0.972209  1.137473 -1.275763 -2.340592   \n",
              "1  0.258909  1.798873  1.650510  1.316225 -1.448198  0.142472  0.347175   \n",
              "2 -1.612096 -0.072132  0.121302  0.861236 -1.610218 -0.410173  2.577732   \n",
              "3 -2.672998  0.136497  1.843603 -1.029744 -3.452370  0.189081  4.446518   \n",
              "4 -2.488783 -2.023038  0.221178 -2.163888 -3.707608  1.447515  4.337764   \n",
              "\n",
              "      EEG-3     EEG-4    EEG-C4    EEG-13     EEG-8  \n",
              "0 -1.523659 -0.575267 -2.562196 -2.898359  0.758116  \n",
              "1  1.505904  0.891796 -1.827555 -1.968405  1.541586  \n",
              "2  2.613414  4.636026  2.600268 -0.274957  2.649097  \n",
              "3  5.995872  6.651295  3.248351  1.593829  6.031554  \n",
              "4  4.519931  6.249573  4.946238  4.268278  7.827097  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d7b0237-3e33-4966-bae0-a746c30c7ca4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient</th>\n",
              "      <th>time</th>\n",
              "      <th>label</th>\n",
              "      <th>epoch</th>\n",
              "      <th>EEG-5</th>\n",
              "      <th>EEG-0</th>\n",
              "      <th>EEG-C3</th>\n",
              "      <th>EEG-9</th>\n",
              "      <th>EEG-10</th>\n",
              "      <th>EEG-6</th>\n",
              "      <th>EEG-1</th>\n",
              "      <th>EEG-Cz</th>\n",
              "      <th>EEG-11</th>\n",
              "      <th>EEG-12</th>\n",
              "      <th>EEG-7</th>\n",
              "      <th>EEG-3</th>\n",
              "      <th>EEG-4</th>\n",
              "      <th>EEG-C4</th>\n",
              "      <th>EEG-13</th>\n",
              "      <th>EEG-8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.100</td>\n",
              "      <td>tongue</td>\n",
              "      <td>8</td>\n",
              "      <td>3.299057</td>\n",
              "      <td>2.245496</td>\n",
              "      <td>3.928189</td>\n",
              "      <td>3.441785</td>\n",
              "      <td>0.305517</td>\n",
              "      <td>0.673606</td>\n",
              "      <td>-0.158350</td>\n",
              "      <td>0.972209</td>\n",
              "      <td>1.137473</td>\n",
              "      <td>-1.275763</td>\n",
              "      <td>-2.340592</td>\n",
              "      <td>-1.523659</td>\n",
              "      <td>-0.575267</td>\n",
              "      <td>-2.562196</td>\n",
              "      <td>-2.898359</td>\n",
              "      <td>0.758116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.096</td>\n",
              "      <td>tongue</td>\n",
              "      <td>8</td>\n",
              "      <td>3.838386</td>\n",
              "      <td>0.587559</td>\n",
              "      <td>2.514392</td>\n",
              "      <td>-0.071620</td>\n",
              "      <td>0.258909</td>\n",
              "      <td>1.798873</td>\n",
              "      <td>1.650510</td>\n",
              "      <td>1.316225</td>\n",
              "      <td>-1.448198</td>\n",
              "      <td>0.142472</td>\n",
              "      <td>0.347175</td>\n",
              "      <td>1.505904</td>\n",
              "      <td>0.891796</td>\n",
              "      <td>-1.827555</td>\n",
              "      <td>-1.968405</td>\n",
              "      <td>1.541586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.092</td>\n",
              "      <td>tongue</td>\n",
              "      <td>8</td>\n",
              "      <td>2.162693</td>\n",
              "      <td>1.499758</td>\n",
              "      <td>1.522294</td>\n",
              "      <td>-2.137938</td>\n",
              "      <td>-1.612096</td>\n",
              "      <td>-0.072132</td>\n",
              "      <td>0.121302</td>\n",
              "      <td>0.861236</td>\n",
              "      <td>-1.610218</td>\n",
              "      <td>-0.410173</td>\n",
              "      <td>2.577732</td>\n",
              "      <td>2.613414</td>\n",
              "      <td>4.636026</td>\n",
              "      <td>2.600268</td>\n",
              "      <td>-0.274957</td>\n",
              "      <td>2.649097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.088</td>\n",
              "      <td>tongue</td>\n",
              "      <td>8</td>\n",
              "      <td>2.078354</td>\n",
              "      <td>-1.807238</td>\n",
              "      <td>-1.980015</td>\n",
              "      <td>-5.249621</td>\n",
              "      <td>-2.672998</td>\n",
              "      <td>0.136497</td>\n",
              "      <td>1.843603</td>\n",
              "      <td>-1.029744</td>\n",
              "      <td>-3.452370</td>\n",
              "      <td>0.189081</td>\n",
              "      <td>4.446518</td>\n",
              "      <td>5.995872</td>\n",
              "      <td>6.651295</td>\n",
              "      <td>3.248351</td>\n",
              "      <td>1.593829</td>\n",
              "      <td>6.031554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.084</td>\n",
              "      <td>tongue</td>\n",
              "      <td>8</td>\n",
              "      <td>0.309444</td>\n",
              "      <td>-2.453101</td>\n",
              "      <td>-3.358299</td>\n",
              "      <td>-5.309546</td>\n",
              "      <td>-2.488783</td>\n",
              "      <td>-2.023038</td>\n",
              "      <td>0.221178</td>\n",
              "      <td>-2.163888</td>\n",
              "      <td>-3.707608</td>\n",
              "      <td>1.447515</td>\n",
              "      <td>4.337764</td>\n",
              "      <td>4.519931</td>\n",
              "      <td>6.249573</td>\n",
              "      <td>4.946238</td>\n",
              "      <td>4.268278</td>\n",
              "      <td>7.827097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d7b0237-3e33-4966-bae0-a746c30c7ca4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d7b0237-3e33-4966-bae0-a746c30c7ca4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d7b0237-3e33-4966-bae0-a746c30c7ca4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5c808f5f-2f86-40f7-bb75-e5759d7110d9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c808f5f-2f86-40f7-bb75-e5759d7110d9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5c808f5f-2f86-40f7-bb75-e5759d7110d9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list of columns\n",
        "print(dataset.columns, end='\\n\\n') # 12 eeg channels\n",
        "\n",
        "# unique labels\n",
        "print(dataset['label'].unique()) # 4 classes\n",
        "\n",
        "# number of patients\n",
        "print(dataset.patient.unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU16psO58L-_",
        "outputId": "76fe00c8-f087-495b-cdb0-e36af412e588"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['patient', 'time', 'label', 'epoch', 'EEG-5', 'EEG-0', 'EEG-C3',\n",
            "       'EEG-9', 'EEG-10', 'EEG-6', 'EEG-1', 'EEG-Cz', 'EEG-11', 'EEG-12',\n",
            "       'EEG-7', 'EEG-3', 'EEG-4', 'EEG-C4', 'EEG-13', 'EEG-8'],\n",
            "      dtype='object')\n",
            "\n",
            "['tongue' 'foot' 'right' 'left']\n",
            "[1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# only interested in rows where target is left or right hand in this tutorial for simplicity\n",
        "binary_mi = dataset.loc[(dataset['label'] == 'left') | (dataset['label'] == 'right')]\n",
        "binary_mi.label.unique() # check that our row filter worked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6pGdOn98P6f",
        "outputId": "527bfb9c-51b2-410a-f363-0a503e78977f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['right', 'left'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get time period and check that it is constant throughout dataframe\n",
        "t0 = binary_mi.time.iloc[:-1] # get time points except last one\n",
        "t1 = binary_mi.time.iloc[1:] # series offest by one, so starting at 2nd time point until last\n",
        "t0.reset_index(drop=True, inplace=True)\n",
        "t1.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(t0 - t1) # subtracting the two series to get time differences between adjacent time points\n",
        "const_diff = ((t0 - t1 < -0.0039) & (t0 - t1 > -0.0041)) # checking that they are all around -0.004\n",
        "const_diff[const_diff != True] # getting just the rows where time difference wasn't around -0.004"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "HxzCw7uA8Snp",
        "outputId": "523e5b52-9506-4dce-8e02-8172bc7dcee8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        -0.004\n",
            "1        -0.004\n",
            "2        -0.004\n",
            "3        -0.004\n",
            "4        -0.004\n",
            "          ...  \n",
            "260490   -0.004\n",
            "260491   -0.004\n",
            "260492   -0.004\n",
            "260493   -0.004\n",
            "260494   -0.004\n",
            "Name: time, Length: 260495, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200       False\n",
              "401       False\n",
              "602       False\n",
              "803       False\n",
              "1004      False\n",
              "          ...  \n",
              "259490    False\n",
              "259691    False\n",
              "259892    False\n",
              "260093    False\n",
              "260294    False\n",
              "Name: time, Length: 1295, dtype: bool"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259490</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259691</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259892</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260093</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260294</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1295 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> bool</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((t0 - t1)[200])\n",
        "binary_mi.iloc[200:, 2] # time discrepancy seems to be caused by label change"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "uZi9ylW28WH6",
        "outputId": "531b9419-9a39-40e2-f721-a474d34f0de1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7999999999999999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "602       right\n",
              "603        left\n",
              "604        left\n",
              "605        left\n",
              "606        left\n",
              "          ...  \n",
              "491842    right\n",
              "491843    right\n",
              "491844    right\n",
              "491845    right\n",
              "491846    right\n",
              "Name: label, Length: 260296, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603</th>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>605</th>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606</th>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491842</th>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491843</th>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491844</th>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491845</th>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491846</th>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>260296 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# don't care about time and epoch anymore\n",
        "pruned_mi = binary_mi.drop(columns = ['time', 'epoch'])\n",
        "pruned_mi.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Q0acmaE-8iwf",
        "outputId": "f9b69023-4540-40fc-832f-6714ff9ee681"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     patient  label     EEG-5     EEG-0    EEG-C3     EEG-9    EEG-10  \\\n",
              "402        1  right -4.727450 -7.846816 -4.680500 -0.901954  1.939467   \n",
              "403        1  right -2.241655 -7.314146 -3.757205 -0.027487  3.302215   \n",
              "404        1  right  1.904297 -3.558819 -0.587816  2.311824  3.004808   \n",
              "405        1  right  3.970614 -1.199533  2.943346  3.645720  3.508625   \n",
              "406        1  right  6.372070 -0.604718  4.417067  4.826472  5.031175   \n",
              "\n",
              "        EEG-6     EEG-1    EEG-Cz    EEG-11    EEG-12     EEG-7     EEG-3  \\\n",
              "402 -1.142339 -6.412021  3.699157  2.611793  3.706669  3.794936  0.023902   \n",
              "403  1.196972 -3.828569  0.960343  1.923760  2.139730  3.546356  0.312432   \n",
              "404  1.876127 -2.026367 -0.215971 -0.277945  0.523963  0.758714 -1.010367   \n",
              "405  2.379944 -1.473722 -0.298091  0.274701 -1.169485 -1.423015 -1.873737   \n",
              "406  3.756010 -0.585937 -0.777494 -0.155874 -1.648888 -1.560622 -2.353140   \n",
              "\n",
              "        EEG-4    EEG-C4    EEG-13     EEG-8  \n",
              "402  1.723496  4.052222  3.466285  3.113220  \n",
              "403 -0.771177  1.362236  2.143486  3.987687  \n",
              "404 -2.435772 -1.523062 -0.155874  4.032076  \n",
              "405 -2.078439 -3.655963 -2.972369  1.069097  \n",
              "406 -4.169171 -5.160757 -4.672476 -1.754056  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-452f08e5-6082-487b-b34e-3ba491f48763\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient</th>\n",
              "      <th>label</th>\n",
              "      <th>EEG-5</th>\n",
              "      <th>EEG-0</th>\n",
              "      <th>EEG-C3</th>\n",
              "      <th>EEG-9</th>\n",
              "      <th>EEG-10</th>\n",
              "      <th>EEG-6</th>\n",
              "      <th>EEG-1</th>\n",
              "      <th>EEG-Cz</th>\n",
              "      <th>EEG-11</th>\n",
              "      <th>EEG-12</th>\n",
              "      <th>EEG-7</th>\n",
              "      <th>EEG-3</th>\n",
              "      <th>EEG-4</th>\n",
              "      <th>EEG-C4</th>\n",
              "      <th>EEG-13</th>\n",
              "      <th>EEG-8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>1</td>\n",
              "      <td>right</td>\n",
              "      <td>-4.727450</td>\n",
              "      <td>-7.846816</td>\n",
              "      <td>-4.680500</td>\n",
              "      <td>-0.901954</td>\n",
              "      <td>1.939467</td>\n",
              "      <td>-1.142339</td>\n",
              "      <td>-6.412021</td>\n",
              "      <td>3.699157</td>\n",
              "      <td>2.611793</td>\n",
              "      <td>3.706669</td>\n",
              "      <td>3.794936</td>\n",
              "      <td>0.023902</td>\n",
              "      <td>1.723496</td>\n",
              "      <td>4.052222</td>\n",
              "      <td>3.466285</td>\n",
              "      <td>3.113220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>1</td>\n",
              "      <td>right</td>\n",
              "      <td>-2.241655</td>\n",
              "      <td>-7.314146</td>\n",
              "      <td>-3.757205</td>\n",
              "      <td>-0.027487</td>\n",
              "      <td>3.302215</td>\n",
              "      <td>1.196972</td>\n",
              "      <td>-3.828569</td>\n",
              "      <td>0.960343</td>\n",
              "      <td>1.923760</td>\n",
              "      <td>2.139730</td>\n",
              "      <td>3.546356</td>\n",
              "      <td>0.312432</td>\n",
              "      <td>-0.771177</td>\n",
              "      <td>1.362236</td>\n",
              "      <td>2.143486</td>\n",
              "      <td>3.987687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>1</td>\n",
              "      <td>right</td>\n",
              "      <td>1.904297</td>\n",
              "      <td>-3.558819</td>\n",
              "      <td>-0.587816</td>\n",
              "      <td>2.311824</td>\n",
              "      <td>3.004808</td>\n",
              "      <td>1.876127</td>\n",
              "      <td>-2.026367</td>\n",
              "      <td>-0.215971</td>\n",
              "      <td>-0.277945</td>\n",
              "      <td>0.523963</td>\n",
              "      <td>0.758714</td>\n",
              "      <td>-1.010367</td>\n",
              "      <td>-2.435772</td>\n",
              "      <td>-1.523062</td>\n",
              "      <td>-0.155874</td>\n",
              "      <td>4.032076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>1</td>\n",
              "      <td>right</td>\n",
              "      <td>3.970614</td>\n",
              "      <td>-1.199533</td>\n",
              "      <td>2.943346</td>\n",
              "      <td>3.645720</td>\n",
              "      <td>3.508625</td>\n",
              "      <td>2.379944</td>\n",
              "      <td>-1.473722</td>\n",
              "      <td>-0.298091</td>\n",
              "      <td>0.274701</td>\n",
              "      <td>-1.169485</td>\n",
              "      <td>-1.423015</td>\n",
              "      <td>-1.873737</td>\n",
              "      <td>-2.078439</td>\n",
              "      <td>-3.655963</td>\n",
              "      <td>-2.972369</td>\n",
              "      <td>1.069097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>1</td>\n",
              "      <td>right</td>\n",
              "      <td>6.372070</td>\n",
              "      <td>-0.604718</td>\n",
              "      <td>4.417067</td>\n",
              "      <td>4.826472</td>\n",
              "      <td>5.031175</td>\n",
              "      <td>3.756010</td>\n",
              "      <td>-0.585937</td>\n",
              "      <td>-0.777494</td>\n",
              "      <td>-0.155874</td>\n",
              "      <td>-1.648888</td>\n",
              "      <td>-1.560622</td>\n",
              "      <td>-2.353140</td>\n",
              "      <td>-4.169171</td>\n",
              "      <td>-5.160757</td>\n",
              "      <td>-4.672476</td>\n",
              "      <td>-1.754056</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-452f08e5-6082-487b-b34e-3ba491f48763')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-452f08e5-6082-487b-b34e-3ba491f48763 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-452f08e5-6082-487b-b34e-3ba491f48763');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7588199d-722f-4764-8aac-f7814b875ad6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7588199d-722f-4764-8aac-f7814b875ad6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7588199d-722f-4764-8aac-f7814b875ad6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pruned_mi"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get unique patients and labels\n",
        "patients = binary_mi.patient.unique() # 1-9\n",
        "labels = binary_mi.label.unique()     # left and right"
      ],
      "metadata": {
        "id": "3f6cWKDY8mPW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "left_hand = []\n",
        "right_hand = []\n",
        "\n",
        "# for each patient, get patient readings, convert to numpy array, and add\n",
        "# to list corresponding to target (left or right)\n",
        "for patient in patients:\n",
        "  left_df = pruned_mi[(pruned_mi['patient'] == patient) & (pruned_mi['label'] == 'left')]\n",
        "  right_df = pruned_mi[(pruned_mi['patient'] == patient) & (pruned_mi['label'] == 'right')]\n",
        "\n",
        "  left_hand.append(left_df.iloc[:, 2:].to_numpy().T)\n",
        "  right_hand.append(right_df.iloc[:, 2:].to_numpy().T)\n",
        "\n",
        "right_hand[0].shape # shows shape of each list element"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOV7HVqR8ouz",
        "outputId": "7a071654-3b1c-4b04-ac61-aa6206397a6b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 14472)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(right_hand[0][0]) # visualizing first channel of first patient thinking of right hand motion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "JvlkzU-x8xfb",
        "outputId": "91ca71b1-1083-406c-acf1-9f4185e41cf8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x79babc317b90>]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGdCAYAAAA8F1jjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAb55JREFUeJzt3Xd4FNX6B/DvpieQAqQRSEjoHUKLoUnJpYjdnwVRQLFjQRAVCyqKYMN2uahXATuWC6iI9I6hE3oVQkJJqEkIJXV+f0CW3c3M7vRzZvf9PE+eB3ZnZ8/MTnnnlPfYBEEQQAghhBDCIT/WBSCEEEIIkUKBCiGEEEK4RYEKIYQQQrhFgQohhBBCuEWBCiGEEEK4RYEKIYQQQrhFgQohhBBCuEWBCiGEEEK4FcC6AFpVVlbi+PHjCA8Ph81mY10cQgghhMggCALOnz+PhIQE+PlJ15tYPlA5fvw4EhMTWReDEEIIISrk5uaifv36ku9bPlAJDw8HcGVDIyIiGJeGEEIIIXIUFRUhMTHRfh+XYvlApaq5JyIiggIVQgghxGI8ddugzrSEEEII4RYFKoQQQgjhFgUqhBBCCOEWBSqEEEII4RYFKoQQQgjhFgUqhBBCCOEWBSqEEEII4RYFKoQQQgjhFgUqhBBCCOEWBSqEEEII4RYFKoQQQgjhFgUqhBBCCOEWBSoWJggCvsnMxtacc6yLQgghhBjC8rMn+7KFu/Iw/rddAIDsyYMYl4YQQgjRH9WoWNjBk8Wsi0AIIYQYigIVQgghhHDL0EBl0qRJ6Ny5M8LDwxEbG4tbb70V+/btc1rm8uXLGDlyJOrUqYOaNWvijjvuQH5+vpHFIoQQQohFGBqorFy5EiNHjsS6deuwePFilJWVoV+/frhw4YJ9mWeffRZ//PEHfvnlF6xcuRLHjx/H7bffbmSxCCGEEGIRhnamXbBggdP/Z86cidjYWGzevBk9e/ZEYWEhvvrqK/zwww/o06cPAGDGjBlo0aIF1q1bh+uuu87I4hFCCCGEc6b2USksLAQA1K5dGwCwefNmlJWVISMjw75M8+bNkZSUhMzMTNF1lJSUoKioyOmPEEIIId7JtEClsrISo0aNQrdu3dC6dWsAQF5eHoKCghAVFeW0bFxcHPLy8kTXM2nSJERGRtr/EhMTjS46IYQQQhgxLVAZOXIkdu7ciVmzZmlaz7hx41BYWGj/y83N1amEhBBCCOGNKQnfnnzyScybNw+rVq1C/fr17a/Hx8ejtLQUBQUFTrUq+fn5iI+PF11XcHAwgoODjS4yIYQQQjhgaI2KIAh48sknMWfOHCxbtgwpKSlO73fs2BGBgYFYunSp/bV9+/YhJycH6enpRhbNKwgC6xIQQgghxjK0RmXkyJH44Ycf8NtvvyE8PNze7yQyMhKhoaGIjIzEiBEjMHr0aNSuXRsRERF46qmnkJ6eTiN+dCAIAmw2G+tiEEIIIaoZWqMybdo0FBYWolevXqhbt67976effrIv8+GHH+LGG2/EHXfcgZ49eyI+Ph6zZ882slhew10M8v36I+jw5mLsOFpoXoEIIYQQnRlaoyLIaJsICQnB1KlTMXXqVCOL4nNenrMTADDqp61YOqYX28IQQgghKtFcP16O+rEQQgixMgpULExOEFJJkQohhBALo0DFy1VSnEIIIcTCKFCxMDkDeljWqFwqrcC23AJZfZUIIYQQMRSoWJic+z/LGGHwf9fhlqlr8fMmyh5MCCFEHQpUvBzL2oys3AIAwM+bjjIrAyGEEGujQMXC5DT9UKML8RWl5ZVYc+A0LpVWsC4KIURHFKh4ORr1Q3zFpL/24L6v1uPpWVtZF4UQoiMKVLwcjfohvuLrv7MBAIt357MtCAcOnSrGsOkbsDH7LOuiEKIZBSoWJq8zLftIhWYbImZgf6Tz4/HvtmDl/lO487NM1kUhRDMKVLwcDzUqHBSBEJ9yvOAS6yIQohsKVCyM9zwq7rw6dyeGz9iASh4iKUIIIdwydFJCYixOY5BqxOKpb9cdAQBkHS1Ah6Ra5haIEC9nkUsDIbJQjQphimpUCDHW3wdPsy4CIZpQoEII8QpWqWE02z+nL7AuAiGaUKDi5ejiTQghxMooULEwOZ1peecN20AIIcQ4FKhYGNWWEEI8ogsFsTgKVAhTdA0lhBDiDgUqjGw4fBbfZGZryhxLzSaEEEK8HQUqjNz1eSbG/7YLqw6oHzpoldoIdwEVBVv82nmsEMOmb8Du40Wsi0K0oJOMWBwFKowdPlVs6Pp5mOuHWNNt/1mLlftP4Z4vaL4YS6NrALE4ClQYo3xnhFdlFVcOzqLL5YxLQpSiBxRp5y6U4resY7hcVsG6KIa6WOo95y0FKoxpuZycPF+iWznYoWppQoh5hk7fgGdmZeHNebtZF8UwC3aeQMvxCzF1+UHWRdEFBSqMVVRWqv5s1Xw5LB09dxHrDp3RsAZ68iOEmGfHsUIAwO/bjjMuiXGe/3U7AOC9hfsYl0QfFKgwNnvLMdZF0KT7O8txzxfrkJVbwLoohBDGLpdVIL/oMutiEC9DgQpje/POsy6CLrYcOSf5no2adwjxCde/txxpby9FtgXmF/Lmq5K31VNToEIMJ7g9bbz5ckEIG6xuVPlFV/rNrdh3klEJiFIbs8/idDHf/R0pUGEsPCTA0PV7W2RNCFGGrgHiaL8Aq/afwp2fZaLb5GWsi+IWBSqMDUlrwLoIuvhxQw7rIhBCCFFgxb5TAICScvWDOsxAgQpjgf7e0fRx4KSxiesIIdZhhdoK77jyauNnkZ1gaKCyatUq3HTTTUhISIDNZsPcuXOd3h8+fDhsNpvT34ABA4wsEmGAOtMSYi7K91ZdcUk5LpVeS/Lm1btI5sZZZXYFQztIXLhwAe3atcODDz6I22+/XXSZAQMGYMaMGfb/BwcHG1kk7tAFhVQpvFSGyNBA1sVwSxAE7DhWiCax4QgN8mddHMIp3u5/l8sq0Pq1hR6Xq6wUcOBkMZrE1oSfVaobNLBZJFIxtEZl4MCBeOutt3DbbbdJLhMcHIz4+Hj7X61atYwsEiFc+mTpAbR7YxHmbD3Kuihu/bL5KG7+91qa/4czZ4pLMPiLdZi71dp5mYxyrOCSrOUmL9iL/h+twqS/9hhcIqIE8z4qK1asQGxsLJo1a4bHH38cZ864z3JaUlKCoqIipz9iXafOU3IoAJiyeD8A4KXZOxmXxL1fNuUCALYdLWRcEuLo/UX7kHnoDEb9lMW6KACs26zyxapDAID/rj7MuCTaWHX/S2EaqAwYMADffPMNli5dinfeeQcrV67EwIEDUVEhPVnUpEmTEBkZaf9LTEw0scQWxPkR+/MmdTUIl8sqMOmvPdh85KzOJWLLfc4Z9qi/EZ8KL5U5/Z/344jwwSqTVzINVO655x7cfPPNaNOmDW699VbMmzcPGzduxIoVKyQ/M27cOBQWFtr/cnNzzSuwAbz1glIpc1potSfKtBX/4POVh3DHNGqCMJXOccqCnScw6a89so8XIs41gHQ8rWb+nW1uYcBfHxVibcZmG1OoYcOGiI6OxsGDB9G3b1/RZYKDg32uw63VTF9zGB8t2X/tBTdXLbX3p4OnvHM4tEUecHTz2HdbAACpibUwoHU849JYmJtz7NCpCygtr0RQAPOWfr742LlmZVwFKkePHsWZM2dQt25d1kUxjTfemCYomD5d7ebTExsbRu136qtkrEqTLzReeFnzShV853mzMzTELi4uRlZWFrKysgAAhw8fRlZWFnJyclBcXIyxY8di3bp1yM7OxtKlS3HLLbegcePG6N+/v5HFIgZZvDsfd3+urCnGKm2k5ArH0YwndQwuqOVHG14D9715RZiyaB+KS8pZF8WnyL2ubs6RnkyWJ4YGKps2bUJqaipSU1MBAKNHj0ZqairGjx8Pf39/bN++HTfffDOaNm2KESNGoGPHjli9erVPNe1YZBi7LA9/swnrDyvr3OrufBIEASXl0h2rpcxYexj/N+1vnL9c5nlhzljpfn39uys0fT737EX7vylg1cY1HwYve3PAR6vxybKDeHfBXtZFISKs0jfM0KafXr16ub0ALVzoOQGPt9Pr+rxoVx76tarexs/7HA7ujPh6E1bsO4kNL2cguqb84PWNP640PX215jBGZTQ1qng+ybHT5qUy5UGkox7vLrf/2xqXS6LWjmM0nJ1HVhnMQb2rvMQj325GflH1qvhSzhohCy+V4R+HjrDuTpRle0+iUgDmbTuu6rsc02VbhjWuG7qjChVj0f4lVkaBis5OnS/BDR+vxreZ2bKW1/P6caa4VMe1GaPTW4vR94OV9v+rvYBaJfWztzFqtys5DAovleG133Ziq0Xa183g6WfJE3mIMdKRMxc9L+RDdh8vwu7jRbhYWo7LGmsifREFKjqbsng/dp8owqu/7WJdFC6VVTjfkswejUC0MSxQUXAcTJq/B19nHsFt//nbmMJ4A5fd+f7CfaZ+vZ4drbW6VFqBnLPVAyezrjyXyypwwyerccMnq9Fy/EK0n7AIgiCg8FKZqj54csjdNqtcfilQ0RnLaNkq7Y2O1J4oS3bn61sQwpSS4+DASevn0KmoFDD6pyzMXOucqn370QL8uCFHcediTwHknztOKC2iJjzdADOmrMQDMzZWe92sOlnXJujLZZU4e6EU7d5YhG6Tl5lUCnE8/U7ucJVHhZivvKISJwovI7F2GJPvV3Oi/H3wtOaOnLziPdg0KoV+WSVffamMtnh3PmZvPYbZW49heLcU++s3/3stACAuIhh9msfJXp/rr8L6OOLpBih3QkKjiM3CvPnIlWbL04yb6wsu8t9dAKAaFd2JPQmdOl8i2tH1yvJ6frfyzwybsQE93l2Oz1b+g1kbckwfribnguraH2U7jSDgxtFz+vRF+NLik8Ap5SmvyP5869QaVVYK+DYzGzvdnJdm9iirrBSwfN9JnC4uMfFbpfmLBCpG9rEruFiKMpmDKI4X8tNE5w7VqBisolJA54lLAAB7JgxAaJA/4xI5W3vwymzVk/+6kufA38+GOzvpO9Gju1NSTnDlGvyJnPfEJK7X10OnLqB+Le21cWcv6Ptk1+6NRRia3gBj+jXTdb168dS0o/ShQ48b308bczBrYy7+O7STonQAf2w/Xq1PnusDiJmPP79uOYrnf92OqLBAZI3vZ+I3ixP7ZYy6hJ08fxldJi41aO3sUI2KzhwvGCfPX8aXqw/Z/y8W4fM2eGXb0QLWRfDIm2fw5aXKfN2hM7KW46S41RReKsOnyw5aJqGVK6VNN9Waftx8fNnefExZtK/avnnhfzuwNacAHyxS1vF294kiRcsbrar/WsFF9wkfWR4ZRl331xw4bcyKGaMaFZ05Pind88U6HDp1weE9seXNKJV8Zl/X1Yz64S2480b3fLFO9HWrDQsvrahEiB9ftZhyaL0ulLs5kR+cuQkA0KJuBAa2qT6vWnGJ9v5fruW31lFDeEM1KgZyDFKswuxU5nICI9ebo5/FbpZK6LH3yyoq8exPWfhpY44Oa3PGw55XUgbeHgSq8FCsExbpn2B1Yr+1F1/CDEGBCmOse+e7MvvCruaE1fsk/2VTLr7+O1vflXrgGBCud2hmqbgauV0uq8Dh0+oC3blbj2HO1mN44X87tBVSBt7n6OHt/JJL8X7V8Zyw+j3Umr84cYcCFZ1cLPWO2UHNjvTV3Of0LGJlpYCxv27Ha7/vQp5JT5iXSivQ94OVePF/2wEAd4s0swz4aBV6v78Cm48om+QRuNI/wygFLuumm4IxlJ4XLGsZxfqMWeG4YBlkcx7fc4cCFR1Mmr8HLccvxN8H3XdksurTnVZ6X0PF8hKo5fiLXNAh2BQEweMFcN724zh0+gJmbcyVXCb7agryedvNTdTlkeu2+eYhbTilu1XNGSF3CKvH7xb58t3Hi+yBuKtxs7fjxk9Xo5TxhKl06FoHBSo6+HzVlZE9b/+1h2k5fCVKl3tRlrM79Hyq+veyA0gZNx8p4+bj4Mnzksu56+joyqqjVjwxK8eFVc8JpeXely99vEn5dNlB0df1eLA4VnBJMhD/cUMudh4rwsr9p7R/kQXw3jxqBRSosObjxzDrTmWOu19rUd5ftN/+79d/3y25nKJARU3TmJE71WXdamsJR8ysntLcpzjsttLySizYmeeUJVTpfi2vUP47eEo6pyexY5Lm+eLLccYZfN2h4ck6c3fq6XVeXiwtF30aEiDgyJkLyC/iIyOjHKr2CevoRqMKBVXuai7mZj7Bqf2qbUfVZxe2+M9fzQeL9+HzlYfQom6E/TXFfVQcHjm1/v5G7N6qMpmdLbbosnR/LaW7acHOE6gRHIAeTWI0lopPXScvw0d3t8etqfVYF6UaClQs6OMlB+zNTa6uf2+FxrWbexfwxWcqo2tUjMTD3CBKbjCc7T5Rv2cdBwDscUic5q7cFZUCZm85is7JtZEcXQOAdZIgvva7ubPKn9FpLp38ost47LstAIDsyYM0r4/XyqRPlh6gQMUXmHG52JunvD1aqYpKQXSOCkdqh88qZdYTtFnJzCoURR98XdGOnHGe2+fkeevU3vFKaYr1Hzfk4JW5OwFcu2k6Hro83gSrzq3cs/rMDeWO3O2X27z23sK9OHZOfbMIhz+HJF7LSn1UdMbrD63EpL/2oO3rC5Fzxv1Fpff7K0wpzz4DAzMeL+qOxCYV/mPbcdzy7zWSF30zs8eOm218rhZvUFJegR835NgncXS8SSr9vTZmXxuyvnzfSVz/3nJsd2hK03pIKy2PNyTgk5J79iKmLv8Hc6/WehE2KFBhjMfz9vOVh3ChtAIfLd3veWETfL9e/wyrvNiuYm6lp37cim1HC+1P1UQaLyMupi47iHGzd+BfU1ZpXpdjYPDAjI3Varm0kjvPE6/kxllyDo2LpdqnEzCTkhjzjEh/IV7OF1cUqGhU6GHiKzPpcYwZ8TC+7pDypGVmYZ3b5uZ/r1X9WTNHbQDGXsRiw+XP1mvFzrSrr+ZYulRW/can9/Zo/Z2MTK1vxvmm12FaXFKOczr0yRKd403zWrXr+NaSaq/xUC4xFKho9O26bNnLyjkILpaWY+rygzh4sljTeryZ3Ov6MYXD7fS8X5hxMzXz6WfhrjyM/nmbYeuvXSPIkPXe/fk6/L6Nv2p7Th9cufLRkv24ZepaXDKoVsPTT9D6tYWSk3N6K16PSwpUNNJ7VMa7C/bhvYX7kDFlpb4rVsGUkQQGnhkHZCTB4vXErMK6xqfKo99uxpytx0z7vhf/tx1P/7hVNBjbmH1O9np2nyjC0z9u1bNoTvacKMKAj1Zh8e58w77Dlac+JHlF5k42aFRQ/tGSA9iWW4BfNl9LHOcYtOgZqK/YdxIjv9+i2/qUUDNNhlF4ud64okCFMdeTbfMRzxdhqeuC3oeY1EF7vOCSwpErbCgtonmji8z5Hqu6XFaBWRtz8fu249VqxXZI5F+5LNKkYoYnvt+CvXnn8fA3m1Svw93x8Oi3mzB0+gZFN+VnZmWpLguPqlLtf7XmMFqMX4B524/jQP55dJ64FDPXHta03hlXPz98xkb8uYPNdBUPfa3+2DFS4aUyDPlyHX7eJD3Vh1loeLJKp4tLsONoYbWEXHKuJzynRfd0D124Kw+PfrsZ/VvFmVIeMXJv9JT50jqkfirX13efEA9Uzl5w35dg4Mer0a1RHbxyY0s1xZMkt5+Qu0NWrObSZrtSe7Bw15WammMFl1C/Vpis79p9vMjzQhb05rwr2Z5HzcpCl5TaOF1cgtf/2I3h3VJUr/ONP3ajY4NaehVRnIfLkNkPfWUVlXhmlngto+P59p8VB7H24BmsPXgGd3VKNKl04ihQUelfU1bi3MUy1IsKlf2ZqhvnhHnS6dW1VL3p3WdB7AL6xdVEc1UXUKuzQiwza0MOzl8ux8M9Gzq9LlV0b66wkfq9PAWve04UYc+JIt0DFT32tVTZpa4Fnr7T7Op7JU3Eep1vctcz+ucsj8uwzuTtui2r9p/C3/+cwXP9miLAX/9Gjz+2Hcf8HXkelyu6ZG5nfXcoUFHp3NXRPq5V03Ke9mf+na3puy1wb+WC0osir9k9X7yaq+SGtnVlBcbedHx4+g3/2HYcHRrUgj+j9jQ/Hb5XzhoUZePl8ADQ+9eRG4xtzSnwvC4NO+z85TKEBQXg/OUy/LnjBG5sk4DIsEBF3+n67UOnbwAAJNUOw71pSarLJsVdLeBRh8R2rJpTxVCgYiI558POY+qrbc1I9KV3rY2R11Q5ZeW185iYCyYPR9aipLwCS3afRNdGdVBLxoge2bkvXP7/1NWOsutf6quwhPpQe8rJOepYBs6Dv1iHAa3jMaxrsi7rq9pec2pUzDmnTxZdRpe3l6JF3QhEhQYi89AZLNiZh29HpLmUpnp5HF+RaqKuSg7Iipmd5z2hzrQ6ssHm9gQSu3E6vnTOQzv7te+Rv35vJPcC7gt7Y8nufNz1WaYpqcmV+GDRfoz8YQsG/1fe8E6pQ/fQ6WJZy7HqoKxLjYrSdZiwrZmHzug6L4/ekxHqeW4rXVfVdXbxnivN33tOFCHzapK81QdOK/5+qUBFbrnyiy7j+V+3YecxeRN98llv7B4FKjry9HTuqc9UmYJZdYk+9IjtKioFTP5rr/YVifBUvoe+2YQN2Wfx/K/b7a/xcCH642ruErnzUkmdO+sPyxu6yar2QW6M4S4Y0b9ZhD9V2XN5HPGm9hqg13Oh1H1hjcygZ9SsLPy86Shu/HSNrOV5PD48oUBFZ+5ORKObGfRYO48XErXkXEgcF1G77XO2HsNnK/9R92EP5P6memTQ1JMeNQ0AUFLmHLzz1lTnuJl//3MaW3Pk5XhxOjYldpXqXcjXLnKi9ubuOFLSZtM7I7i6Qh3VMFGhI6lRoDtk1pDsl5EvyuoMDVRWrVqFm266CQkJCbDZbJg7d67T+4IgYPz48ahbty5CQ0ORkZGBAwcOGFkkQ+08VoTf3ExeJTbBnJ70GOaWe1afk48HZt3UjivMgKuW631LyUX/ROElrD2ovFqaNbm1jDw0/dz73/W47T9/K16H0s60vHX6NmLfT1/jnB/l181Hnf6/j4Obs9yHE9EU+g6vaU2joPTTfB098hgaqFy4cAHt2rXD1KlTRd9/99138cknn+Czzz7D+vXrUaNGDfTv3x+XL5ubWdEsQQHVDxGng0zmEXSxVLxT5c8btSfmWbn/lOZ1GE1uAOJ6/lc9uZy/XIbFu/NRUl7Bfb8evYqXPmkZhny5XnZ1shG25JzDl6sPKcojVC4zumd18dVneLK+peet1smRY8ncHduuKRw2ZHOUvZWz3cv7NUwPho76GThwIAYOHCj6niAI+Oijj/DKK6/glltuAQB88803iIuLw9y5c3HPPfcYWTQmQgL9dVmPVArxf06Jzw80d+sx/G/LUXw6OBVRYfLnVBELiHTPfmvgORYWdG1/z1x7GO8v2o8fHk7DhD92Y9ORc3ioewqeyWhiyHe7u/mUVei/0XJvdusPn0H3JtG6f78rseLcfrW2IUbBBIRyjw8zRryJ0auJy5W7WhNPX2n2fcuMPW/kd7C4zzv+ht4fZmjHrI/K4cOHkZeXh4yMDPtrkZGRSEtLQ2ZmpuTnSkpKUFRU5PRnFZ6qALWSelAd9VMWVh84jY+XKmtW+2un56RAPLuxbYL936//sRvFJeW4+d9rsenqNAW/bjlq+kViX955vLdwn8nfeo1ZF2XHC/HF0nL892qiQAD459QFxeubv+ME1h06I1n+uayGUorcQcWecKs123k48gQIOHVefKSMDzxAV6MkHlS6f4zenWLrd/xtffH3VIpZoJKXd+UmGBfnnIo9Li7O/p6YSZMmITIy0v6XmMg2ta+V6NEBjYf2TdenTam+OYEKszqqzomh4EIzZbGyIMXdDU3snW8ys91mPjaL42805udtmDh/j9vl3e3DI2cu4Invt+CeL9ZJ7g09tlnN1BZGJnwrcDhflTTn8HrfO1F4CXtO8PdgySJQeGXuTo/LdEmubf/3xdJyybwqvP7eerLcqJ9x48ahsLDQ/peby37CJC3MrLHW44Dm4aRwvWgXXRIPwDw+tQrmX6S0fJ+cY2X8b/rlvtDCsaxaauYEAcgrNL7P2thftqHbO8uw+chZ9Hh3GeZsPer5QzAuhb4NNlP6mgybvgEHT6rvmLox+yw+WXZQ1rJvzXMfrLrjGPi6axY7VnCJi2uUHlKia9j/3XXyMnR/ZzkOiTTvK76mWHBoJ7NAJT4+HgCQn+88Z0x+fr79PTHBwcGIiIhw+rMKo5t+vOUEFTN9zWEM/Hg1zuicOMpsin8juX00ZK/OnKNEy6XQ9Trq5+fYoG9M+X/ZfBQnCi/jjmmZyD17Cc/+tE3W5+TWqLgupmUzPAfg8le+cv8pDJ+x0e0yv2Udw8dLxJuNh11N9y5H0WV1NbqCIO/e+sP6HHSbvAzL9p5U9T2yyyNjmfWHzuCjJftRrlNurKratVUigx0KJR7U9CQWIJmJWaCSkpKC+Ph4LF261P5aUVER1q9fj/T0dFbFMpTheVQUXv1yzvCVzdSdCfN2Y8+JInwq8+lNNgvVqFiJnp1beX7+E9tMI35jRXP9KFy3p3wgz8zKwodL9mPzkeqd+MsVdAz/+58zCkumzLsL1SVdNOK6fPcX6/DRkgP4edNRrxiVY3Tw54mho36Ki4tx8OC1G8vhw4eRlZWF2rVrIykpCaNGjcJbb72FJk2aICUlBa+++ioSEhJw6623GlksZkRrVHQ8STydD44nzJacc/ZRGFZSUl79CUXLPdFx/5txcz2v8KnS7U9q0Qugx9l/XTbL8XeR28xgFrNGGwmS/xFZ1qDDokAsqaCCzdeS58nI3WzkaZR9RnnH8Spikwd6KqpYs9il0gq8NGcH+reKw4DWdVWXhyVDa1Q2bdqE1NRUpKamAgBGjx6N1NRUjB8/HgDw/PPP46mnnsIjjzyCzp07o7i4GAsWLEBISIiRxWJGzUGmhJLEQb+7SUxnJuWBmjVvzlXkpoQ3yomCy7j3v+uwZHe+54U10PO+4tjyIzUSxsrknPfe8FSu1pUgxbhIhdc9++eOEzgrc/43d75cfQhzth7DY99tUb0OVsP/qxhao9KrVy+3J5jNZsOECRMwYcIEI4vBDdYXGx5PSD12yePfbUHn5FoY3a8Zk+83kt7HzOyrw3j//ucMsicP0nXdTnS6rgkQDMtVYhS9+jaaeWzKGd4t3unXeLydo1fOSZl9kzR+1/pDZzCwjbZakJMKg/v9+ecxawNfg1QsN+qHSNMhg77p9LgHZR46o0uTwKXSCu2F0dlcp5ov6Z0lla3Yk8tlFfjPioNcDhutYrE4RbfgUmotRpzmo37K8rgMy9T9xjb9GNx3UM91qViZ677ztCv7fbgK09ce9rCUuShQMZHYMabrqB8FK7PaxV+ucwqqSgXBueEpY8pK2ZPK8SZbZcfoz1b+g3cX7MPAj1frXCJlJG/KAn9z23hyvKD6cGrXbfDYDOw6SkhjmfRw8nz17RLrMybX3K3HcKJQ3jxZ1joC9KPH7+4N+44CFROxrsJk/f1iqsqUlVuA79Yd0fx0M+gTbTfcTxRm7wX4nlvFkx1H5c3Qqielv/HHS/cbVBK+8XaDWbhL335NC3bloc/7K3Vdpxo8XhflMiPHEMD+WDS0jwpxZfTwZOO/3aiT+tapawEA8REhyGgZ52FpaccdTlw5ZVV606ysFJzzejBk1eur0nIv2cN2aKQ7hs5BI/U6ozurEYf9pTJ5za1ONUw6lyOvSNnNXnH3fwNzZR2XUSPFuiOsHqhGxUSeDlitx1OFkqYf5jGyuAMn3ScWcpdNVmnio6LL5ShX0LFnx9FCtJuwCF//na3oewD2HamlsCiVktFpLPeaob+Zw7rFbiRTFu/HMYn8Jqz2CcsbnpHXq8l/qcu/IovOxb5UWo4lu/NxWWaApxfWsQ4FKiYyfPIrTm+GSnhqRpm1MRcLd4mnZG/3xiLF3+c6QaC7b3/ul204f7kcr/2uLE39/zYfReeJS5CVW6C4fI5E81hYkFhsyOrY3ZJzDn0/WCH63jOzslStU2lToFRunZE/XBtOysOpzaoi0XV/ShWDz0cvfb2/aD8e+maTfa4g1+Ni1YHqmWtdsQ461KBAxUSeE7IZvX7tVzstSZvkkDMUdfWB07p936+b5c3p4o6np70xv2zD6eJSPP7dZk3fw3LWZaXc7RElk//pfYM+VuBcS3H/l+slZ3P+fZs5uYY8ZYbVyxqN5w2rWlgbbLJurhzEcrqTOv6lrluzt1QfZu6673ge4SeFAhUTGZ5C39C1X7HjmPmdL82k5lIs93fVMkICqN60pfdNvLyiErdOXYvnf5U3z41aSpp+9HbYJSi5wOGQdHHa99mDM93P6cMrAYLTecm6RkDp4Wvsdd/zul0DzO/W5Sj+FtaVMNSZ1kSeO7tqO6APn3afrtkbnzj0ZuQ+KtNpgjKjrDt0Flm5BZqbqDxh2YzBLEjSeKVfuCsfcREhCA8JVL2OUo3HH+sAocrlMr7PI1fzt58wbN1yDmdefjctKFAhXOH5nNJ6witp8tDTD+vlPUEp6Yythafd4FgMvZ9GWdbmaPHewn3I/OcMvnsojVmgx/KGJ6cjb4WCCRK1UHJMfr7ykObv+nmTdJZYpVustjmT9cghavoxkeikhM5XZdPIOe6ubxpjfEFcWPM2Yo78osuq+hm9NGeH5HssOrGKBQtSpdC7XwQvx5eacqw5qF/fLDV4HSlY5bzIJH7e4Plft2v6vOOv9vSPW7UVhhEKVEzEPDGYwq83I6W8RR9wVdG6qeculuGlOTsd1ud5jWeK+ZvET0lwpPc5w2p0Ed+3eKKnX9zUgBB1KFAxkRkJ2dyv34eiApVW7DuFf065z+Xiysx7348blHWE6/jWEoNKop6iJiad963S32rc7O2q51Eyiq+dxYIgbzSgWTwdQ2M11oAo4SsPehSoEKY4uv7Y9f3Ac1pvT0/muecu4r+rDuGCQ3W00ZtaeFFZwjtXZv0ULCfPVHph/3FDLj7T2M9Aj3JwgVkeFf5YKWeVHtdY1tdp6kyrgtpcIkbnUbEi123mMG4R1X7CYnx+f0fUDA7Axuyz1d4/dOoCJs7fg+wz10ZiGf3ztpugPOEdC56O84MeshNroaYz7fECZXlONmafQ4M6NRR/j1zUfMWekozWWuiRG0uPjrDlJnVUlkI1KiqoHWYq1vQi9+dfd+gMfsuqnsxH0fdzGAixjtTVKrxUhgdmbMSNn67B3/+ckVxu3aFr713kMGeHHofE7uNKE0hV/1bHc8oxX4zeh6wZ95edBuYa2n28SPFUEUYp1ZgXiJhDj0vshHm7mf7eFKio8Nwv6hJiacmjcs8X6/DMrCxMX3NY1XcDwJkL11Kwyzl4WfRp2an4pkdYu0FkxupcN9lWxc6D3LPXljc2eNXvmB75/RbsFsnyGRxQ/bKq1zbd8MlqTZmZiyTS9avxxap/dFuXO4LA1wONEQ98o2ZtxbkLfE+RYWRNpycUqKgwT2UCH7HjW+lBLzXPjRwbDl9rouDlxHfd/j9MSluuBzn70Mj8AzzWkFXR8vRl5KGpZ43KnzvUJ/Ji1Xzz/C/qO3q6HstL95ozq7UAgetjXQ9zs44jbdJS1sXgFgUqEi6XVWDKon3YZnCWzm/XHbH/m/csg9keMt96m+X7TuLjJQc03VSMvCFZ9eLtsdwOx7je+8+q+0wvCzQ86Lheenx5XxpxGVYT3PvKT0CBioRpK/7BJ8sO4papa3Vb561T12qenptF0qXS8kpkTFmJXu+v0H3dYoFXSXkFF73qH5ixER8u2Y+Fu/IBsM/O6Eqs2YGVk0WXZS+rpElR/z4qytfI169uLsfzkG1mWnbf7UowsFHcdeQe+6sgHyhQkbAv77wh6/1KpI9J1Rw9cg5KradI7tmLAIBT5z0nAqsKir5cc8iw9kmx+0bzVxdg6PQNhnyfGkpHfTiSmpmXF3rFg1tyCuz/9jQqTslcLXrHq57mw9KDWJFdHzCscgP6zwpz+qG4c7a41GOTd8FFvvt3yPXR0v2ylxUEQd60HDoFeSyDRQpUTPbewn3VXuv9/gqM/ilL1ue11qjc88U6AFfaROWau1XbaCOlBAGaOgzqTepSYNQongsWTAW+cFcevsnMhiAIWHXglNtllcw3onZuEilTFsu/EVQR71umPtT4cvUhvPHHbtWfN5PY9aqKWcHWl2sO46ibztkAcPO/9av59sTIyt6zCjrUpoybj3u/XO95QZ3Ky7KSmwIVTszeekzWxS/zkPRQWDmOKagdqKq92Z9vXG9vnqp0PTGrOarVawtN+R5XWn6LOVuPYfxvu5Aybj7GqhwVV6WMcc4GObQcCm/9uUe/gpjot6zjbifIYynnak2xWThomfYpFKhIoHTz1lcVWMhp5nLn6DlzL4JWd7pYfTX8hZJyDOOo2U+Ku6vDaY3HG8+e/3U7xv+20/OCXsxydwZq+iF6co3SZbU/GkjPjrss5kspLrnSNNNt8jJN65mxNluH0vCJtxqtTUfOsS5CNWK7yF3t2myTm0rN9k3mEc8LeTmzHmR5GFTAAwpUZGCVkc+bDtGJf+4x/aSrCo5KVWYS9gV0HfTsl81Hq70m5xmivKISS/fka56DyduxfiAj/KNARYamr/yFX0UuVkarurHrfYMfJJJJ1GjLTEoO5UjNUFRfxmLou1XJeaL+fNUhjPh6E+78/G8TSsSATufXg19v1GU9ZqFaDvNRoCKT2rT5WlSdDnqfF7sYpak3+/wWBHpa82TlfvcjdIg4T8dy4aUy/H51ZN3+/GLumth4smKftmNw6vKDOpVEPopVzEWBCkdcD/7TxVc65bGqGah6arTqRbZSEHDTv9ewLga3ThSqzw/jDV6Zu0P2sjd9ugbFCoaNt3tjEfblG5OLiThzN4TaCBSjmI8CFY7d/fmVnCfecmKcKjZ3NMSPG3JV1x7d/XmmzqXhz6PfbmZdBKa+W5cje9kdxwrxbaay6S6I96J+b+YKYF0AqykpNybJF1C93bsqNwDrvhY26BMsrRJpZggP4fMQXO8wgSMAFJeUY69B2YpZ2X600On/rIdhrz14GlMWmft0rESZw82J0hd4zwOUUoLA/lxRQq++Zz49PPn111+HzWZz+mvevDnrYkk+MT3G4CmUVZxSdYDr0c1DKtjp3SxW+8pN8PSPW1kXwXDTVrJNlz7ky/XY5hI88cTxOk01Kr7N0zQRetEjg7FeQTXLY56Lx9lWrVphyZIl9v8HBHBRLFHLNXb8cmdTtngOCVYHiJ5PjccLL+PF/1WfYt4q/V9YjFoi/FJay2mV45zwRUlKfW/GRUQQEBCA+Ph41sVgbozEyCJW1cwbs8/pOtqJBuDwzVdqCdYcOI2GMTU0rcNHdpVbRh0vS/fkG7NivVjsx/eGph8uApUDBw4gISEBISEhSE9Px6RJk5CUlMS6WNxgeYNnkT+GsOEr/S7u+0rGRG4e+EpQx8LXFsh8a1TOob0nvKsfnF6YByppaWmYOXMmmjVrhhMnTuCNN95Ajx49sHPnToSHh1dbvqSkBCUl10aPFBWxyQliprMa5k4hhOjD6YlSYaBCyfS8h5EBvRFD2tcf1jaRLQ+YByoDBw60/7tt27ZIS0tDgwYN8PPPP2PEiBHVlp80aRLeeOMNM4vIXMaHK1kXwTD0ZMoPHn8LPxufTYa+UvvkjlH7wAqZX6PCAlkXQbatOQW6rIdlsM181I+rqKgoNG3aFAcPimcbHDduHAoLC+1/ubl8TjuuJ1ZzDRHfQh0+5VN6L11z8LQxBSFM+OK5wjI45y5QKS4uxj///IO6deuKvh8cHIyIiAinP2/24wb5SamsiP9nJ0Kq8/Xj1gq1Hkbx4U1nhnmg8txzz2HlypXIzs7G33//jdtuuw3+/v4YPHgw66JxYdxs+Wm+CfE2PDX72Bweo335Rg0An608xLoITB3IL2ZdBNOxbPph3kfl6NGjGDx4MM6cOYOYmBh0794d69atQ0xMDOuiERP4+PWeK7lnfXvuH0+OF1zbPzwFUCx8uHg/msbXZF0MJgQAG7PPelyO6Id5oDJr1izWRSCEEI++X5+D21LroVNybepM6+Po1zcX86YfK5m59jDrIngduuATK6nKK9TrvRVsC8IBo2pDVx/gu+Oxrzf7sUCBigKv6zDvAiHE+i6WGjc5KeEf64lifQ0FKoQQIpMvDkslIihOMRUFKoQpejAhxJp89dwVQHGK2ShQIYQQogj1LfM9lPCNQ1TFSwipji4Mvk4QgOKSctbFMB3LGjQKVAhTes1DQQgxjyDo2/xxrMBaOXx+WO/dGcN5Q4EKYWrJnnzWRSCEKFSuc8a7bpOX6bo+I/lqsxfVqBBCiAVQkzDxVdRHhRBCLMAGIPfsRdbFIAxV0mT2pqNAhRBCFMg+c4F1Ebiw50QR6yIwsWr/KdZFYIKafjh0oYQyTxJCCHF2sdT3RvywRoGKBEqRTAhxRX1UiK9OpUI1KhyiCxIhhBDCHgUqhLmScmpmI4QQntGoH+LTJv65h3URCJHFRplpiY+iph/i02ZtyGVdBEIIIZyiQIUQQgghbrEcXkKBCiGEyESd7ImvEhi2/VCgQgghMlGcYpxdxwtZF4FwigIVwpyvTvJFCLlm0CdrLDeLsi+hph8OUe9+QoiY7NOUQt8o+/PPsy4CkUCjfohPK6ugGhViDTabDYt257MuBiG6+Pe9qayLIAsFKoQQQogP6tEkRsHS1JmWEGIhg9rUZV0EQoiJqOmHQ9TBkxBpU+5ux7oIhBCNKirl3+eoMy2HaPJkQqQF+fvupYOuDcZZQv1/TFUzOIB1EWTx3asNIUQ1G2U+Iwb4fn0O6yL4FD8FpzE1/XCInpoIEdcwpgbrIjBD8RnxJkoeOCgzLSHEMm5ul8C6CExR/zXiLZTUqLBkjQYqBuhiRAhxtTH7LHYeK2JdDEJ0oahGxcByeMJFjcrUqVORnJyMkJAQpKWlYcOGDayLRAgh1VCQQnyVT/dR+emnnzB69Gi89tpr2LJlC9q1a4f+/fvj5MmTrItGCBFB00sQQszEPFCZMmUKHn74YTzwwANo2bIlPvvsM4SFhWH69OlMy0WdaQkhxPsk1wljXQRLYtkdgmmgUlpais2bNyMjI8P+mp+fHzIyMpCZmcmwZIQQKecvl7EuApFp8bM9WReBOyvG9mZdBGvy1aaf06dPo6KiAnFxcU6vx8XFIS8vT/QzJSUlKCoqcvozAlWoECJubtZx1kUgMjWJC2ddBEI0Y970o9SkSZMQGRlp/0tMTGRdJEJ8yj2d+TznagT5sy4CIV7LZ0f9REdHw9/fH/n5zmmT8/PzER8fL/qZcePGobCw0P6Xm5trRlEJIVdFhPKZ1SCUAhVCDOOzo36CgoLQsWNHLF261P5aZWUlli5divT0dNHPBAcHIyIiwunPENT2QwghhABg25mW+aPR6NGjMWzYMHTq1AldunTBRx99hAsXLuCBBx5gWi5K+EaItZwuLmVdBEKIAZgHKnfffTdOnTqF8ePHIy8vD+3bt8eCBQuqdbAlhPBh3aGzeKRnI9bFIIRICA7wQ0l5pa7r9NmmnypPPvkkjhw5gpKSEqxfvx5paWmsi0R5VAiRsP1oAesiSIqPCGFdBEKY++4h/e+hPtuZlhBiPX4cTyHcNJ6G4xKip/q1QlkXgQIVKVShQog4f6tMueogyJ8udcR3KDlD/9VSXjcLgWEzA529XiCjRSzrIhAfwnONCiE8C/Cz4ca2dVkXw0lqUpSs5ajph2jSrXG06Ov1othX2RHv48fxVUMshAqj/CqEE342G1omGJRSQyVPFSU8PJdwfMlhi2U1l1KV1ikq8QL+PFy5JEidCpRugPDArFNHz++xz5bu66N+eGSly5qVgipifVbso0IID3o2jTHpm+Sfo57uHzZ7nEJ9VIgG1zWsI/o6xw++xMISqEmREMVeGNAc7/1fW9bFqMYKz7nME74R7WoGi/+MFKgQI7Soy1cbuxxWuBgT7/Z4L2snSfT5hG88stKFTSogsSkapGZN857qzroIhHNWOpet6pb2CayLYBm8HY+eilN1F6FAhRCVrPh0T4i36dZIfOQhYUNJbbrnUT9XVkbDkznEWdCryu0d6rEuAvFCVqyn84bzmWtWPCi8mJKfo5K3Kh4RFKh4sU4NarMuguHo+kgIIerJb/qhUT/8sUCUWcUX+qIQQpRJrhNm2ncVXiwz7buIvqJCA90vwD6NCgUqUqwTpkijUT+EXOGLuYZ+ejTdtO/6Y/tx076LeGZTcPG/Ny0Jg9rwldbfFQUqXsysOKVbY/E8LsQ7RXh6AmPIFwMSKYEmTsRYQemxLSsk0B9Th3TwuByN+iGWxnKSOqo1Mt8D3ZJZF0Exuo0ai0bf8UXPy+K1dVEfFe7Qgxkh4sKC1OWJbBhdQ+eSVCdW5S1A8Mnz2cwYvk9zmsHdWylpRjIKBSpeQPI4Yn98EQ98adqc7x9OM3T9zeLCDV2/1VRdF7okGz/6z4cOY58TEnglTKCmHw7RbKvytaRqX9XqRvrOvDlGb+uI7imGrt+qWiYYf35y8NBNDBIWeKUGlUb9cCiptnlD+6yuXi12N1seqiW1oM6f+gkMsNH+dFCVtuDpvk0Yl4SYTdfLIgeXWApUJDSOpWpkuW7vUJ91EQghEkID/VkXwfK6NqKRjdT0QwwRZNLwxJrBAagbGWLKdxFS5bWbWrIuAt+uPglbvNKRC8O6JrMugiJ6jsS0Z6alUT8c8oIqZDMuUNc3jQEANIqpafyXEeLggW7OfVJq1whmVBJriQhRN2qLqDcsvQHrIqhWdR+hGhViEOMjlXs6JwKgzseEvc7JtURf94JnDlWkHlT8fGSoWWpSFOsi2EWanCRRz4dUHqZooUBFAstr29N9GjP8dmUSqdMx4YTUBXU8NRE5YX/bMUe3RtG6ratd/Sjd1mUGI4ILGvVDnDzZR59e+mY0/bSuF6nqc5TJ8goffdi3++w+z6m7tbqxTYLh38EjyfRK1GlFsXgd++BVmjDdgJ+Od/ZrTT/UR4U7Sn+THx++zpiCyGDF646V22yJfprHU8BqFKmAxIKXC1X0ui7qPVBgyZ58XdcnRs8aFR7uLxSo6CRdx+FrPBwYhFiN1HlD/acIcw4HZ+GlMsO/rk7NIMO/w0wUqEjwhosby3inSSyNAiL8MKOJiRBJDlX0PZrEGPpVLepGICxIv9w5VbUzNOrH4kb2bqTr+qxeobLhpb5olxjldhmqNbrC08n/6eBUcwrixQQBGNC6LutiMON6rvlqH5XUpCh8/5Cx803JEWhwfqvkOvoOcODhcKFARYKS6HFs/+bGFUQDMy9IjvsrNoKSv+nh3Tva4qZ2vtkRVI0KEzop8igsyB/9WsZVe126M6379U0borz2yfV6+d0I9gGB62bOeaIbujXWbySQWkbX1utd87H6wGkAwN688/quWAEKVDikNMDQIyCpF6XvfD2+mrtCVxw8yViJntXdVmID8MXQTrKX95RGZWAb5bVPrpeg7k2i0d5NreoNbeIVf4e3MOPaKKcz7dR7lQWkn638R21xNGMaqCQnJ8Nmszn9TZ48mWWR7My4zzaPN3Y+IZ7vczwkEeKeBYO97gqfWHVNTCWxMgvuRkVeGKisRjcogP3z6W2pPjY/GA/tJy66NbbO/EXMj9gJEybgxIkT9r+nnnqKdZFMU7+WeFsif4e0ct7QGdkMlV5W9VQzWFl6dj3zU/iqoenJbt93nfPrP/d21PR9L9/QQtPnAXNycpTz1BTosL1mxCwcxkWaMA9UwsPDER8fb/+rUaMG6yIBAHo0Yd+WKYdeVagsk/n4MrfXUhkXG6Nr5ZRSeoEMDvDH+3e2M6YwV/nqsV31W9hsNtyblmR/vU19dUkaq0SGyUsHz3qvT197mHEJxPno4agJ80Bl8uTJqFOnDlJTU/Hee++hvLzc7fIlJSUoKipy+jNCVx3TL0uRuqjLvdi3SojAp4M7qO40xxTPZTORuxqVtJTaHj//RG/rTLcgpYaP9i0xk16n2/MDmuk6M6+RLpdVsi7CNSbvM6v8RnIxDVSefvppzJo1C8uXL8ejjz6Kt99+G88//7zbz0yaNAmRkZH2v8TERJNKy5/k6Brw12mCMd2DfE6fGr4a1kly8joWpEaqNI6tiQZ1PNcu+mptgdEaxfBRs8ubJ3o11iXo8eWj1owYItCfAhW3XnzxxWodZF3/9u7dCwAYPXo0evXqhbZt2+Kxxx7DBx98gE8//RQlJSWS6x83bhwKCwvtf7m5uXpvgmm0zsVRtVRMuPj09ko6rPrK/a5pXDjT6Q5cSQUqj/RsaHJJ2DF6Zlk1h/Y9nZOw+ZUM3cvirXzl+mEVcu4hSgc06D0yVAndA5UxY8Zgz549bv8aNhS/CKelpaG8vBzZ2dmS6w8ODkZERITTn1XpVT0X6O+HXW/017QOrZ1fXS9UdN2S50mJmbL/r4O6URFmNqPcIVJGNTes9EZ18GC3FB1KpB8BAurUFH8AsAp3N6L3/q8tAODNW1rhKYWztetx2fK5wEbHDX736m+nldTor+Fdk3VZv550D1RiYmLQvHlzt39BQeLzEGRlZcHPzw+xsbF6F8srOQY6NRSOtnD0/UNppl84vKtiUr1HRWpOhqY3gJ9Dk96cJ7pKfp7lBf/d/2uLnx7RXjtls9kw/qaWimpWlAQ2PndTFOGa6OzOTonYPaE/7k9Pxph+zTSvXzR4cbPjY8K1zUXz7Ygumj5vZXd10qe7Q6jEQ01IIH99xtTf3TTKzMzE+vXr0bt3b4SHhyMzMxPPPvss7rvvPtSqxU8fAiNprcXw9GQj58nno7vbo1vjaJ+qAeEphbhYWcJDnE/L1CTp88H1GGoWH44tOQW6lM0Tfz8b0hrql4tBbn+bdeP6Ii5Cfm2H6/BcXzSwdTxmDO+M5nWvjRILC1J3+dfj9OnYwHNHcSl73xyg+Wb6eK9GmLbCvARmYQ4PkkbnkNJcO87h3YBZoBIcHIxZs2bh9ddfR0lJCVJSUvDss89i9OjRrIpkOq1NP3oe7rd3qIfPVx7ScY3EE6kOb1r6FiXVDjMtUBFjxkVObu6VVwa1QKUgyB5O620cLy82mw29m3tHTbUeT/xxEv36jKKlxpswDFQ6dOiAdevWsfp6Lmh9MtFzFs4x/2qma6BCo1E8++uZHqKva7nZ81RbpJTeR8xDPdR3SKbDV5o37JvW9bTlklHKumclH6hO1MJuS63n9v2iS2Ue11F1XzM7rfaZC6Wmfp8jXi4aibW1z3LqetPgZdtUcXMDDDW53ZyegJVhEbxMH94Jg7skVmsqlaNTcvWmp8XP9sTckd30KFo1eu2eCbe00mlN1kKBCkNann79/WxOHS7FnCqWHuZtNE8n5rK9J00ph7ertp8NjlRGZTRx+74RWcsbxdQwLV/WhFtaIaNFHO7sZM5cNPddl+R5IRdv39bGgJLoz+jYpU/zOEy6vS2CA/QJYmMjQlQFPUppOZYTJaZdMQPLyloKVBiqqNBQxa9jOQgbenSqc21iM7Kj3vbX+2FURlO3y0SEqO8PInU2vHOHPsMx5Rianowvh3XS7ebnSWeRJ3tP7k1LQpPYmgaUhvCOZUdXlk1+FKi48datrZESbVyGygCLZQ98uIf0kFDXE6jn1f4zAVK1PgwPegt346jGdTcauW1ygpDE2u6TQvVrGSf5ntH9mmYM72zo+tVQW6sqZ08ZtTvF1svT/H9q2Wzi2+ZuP7aoa908Xq6qmv97NeWv0zUFKm7cd10DfDWsk2Hr79ooGrd3cN/PhCdK2u1vS62H/w7thLUv9hF9n9WTQYTBWVCVqLpH3di2rvqVGNxH5bHrGyE1KcqeIEyrz+7rKJnhUuqI0Cv44nXUy5u3tmZdhGrc7XMviEl0E2vy6CEjrRvXF3Oe6Ir0RuIpB6jpx0f5+wFT7mqP+69rYNh3eM61os/R59rk4Odnw79axiEuQt5QUjM83aex4ena1ZhyV3vMdkjqZnSeBSWiawZhzhPdcKebJFPtEqNkr8/Pz4baNbQl+/ImNkDV+W/0EfLTI+mqP7vp6tQDnmp0vn8oTfV3SGmv4FiUy90lso2K0UP8nN3OatcIcp+ziZp++GXkcM+qG5KaC7fcYqlpA5drQKt4w9ZthOsknhRYqfoJgwL80MHhAiFW27RybC/RdfCQnKl9/WsXa6mLmePcRVJldnchlHsWWm3orLvz+O5OiZj3VHfR94zeTKWT2jn+ptFXpx7wdGzq9xBz7XukRi/KmbxVagl3x5TUFBhVmsdfSbD3rxbXmjwtdohygQIVhqqaUh7p2dD04ZdVtIRhQxxGLPBww5RL7+Az3oRaI6mZlF0vonpP735z+wSPyzzVtwmaxYXjlUEtRN/v3jgaL91w7b2q/D/hLk2JVjqG9OKu9qxuVIjp+T7U4j1AbFtf3n5Uevq4Jp+LckkuOO+p7tj+ej/ZSQr11FCH/pWO66CmH44Z+dv0bXGlzbxGcADWv9wXYUH+aBpnbm9+JQdftYkHOb84VcNZefUImIzuTBsb7vkCG10zGAuf7Sk7wdozfZvg7dvaYMGzPbUWjxv+fjYM7qJ8qLGRjAr8xDo9V4q85un6wFundj32VkeXppMAf79qndBdN/uL+zu6Xee9adeOKyXNwi0SdOjo6/B11PTDMSNPJsfqyIiQQKx/qS/mPy2erVQtT8VXlK5dW1Gc18VZ0GBV1RK+aTxejew8XiUk0B/3piVV61TrtumHt7uai55NovH6zS0Vf85tp1WF50jvZuozVddl8MRvhiFXb/Kj/+V+WD1w5RrM4rrUz0MT+qMymk0deeO1lQIVjoSHBCJAwwRqNSRmw3RHy/Vfy2e96Vyy2SDZ7OH2czp8t95Pze4606klt4xWPiaaxIWr6gStZ/g17b6O+ODOdqo+Wz3gVdhHRcWPZ0bo+datrbH99X66TjfijtprYk0LZEKmph+OGTkCQ8uaxcq18vneyGjhnKeij4chmYrK4OZq1Lf5le91baP1Faye+KsfB9rKwcuInGc9JJZT62kPnR+V6JAUZf/3PZ0TDbuQrxvXV9ZyIYH+SGtoXOd5d8S2ncWTfbWzwWbTlITQ0fgbldeYWZ3j/kyW6CdnBgpUdHRDG2WjYDTd3EQ+Gl0zGF0dRrZUCgLuTzdu6LOjB7ol4z9DOmCRzH4HLG7rvD2xG3Fj01Ahpwst+zjMoUawdk1jAqbR/Zohe/IgXdblWPsZERqo6piWcwzER4agJUeJxcR+426No9GufiTu6Sw9jN0Vj815ogHX1S1+sHuKLgG0aZut0wVv9hNdcXO7BLyvsrZOD/zXNzGm5KCacEtrzN+RJ3/dKsrjieMovMpKz6NA9DppAvz9cEMb+YnLPJ1DMeHBOHVe37mKjJpozgZ+ciP4M774B2nIthwW6I8CXJlI07UZU+5azdz8QH8b/jOkA0rKKxBdMxgVKtKzGjECrVZYIIID/BGiYBoA1+Y5paUK8LPhtyedh1Lz9mCgh+Fdk/Hhkv1ul5HKcOv2M27fU3mM6HBo2Ww2dEiq5ZQ+gQWqUbEoqaFnrhMVKrkOehrO5njuRYUFolMD46qZpw/TP915O5lDFM1ixBOlp4kqjTa0azKax4drfvJ03DU2mw1v3XYle6unphszn9KbxIbjhjZ1cVvqlQkMVdWouHlPzY0+wN8P61/KwJoXeut2LLgOIxfDso/K7R2u7H89kr152o7AAGOOL61B3Wf3ddClHLyiQIUhJdfUBnWcZ83Ub46Ja4VIkEhtLmbjyxkIVdF5t4qneV3kJGhSysibGC9Pj6yz2kaEBGLBqJ54xsMsy2Lc7cNb2tfDttf6YXS/Zm7XYebWP3q9vOHYRnB3/gQF+CnulK8k0KjkbGKf5/o1wxf3d8TXD3ZR9Ln/66h8hmzP55c+Z6DUvFSuv1OAnw3ZkwdhQGuR2my+fiZNKFBhSMmNU23HNE+njfOTq/RyT/Zu7FSGQI2dIfQ8hzLH9cFiD31jjJymQG9JteVP5e76m3HY7C+b4/HleNxW/Uts+oMP73ZuN9cS33ZsoKx623WGZTX7Xu41YNwNzQEAI7qnKP8SGdyejy5FnLf9hKbveuz6RldWq9OxGhTgh36t4hVPj/He/7XFiud6eVxOKi4T65MYLJEZ15HYb+76itR8O2bj5XJCfVQsSuqJSumB5bh898bRWH3gtOhyY/o1xQeL3LfNKqHHiICEq7kf6kaGAoxbdfQ4oX94KA3rDp3B/3WU3yHRnSFpSfh+fY4u69JC7m8tNYzZ3c08Ksy5063aWrNt4/uhZoi2y6Ga745xN6mdw47r0SQGO9/obx/GyrIj6onCS7KWk7pGvTDAfa2YXqrS10ux2WxIjq6B/z3e1R7kiO3W8opK2d/50qAW+Gun+0DOMZipylvUMKYGth0tlP097jSNc7/dVkQ1Kjoy8tKhJl+GAGWTEj7o5mnNZrOZmuLcsdyOzVxdHOYu0tL0JOXxXo0Uf0avm0bXxtEY3a+Zbs1eVq5dcarpU/I5ld8XGRaoeL+LLd1X4QzNSvpVOOba8NR0qpTeiQPdqTpfjG6mdJxfyp2ODWqhcax0RnDHXeO4X1z32Us3NEe9qFCP14OHejRE63oReOmG5uh7NZ3EW7e2kVVWd+aO7IYnejXCyN76DcHnBQUqnPrhYeeZRY3KSeB4SnlqzqkbKb8PiydKNqdm8LWA5OfHrs3qakQ/lhcGNNd9nWaycGyi6hh3nSPLzOBM7LuS6shvtrNqNlirdH2QmqBQKaXHpacgMjI0EPOe6oFHel57KKrjMhzf8doW7lDT566pt31iFJ4f0Nz+AOdNc2dR0w+nujaKxiM9G+KLVYcAKDhZXI5kj12/FFzY7+6ciEOnLqB7Ex3aT3WIvPSegE8tm41d7YWZT8JGkzoi3G1TWkpt3N6hHhrF1Ly6rHk7QKxGQEktAV8/lYLzUW5Tnk5z/SwZ3RMZU1bJWlbrz89L+vlAfz9MH94JpeWVqMVJEkaWqEaFY2Zcc5WMDgj098P4m1qiT/M4zwvrSOrir6VGpZmO7bhSv1OjGPMzOTreqAeKjQTgWI8m0QCuJC505O7mb7PZMOWu9vbq7k4KO8QCwMSrQ58V03h+8pjwrIrSZhmx2ouQQH1uL41j5Z+rLAONqn2mVxH6NI+rNprH7O3j5RClQMVgVSnl69dS3mziWGMgt03a8bgSBMHtxfC6hrXRTUbv8jtVDOPzRI/zLYBxzpAqrhf1h7qn4M+nu+M+xiONujWOdvp/V05GEkiZcEtrvDKoBX57spvT60oulg92T8Gbt7TC0jHXy1r+y6GdMCRN3e9k9EXczHuS2wkhXf7vOlPyv+9NFU2m+P6d7dAwugbevKWVqjLVrxVabVSXEnr1gXG89rrro6KF43rljESyf85dEK/D9rNOd1CFAhUdiQUFq5/vjUXP9kQ7FcmIkh3au1W2/EiKCgvErEfSPdaodGtcB+8ZkDpZj5NcS0IrtTeZuztVH5Hjuq5XbmyJVgn6D0MSq6Fx3QXuNuubB7vgo7vb61omOeT+1jWDA/BQj4bVZlVWItDfD/enJ9ubgowktq8PnDyval3ThihL2KV3EOO6Psf+DZ5qfm5smyD6epO4cCx7rhduTa2nqkw/PnydPZmeXFqDRy2fv66h+gcBx3MkXOPoM/s6NRwlVZ2Lb2zLR60sBSoGCw8JVD1crGbwtbwAcms1qvVZkFju0Z7yRrf4+7E5RJwuGC4b8a+WV5qeHulhTsKtQIe08Nc3qz4Lq1nPHF8M7eT0/yaxNXFLe5ebgJvCBPj7oV8rc5vtvJnog4nI8H45OXw6p7CZTFCKu+BS6e1PKtDxFBSwzrIsRqyGYePLGfj9yW5oczXztdaHMEVNggbtol8fS8eXQzvhMRWjII1AgYpFPNW3CWY+oF9a+ar+AJ7oPQxSFZcifHZfR6x+vjcGKphbyB3XGadd9WvpfrJJszr1OtYS9Gwag8Wjr682RFuqqrYqp0RYkPn957XuHq3JBY0id7Ncs0pXGdzlWu2c47qqZmW+S6T2rkp5hbHnpbu16zmPjRGfs39exQrEtk1qc6tqLGLCg9G2fpTyL3PAS1+QKlFhQchoGcfNuUejfjjm+EAR6O+HXs2u5WiQO0JC7ASYeFtrtK7H17w3rgLc1OT4+9mQqCB7qydq+g854ewiI6a2w8gBNZOmaSEnW6c7TeOMa8bRshsCZE7AKPWE/Hgv8XwXn93fEREhgQgJlM4TlHP2oqzvVsvdA4pew1491RxobsbR9nHL46V/iR74CJeIKFUpuR0OTqnLSTuN0b8ZGsXUwG2p9fBgtxTZV5wZwzsj0N+GD0T61LibObmmp0nXVJ7vZl0mqp7YI0MDJY8Zx/uOx+3VmWuqeaWMGB1zY9u6SImuIbtmUYy7YNqRVOmlRq3ZYHMbpBjBNTDRczoftT8fjzdaOdvy6eBUAMD4G1vq/v2u8aNrHiGnZb0ojwoFKlxTfqK61tRpvcjrEdTc1UnF5F82Gz68uz3G39RS9jDf3s1jsffNgbhDpD+Pu4yzejy5sbykfv1AF9zeoR5+fSxdshxOnSPNKZa9CWNwWpJJ3yjfv+/tgKWjr9cUEOjZhcIxkDY7kASqP9S4y9SqlGPA8b/H0x1e9/A5BieV6HdK3O9X7Dsl+vpN7RKwZ8IAt5m+XV0uu5amX86w7i+HdkJynTBduwPwjJp+dOT2vFIzDbqKE9Wxv4S/xjM9NSkKT/bRno5ZvN1X/g55cWAL+NlsuL2D59EDYk+p2ZMHyf4uT8S2hXXiueToGphyV3umZRDz4yPX4XjBZaREm59PRg6tnTX1rOkJCfTHvKe6AzBmagilIkMDseHlvggO8EfPd5c7vVcpf+qbahwHCHjCoo+Kx3U6/LukXHpHKP0NHWu0QmTUQGa0jENGS9/pGE+BCiMrx/byuIy780yqpsOx3bxrY215M96/s50uVdBaLxiRoYGYeJv2uTDUUt0ZkEEAI+crjZh6QExwgD+3QYqZ5B4GLPuNiQXgseHiKf5Tk6JwrEDexISAS+4Rp2HPnj4o+ysMWcGLA5tj8l97McWEIf0p0TUwJC0J0TWD3QbQvHW6NYthTT8TJ05E165dERYWhqioKNFlcnJyMGjQIISFhSE2NhZjx45FeXm5UUXiSoM6ni/gYje6JaN74s1bWmFouviQx4iQa08skm3gMg92o3JR3K4yr4JRXHfH/Kd7KPu8Dejf+srIoFYJER6WZsPxRmRWoEKkKZmMkDdqE+QpxaKPiuN58mC3FOx9c4A9HQJg3MOHzWbDxNva4Nl/NTVk/VZnWI1KaWkp7rzzTqSnp+Orr76q9n5FRQUGDRqE+Ph4/P333zhx4gSGDh2KwMBAvP3220YVy1LE7ieNY8PdppTm8QLo+rTWq3ksDpwsZlOYq+rXCsPePPHkXC1dgg1PFyc/mw11I0Ox/fV+qMFg+K8jORd31k1VvkZsb2flFphdDLeUpCGQO9rJE0/HqtbBBFrZbPKaYXjFQ2YJvRhWo/LGG2/g2WefRZs24lX2ixYtwu7du/Hdd9+hffv2GDhwIN58801MnToVpaWlRhVLk9s81AToff1XdaJa4CZkA/se6RGh+gUUN7W7kpkzIiTQtNqKNA0JwqhGxTi1wqr3wTDinGQ5fYTSb1abdp5FHxVPn2F95nhT8KEEs1E/mZmZaNOmDeLirlWr9e/fH0VFRdi1a5fk50pKSlBUVOT0ZxZPtRXuszkqP8J4HJ7nLaom7IsJD/awpGeP9BTPkCt10bu9Qz083beJqu9a8VwvvHVrazwskZVXcniyw78dAxU5HZRZsOoFua9I8kAjkibqcdw6UlJCpQGA1HXMY1AgskDb+vL78dDV03swq6fOy8tzClIA2P+fl5cn+blJkybhjTfeMLRs3NB6pklcfeQEQP++N1Xjl/Mto0Us5jzRFQ1jauKr1YfcLutpbynN3qhlhE5ydA0ku+mgKueQcXwan3R7G8zeckx1eYiXUBRLmRMCiH0Li6HbVmWBynXZFF1hX3zxRdhsNrd/e/fuNaqsAIBx48ahsLDQ/pebm2vo9zny/ASg8/fptB41E0sZeUEws4/ECwOai75us9mQmlQLkaGeh0s6FjchSnwkBC/aX81dUo1jJ0GH/A7BAf4Yc7UD3zCJDtpEGyOafqxU4yTV9KMmj4qiaXBU7HdP+9VKN38rHSOeKLobjRkzBsOHD3e7TMOG8iaKi4+Px4YNG5xey8/Pt78nJTg4GMHB+lZ7ymX2Mar5hi7y8faJUWgW73mSRD0vrq7ni5nN6+mNtA3RdpWaVAsTb2uNU+dL8NGSA26XZXFN690sFlPv7eD2N06IdJ4y4Mk+jTGwTV00pKHEmon95la4ubm7p0WFBaLwUpn9/8qbftQRq/lVUnvpOG0EsTZFgUpMTAxiYqrPHqtGeno6Jk6ciJMnTyI29socNosXL0ZERARattQ/9bAetASoretFYv4O6SYtMUZc4OY80ZV5h1szvn7ZmOuRe+6SvFFQCgs0JK0BNmWf9RiosGCz2TBIpAbNXR8pm82mayZSX+a6lx/uIT87Ka8+u68jnvtlG57r1wyAms601z7hdByqyKOi5Ls7NqilYOmr61fRb4YYz7DOtDk5OcjKykJOTg4qKiqQlZWFrKwsFBdfGZbar18/tGzZEvfffz+2bduGhQsX4pVXXsHIkSOZ1ZioUTdSXlPAiO4pqKEwW6HmzrQi9yYmSchEXjG6WrJhTE1c31RmUO1NdaREVz88lKbp86lJtSzfqbNF3Qj8+XQP9G5+5YFS6TXEsQZV0agf0aYfq+9NooZhgcr48eORmpqK1157DcXFxUhNTUVqaio2bdoEAPD398e8efPg7++P9PR03HfffRg6dCgmTJhgVJE0cz3Jbk+th+8dLmTuAovgAH88er30fDNi1OUR4A/Lph89WKy4REddG6uftLCKFcJgJSOTlJ6/UsGFxzwqyr7Gq0XXvNKMpaaWyBsY1mNy5syZmDlzpttlGjRogPnz5xtVBMO5plbWKxFSFZYnqpHf7WczvkZFT6qf4jh6+rPS/vYmggBU6jkVsUHG9m+G1//Yjfuu8zyBZKsE9an+KxUciFR7cs3aF/vgcmklIkXy9EgJDvCeOYdprJcCnp46agQH4I2bW2HR7jxszy3EB3e10/aFKs5TsRLydpm02ZRdsHjkzddQm40CG18zvFsK+jSPQ2LtUI/LakkYmFQ7zP5vNcnVvPi0cys4wB/BCrPk/l/HRMzNOm5QicxFgYoCcq7dw7omY1jXZFRWCtUml1J6gktNCmY1rjc9Txeo7jpUtyuh5p5stRu5xYrr9RJk9m2TYkRm56Q6YZ4XUmnDS31xuawSUWHyR+J488OAGYIDqUbFJym5OYnNgHl/egPM2XoMA1pJD7921Di2Jt65ow2ia8rvXGyFpxAbbKI1KuEhAfjv0E6SM0NbDU/7nWYxZkfsslHLx4bOxkZUD8w8D/rh6QwiLFGgYqKIkEAsGX29os/c3dlzm7Enap699HyaqbYuiaaFAD8brmuob94TPVg1NwYA/O/xrvjflqN4vn8z+2tdGl6ZJ6hhDL/BS5M47xkuLXasW+X4YYn2EalCgYoHIYHX2gWtNlpFCz2fZqo1/cBiTREW/t07NqhVbaRAREggdk/ojyCJ5Fk8/D6tEiIxfXgnJER57jNhtOsa1sa6Q2dZF8PJ1Hs7YPiMjXhlUAvWRVFNTWdZs7ODW5nVmqfdoUDFA8fJvwIt1oua1+PU38+GhtE1cPBkMeuiAPB8QndvHO118+GEBfF/6vdpXn2CP6sRDJonvFNybWx/rZ9oE7O3UBN01FLQB0aM44OpJ3V8rPmOJf6vVhyxQoQaFRaILsm1USEIiL0aZKUmRuHP7ScYl+waP5sND3ZPwaLd+U6v8zoc8db29VAjOABt6qkflkmsq4YBQZ0eNZZWD1I8lV7NFCLjb2qJ08UlGNY1WVWZ6kWFYmTvRqgRHOAxXT+nlys73sunBAUqClggToHNZsNPj15n/zdwZSRSUIAfuuo8741crs+UNiifcZglPz8b+svsAO3Imy4Uvuz1m1vheOFl3NI+AZP/cj/p6q3t6+HXzUedXlOSTI1cI36NcH9SxUWE4KdH0zV979j+4hOZKi0L0Y917hY8sMgFp2om6yqB/n4Ymp6MxrGeJyO8tg79yiOeyr76vqTTng+81myxklg7DH890wOPycgs3b1JtKwO87SLaR8Yzd3tSul0LqxRjYpCESEBKLpczroYlpKW4lKTw1lCMXe9CMKD1Z8iNLzSN8mZ4JGODOuzYqD1RK9GuFBSjvvTk1kXRRGqUVGAo3urpVRv+rFZZ19a8GJE+DKgtfJmQ18gFcgP75qMDS/1Ff8MnY+axEeG4I1bWltutnQKVBTgqRbASlz3W7vESNH5T+giRLyNIAB1alhnNngepCZFiSaII76LAhUFfOlGquemOoYkU+/tgLCgAOvUqPggHzrMTSF63fCli4kUi+8CixffUqiPigI8JMIyjY5noWPtScjV+Sd4mpSwZrD8GUmvUb6DkuuE4aEeDVV8FyG+w11nbp6CA4o1zUOBChFl1BThDWOutI1WzedTv1Yojp67dPVdNmf+sK4N8Pc/p9Gvpb4JxpJdJnlbMba3rusn1kX3OOvf6HnvLO9Nw+IpUFEgONCf80NTu2f6NkH2mQvokFTL88IyOdae1L06a2yN4ADsmTAAAf42NHn5L92+S42woAB8OyJN0WfkdEZLZ5S3hvDF6jdkQlijQEWG5/o1xd//nMEt7RPw1rzdrItjqGf/1VT3dToG9o4X7VCXsfw8XtClihQZGoiNL2e4nUrdZrOhaVxN7M/nY6oAuXj8HaxKABDgR10Bxag5zOjY9E10BsnwZJ8m+OHh6xAc4O87fVR05LjPxNJi35t2ZYbosf2aVXuPZzHhwYgIcd+/xXGuKOKb/P1smP90D8wd2c3+Gt1wrY9+Q/NQjQoxnGPTj9i5PfHW1niqT2PUjWQ/U26V6JpBOF1ciusaamu+eeeOtnhpzk481D1Fp5IRlvo2j8XSvScVf65lQoQBpbE2q2dAtnbprYUCFWI4x6YfsRoVm83GVZACAHOe6Ia5W4/h/vQGmtZTv1YYvnmwi06lIqzpdW+lm5w0d/uG9w6svLNq/1pq+iGGqxV2rXnEKg9RibXD8FTfJojSOG28FdHNQD/eNPJCb0qOskd7NoS/nw2j++nfh47wj2pUiOHq1AzG1w92QUiAn+Wre31B7RpByCu6zLoYxAfFR4Sgb4vYaq+Pu6EFnuvfzFKzrrPmTSEy/erEFNc3jUGaxv4exBzTh3dG+8Qo/PCQsiHbRD4K2MWtfbEPwoLEn595C1LoNzQP1agQQpy0TIhwGqFC9Ee3OHH+frRnSHV8haiEEMIxpV1OQgP9PS/ko7ypaYJH3tQ9impUCCFEZ+MGNse2owXo20J8WgartxokRIbgeCH1YyLmoECFEEJ09uj1jVgXwVCdkmvj923HNa2DRkQZy+rBsCNq+lGKzi1CCCHENBSoEEKIyShXjfWf+YIMmmFeL95UYcX3niaEEOKVAiw+wqdnk2jWRfAZFKgoZe1zixDCgfq1+JoyggWpfClWwVteF29m2J6eOHEiunbtirCwMERFRYkuY7PZqv3NmjXLqCLpw4uq0wgh5vrhoTTc2j4Br9zYknVRNPGmjppqWXEfWLUDs2EhbWlpKe68806kp6fjq6++klxuxowZGDBggP3/UkENL6z5MxNCeNC1cTS6NqYmA29AmWnNY1ig8sYbbwAAZs6c6Xa5qKgoxMfHG1UM3Vk1IiWEEOLbrBpcMW9kGzlyJKKjo9GlSxdMnz7dYyBQUlKCoqIipz9CCDFDalIU6yJwwZq3O33xvg8Ekfp/qz5oM+3NNGHCBPTp0wdhYWFYtGgRnnjiCRQXF+Ppp5+W/MykSZPstTUsWPNnJoTo4eGeDREaFIDrm/p2882Yfs2w5uAZDEtvwLoozNSpGcS6CD5DUaDy4osv4p133nG7zJ49e9C8eXNZ63v11Vft/05NTcWFCxfw3nvvuQ1Uxo0bh9GjR9v/X1RUhMTERFnfpweLBqSEEB0EB/hjRPcU1sVgLrF2GDa+3NeyTQlafDo4FUv35GNoejLrovgMRYHKmDFjMHz4cLfLNGzYUHVh0tLS8Oabb6KkpATBwcGiywQHB0u+Zwax6jRCCPE1vhikAMBN7RJwU7sE1sXwKYoClZiYGMTExBhVFmRlZaFWrVpMAxFPqEaFEEII79onRsFmA5Lr1MDh0xdYF0cTw/qo5OTk4OzZs8jJyUFFRQWysrIAAI0bN0bNmjXxxx9/ID8/H9dddx1CQkKwePFivP3223juueeMKpIuwkMCUFJcyroYhBBCiKSwoADsmTAAAX42NH75LwDWrQUzLFAZP348vv76a/v/U1NTAQDLly9Hr169EBgYiKlTp+LZZ5+FIAho3LgxpkyZgocfftioIuli+vDOGP3zNrx0g7x+OIQQQggLIYH+rIugC8MClZkzZ7rNoTJgwACnRG9W0bZ+FJaMvp51MQghhBBFLFqhwj6PCiGEEEKIFApUCCGEEMItClQIIYQQwi0KVAghhBAfYNEuKhSoEEIIIYRfFKgQQgghhFsUqBBCCCG+wKLjkylQIYQQQgi3KFAhhBDCXICfNZ/2rcSqe5gCFUIIIczNfqIr6yIQTlGgQgghhKkBreLRtn4U62IQTlGgQgghhPgAi/alpUCFEEIIIfyiQIUQQgjxATaLdqelQIUQQggh3KJAhRBCCCHcokCFEEII8QF1I0NYF0GVANYFIIQQQohxpg/vhJ3HitCrWQzroqhCgQohhBDixfo0j0Of5nGsi6EaNf0QQgghhFsUqBBCCGHKqonIiDkoUCGEEEIItyhQIYQQQgi3KFAhhBBCCLcoUCGEEEIItyhQIYQQwhR1piXuUKBCCCGEEG5RoEIIIYSpDkm1WBeBcIwy0xJCCGFi+XO9kPnPGdzZqT7rohCOUaBCCCGEiZToGkiJrsG6GIRz1PRDCCGEEG4ZFqhkZ2djxIgRSElJQWhoKBo1aoTXXnsNpaWlTstt374dPXr0QEhICBITE/Huu+8aVSRCCCGEWIxhTT979+5FZWUlPv/8czRu3Bg7d+7Eww8/jAsXLuD9998HABQVFaFfv37IyMjAZ599hh07duDBBx9EVFQUHnnkEaOKRgghhBCLsAmCIJj1Ze+99x6mTZuGQ4cOAQCmTZuGl19+GXl5eQgKCgIAvPjii5g7dy727t0ra51FRUWIjIxEYWEhIiIiDCs7IYQQQvQj9/5tah+VwsJC1K5d2/7/zMxM9OzZ0x6kAED//v2xb98+nDt3TnQdJSUlKCoqcvojhBBCiHcyLVA5ePAgPv30Uzz66KP21/Ly8hAXF+e0XNX/8/LyRNczadIkREZG2v8SExONKzQhhBBCmFIcqLz44ouw2Wxu/1ybbY4dO4YBAwbgzjvvxMMPP6ypwOPGjUNhYaH9Lzc3V9P6CCGEEMIvxZ1px4wZg+HDh7tdpmHDhvZ/Hz9+HL1790bXrl3xxRdfOC0XHx+P/Px8p9eq/h8fHy+67uDgYAQHBystNiGEEEIsSHGgEhMTg5iYGFnLHjt2DL1790bHjh0xY8YM+Pk5V+Ckp6fj5ZdfRllZGQIDAwEAixcvRrNmzVCrFqVUJoQQQnydYX1Ujh07hl69eiEpKQnvv/8+Tp06hby8PKe+J/feey+CgoIwYsQI7Nq1Cz/99BM+/vhjjB492qhiEUIIIcRCDMujsnjxYhw8eBAHDx5E/frO8zhUjYiOjIzEokWLMHLkSHTs2BHR0dEYP3485VAhhBBCCACT86gYgfKoEEIIIdbDZR4VQgghhBAlLD97clWFECV+I4QQQqyj6r7tqWHH8oHK+fPnAYASvxFCCCEWdP78eURGRkq+b/k+KpWVlTh+/DjCw8Nhs9l0XXdRURESExORm5vrU/1faLtpu32Fr247bbdvbTfA57YLgoDz588jISGhWvoSR5avUfHz86s2qkhvERER3PywZqLt9i2+ut2A7247bbfv4W3b3dWkVKHOtIQQQgjhFgUqhBBCCOEWBSpuBAcH47XXXvO5uYVou2m7fYWvbjttt29tN2Dtbbd8Z1pCCCGEeC+qUSGEEEIItyhQIYQQQgi3KFAhhBBCCLcoUCGEEEIItyhQkTB16lQkJycjJCQEaWlp2LBhA+siyTZp0iR07twZ4eHhiI2Nxa233op9+/Y5LXP58mWMHDkSderUQc2aNXHHHXcgPz/faZmcnBwMGjQIYWFhiI2NxdixY1FeXu60zIoVK9ChQwcEBwejcePGmDlzptGbJ9vkyZNhs9kwatQo+2vevN3Hjh3Dfffdhzp16iA0NBRt2rTBpk2b7O8LgoDx48ejbt26CA0NRUZGBg4cOOC0jrNnz2LIkCGIiIhAVFQURowYgeLiYqdltm/fjh49eiAkJASJiYl49913Tdk+MRUVFXj11VeRkpKC0NBQNGrUCG+++abT3CHest2rVq3CTTfdhISEBNhsNsydO9fpfTO385dffkHz5s0REhKCNm3aYP78+bpvbxV3211WVoYXXngBbdq0QY0aNZCQkIChQ4fi+PHjTuvwtu129dhjj8Fms+Gjjz5yet2K2y1KINXMmjVLCAoKEqZPny7s2rVLePjhh4WoqCghPz+fddFk6d+/vzBjxgxh586dQlZWlnDDDTcISUlJQnFxsX2Zxx57TEhMTBSWLl0qbNq0SbjuuuuErl272t8vLy8XWrduLWRkZAhbt24V5s+fL0RHRwvjxo2zL3Po0CEhLCxMGD16tLB7927h008/Ffz9/YUFCxaYur1iNmzYICQnJwtt27YVnnnmGfvr3rrdZ8+eFRo0aCAMHz5cWL9+vXDo0CFh4cKFwsGDB+3LTJ48WYiMjBTmzp0rbNu2Tbj55puFlJQU4dKlS/ZlBgwYILRr105Yt26dsHr1aqFx48bC4MGD7e8XFhYKcXFxwpAhQ4SdO3cKP/74oxAaGip8/vnnpm5vlYkTJwp16tQR5s2bJxw+fFj45ZdfhJo1awoff/yxfRlv2e758+cLL7/8sjB79mwBgDBnzhyn983azrVr1wr+/v7Cu+++K+zevVt45ZVXhMDAQGHHjh2mb3dBQYGQkZEh/PTTT8LevXuFzMxMoUuXLkLHjh2d1uFt2+1o9uzZQrt27YSEhAThww8/dHrPitsthgIVEV26dBFGjhxp/39FRYWQkJAgTJo0iWGp1Dt58qQAQFi5cqUgCFdO7sDAQOGXX36xL7Nnzx4BgJCZmSkIwpWTxM/PT8jLy7MvM23aNCEiIkIoKSkRBEEQnn/+eaFVq1ZO33X33XcL/fv3N3qT3Dp//rzQpEkTYfHixcL1119vD1S8ebtfeOEFoXv37pLvV1ZWCvHx8cJ7771nf62goEAIDg4WfvzxR0EQBGH37t0CAGHjxo32Zf766y/BZrMJx44dEwRBEP7zn/8ItWrVsu+Lqu9u1qyZ3psky6BBg4QHH3zQ6bXbb79dGDJkiCAI3rvdrjcuM7fzrrvuEgYNGuRUnrS0NOHRRx/VdRvFuLthV9mwYYMAQDhy5IggCN693UePHhXq1asn7Ny5U2jQoIFToOIN212Fmn5clJaWYvPmzcjIyLC/5ufnh4yMDGRmZjIsmXqFhYUAgNq1awMANm/ejLKyMqdtbN68OZKSkuzbmJmZiTZt2iAuLs6+TP/+/VFUVIRdu3bZl3FcR9UyrPfTyJEjMWjQoGpl8+bt/v3339GpUyfceeediI2NRWpqKv773//a3z98+DDy8vKcyh0ZGYm0tDSnbY+KikKnTp3sy2RkZMDPzw/r16+3L9OzZ08EBQXZl+nfvz/27duHc+fOGb2Z1XTt2hVLly7F/v37AQDbtm3DmjVrMHDgQADeu92uzNxOHo9/R4WFhbDZbIiKigLgvdtdWVmJ+++/H2PHjkWrVq2qve9N202BiovTp0+joqLC6UYFAHFxccjLy2NUKvUqKysxatQodOvWDa1btwYA5OXlISgoyH4iV3Hcxry8PNF9UPWeu2WKiopw6dIlIzbHo1mzZmHLli2YNGlStfe8ebsPHTqEadOmoUmTJli4cCEef/xxPP300/j6668BXCu7u+M6Ly8PsbGxTu8HBASgdu3aivaPmV588UXcc889aN68OQIDA5GamopRo0ZhyJAhTmXytu12ZeZ2Si3Dw364fPkyXnjhBQwePNg+8Z63bvc777yDgIAAPP3006Lve9N2W372ZOLeyJEjsXPnTqxZs4Z1UQyXm5uLZ555BosXL0ZISAjr4piqsrISnTp1wttvvw0ASE1Nxc6dO/HZZ59h2LBhjEtnnJ9//hnff/89fvjhB7Rq1QpZWVkYNWoUEhISvHq7SXVlZWW46667IAgCpk2bxro4htq8eTM+/vhjbNmyBTabjXVxDEc1Ki6io6Ph7+9fbSRIfn4+4uPjGZVKnSeffBLz5s3D8uXLUb9+ffvr8fHxKC0tRUFBgdPyjtsYHx8vug+q3nO3TEREBEJDQ/XeHI82b96MkydPokOHDggICEBAQABWrlyJTz75BAEBAYiLi/PK7QaAunXromXLlk6vtWjRAjk5OQCuld3dcR0fH4+TJ086vV9eXo6zZ88q2j9mGjt2rL1WpU2bNrj//vvx7LPP2mvUvHW7XZm5nVLLsNwPVUHKkSNHsHjxYnttCuCd27169WqcPHkSSUlJ9mvdkSNHMGbMGCQnJ9vL6y3bTYGKi6CgIHTs2BFLly61v1ZZWYmlS5ciPT2dYcnkEwQBTz75JObMmYNly5YhJSXF6f2OHTsiMDDQaRv37duHnJwc+zamp6djx44dTgd61QWg6oaYnp7utI6qZVjtp759+2LHjh3Iysqy/3Xq1AlDhgyx/9sbtxsAunXrVm0I+v79+9GgQQMAQEpKCuLj453KXVRUhPXr1ztte0FBATZv3mxfZtmyZaisrERaWpp9mVWrVqGsrMy+zOLFi9GsWTPUqlXLsO2TcvHiRfj5OV/G/P39UVlZCcB7t9uVmdvJ2/FfFaQcOHAAS5YsQZ06dZze98btvv/++7F9+3ana11CQgLGjh2LhQsX2svrNdttWrddC5k1a5YQHBwszJw5U9i9e7fwyCOPCFFRUU4jQXj2+OOPC5GRkcKKFSuEEydO2P8uXrxoX+axxx4TkpKShGXLlgmbNm0S0tPThfT0dPv7VcN0+/XrJ2RlZQkLFiwQYmJiRIfpjh07VtizZ48wdepU5sN0XTmO+hEE793uDRs2CAEBAcLEiROFAwcOCN9//70QFhYmfPfdd/ZlJk+eLERFRQm//fabsH37duGWW24RHb6ampoqrF+/XlizZo3QpEkTp+GMBQUFQlxcnHD//fcLO3fuFGbNmiWEhYUxG548bNgwoV69evbhybNnzxaio6OF559/3r6Mt2z3+fPnha1btwpbt24VAAhTpkwRtm7dah/dYtZ2rl27VggICBDef/99Yc+ePcJrr71m6HBVd9tdWloq3HzzzUL9+vWFrKwsp+ud40gWb9tuMa6jfqy63WIoUJHw6aefCklJSUJQUJDQpUsXYd26dayLJBsA0b8ZM2bYl7l06ZLwxBNPCLVq1RLCwsKE2267TThx4oTTerKzs4WBAwcKoaGhQnR0tDBmzBihrKzMaZnly5cL7du3F4KCgoSGDRs6fQcPXAMVb97uP/74Q2jdurUQHBwsNG/eXPjiiy+c3q+srBReffVVIS4uTggODhb69u0r7Nu3z2mZM2fOCIMHDxZq1qwpRERECA888IBw/vx5p2W2bdsmdO/eXQgODhbq1asnTJ482fBtk1JUVCQ888wzQlJSkhASEiI0bNhQePnll51uUt6y3cuXLxc9r4cNGyYIgrnb+fPPPwtNmzYVgoKChFatWgl//vknk+0+fPiw5PVu+fLlXrvdYsQCFStutxibIDikcCSEEEII4Qj1USGEEEIItyhQIYQQQgi3KFAhhBBCCLcoUCGEEEIItyhQIYQQQgi3KFAhhBBCCLcoUCGEEEIItyhQIYQQQgi3KFAhhBBCCLcoUCGEEEIItyhQIYQQQgi3KFAhhBBCCLf+H3I5Ezg0wVAmAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get sequence length/length of each signal\n",
        "left_len = left_hand[0].shape[1]\n",
        "right_len = right_hand[0].shape[1]\n",
        "# portion of sequence used for validation/testing set\n",
        "left_eval_len = int(0.4 * left_hand[0].shape[1])\n",
        "right_eval_len = int(0.4 * right_hand[0].shape[1])\n",
        "\n",
        "# select random starting indexes for sub-sequences for validation and testing sets\n",
        "left_hand_partition = np.random.randint(0, left_len - left_eval_len, len(left_hand))\n",
        "right_hand_partition = np.random.randint(0, right_len - right_eval_len, len(right_hand))\n",
        "\n",
        "# initialize lists to hold respective signals\n",
        "left_train = []\n",
        "left_val = []\n",
        "left_test = []\n",
        "right_train = []\n",
        "right_val = []\n",
        "right_test = []\n",
        "\n",
        "# create training, validation, and testing sets for left hand signals\n",
        "for i, num in enumerate(left_hand_partition):\n",
        "  # get ending index of subsequence being cropped for validation and testing sets\n",
        "  upper_end = num + left_eval_len\n",
        "  # add portion of sequence excluding num:upper_end (portion used for evaluation)\n",
        "  left_train.append(left_hand[i][:, list(range(num)) + list(range(upper_end, left_len))])\n",
        "  # first half of subsequence used for validation\n",
        "  left_val.append(left_hand[i][:, num:num+(left_eval_len//2)])\n",
        "  # second half used for test set\n",
        "  left_test.append(left_hand[i][:, num+(left_eval_len//2):num + left_eval_len])\n",
        "\n",
        "# create training, validation, and testing sets for right hand signals\n",
        "for i, num in enumerate(right_hand_partition):\n",
        "  # get ending index of subsequence being cropped for validation and testing sets\n",
        "  upper_end = num + right_eval_len\n",
        "  # add portion of sequence excluding num:upper_end (portion used for evaluation)\n",
        "  right_train.append(right_hand[i][:, list(range(num)) + list(range(upper_end, right_len))])\n",
        "  # first half of subsequence used for validation\n",
        "  right_val.append(right_hand[i][:, num:num+(right_eval_len//2)])\n",
        "  # second half used for test set\n",
        "  right_test.append(right_hand[i][:, num+(right_eval_len//2):num + right_eval_len])"
      ],
      "metadata": {
        "id": "ctuLqCHR810Q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to bandpass filter signals\n",
        "def bandpass_filter(signal, crit_freq = [5, 40], sampling_freq = 125):\n",
        "  order = 4\n",
        "  b, a = scipy.signal.butter(order, crit_freq, btype = 'bandpass', fs = sampling_freq)\n",
        "  processed_signal = scipy.signal.filtfilt(b, a, signal, 1)\n",
        "  return processed_signal\n",
        "\n",
        "# segment a signal using sliding window technique, specifying sample frequency, window size, and window shift\n",
        "def segmentation(signal, sampling_freq=125, window_size=1, window_shift=0.016):\n",
        "  w_size = int(sampling_freq * window_size)\n",
        "  w_shift = int(sampling_freq * window_shift)\n",
        "  segments = []\n",
        "  i = 0\n",
        "  while i + w_size <= signal.shape[1]:\n",
        "    segments.append(signal[:, i: i + w_size])\n",
        "    i += w_shift\n",
        "  return segments\n",
        "\n",
        "# apply preprocessing steps in sequence to each signal\n",
        "def preprocess(signals, crit_freq=[5,35], fs=250):\n",
        "  preprocessed = []\n",
        "  for signal in signals:\n",
        "    # perform bandpass filter on each signal\n",
        "    filtered_signal = bandpass_filter(signal, crit_freq, fs)\n",
        "    # channel-wise z-score normalization\n",
        "    normed_signal = (filtered_signal - filtered_signal.mean(1, keepdims=True)) / filtered_signal.std(1, keepdims=True)\n",
        "    # segmentation of signals\n",
        "    segments = segmentation(normed_signal, fs)\n",
        "    # add signals to list\n",
        "    preprocessed.extend(segments)\n",
        "  return preprocessed"
      ],
      "metadata": {
        "id": "C-2GU3H-85B2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate preprocessed segments for training, validation, and testing\n",
        "train_left = preprocess(left_train)\n",
        "val_left = preprocess(left_val)\n",
        "test_left = preprocess(left_test)\n",
        "train_right = preprocess(right_train)\n",
        "val_right = preprocess(right_val)\n",
        "test_right = preprocess(right_test)\n",
        "\n",
        "# print number of samples corresponding to left and right hand targets\n",
        "print(f'left samples: {len(train_left) + len(val_left) + len(test_left)}, right samples: {len(train_right) + len(val_right) + len(test_right)}')\n",
        "# print shape of each sample\n",
        "print(f'segment shape: {train_left[0].shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqGRsmos87BG",
        "outputId": "e65d65e1-1f57-4ba7-a4d8-ec6d52a6e999"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "left samples: 30897, right samples: 30897\n",
            "segment shape: (16, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combine left and right signals to generate signal training, validation, and testing set\n",
        "train_eeg = train_left + train_right\n",
        "val_eeg = val_left + val_right\n",
        "test_eeg = test_left + test_right\n",
        "train_labels = [0 for i in range(len(train_left))] + [1 for i in range(len(train_right))]\n",
        "val_labels = [0 for i in range(len(val_left))] + [1 for i in range(len(val_right))]\n",
        "test_labels = [0 for i in range(len(test_left))] + [1 for i in range(len(test_right))]"
      ],
      "metadata": {
        "id": "zb7kkfAd8-fQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create torch tensor of zeros to hold data\n",
        "train_eeg_tensor = torch.zeros((len(train_eeg), train_eeg[0].shape[0], train_eeg[0].shape[1]))\n",
        "valid_eeg_tensor = torch.zeros((len(val_eeg), val_eeg[0].shape[0], val_eeg[0].shape[1]))\n",
        "test_eeg_tensor = torch.zeros((len(test_eeg), test_eeg[0].shape[0], test_eeg[0].shape[1]))\n",
        "\n",
        "# add each sample in train, validation, and test lists to appropriate tensor at correct index\n",
        "for i in range(len(train_eeg)):\n",
        "  tens = torch.from_numpy(train_eeg[i].copy())\n",
        "  train_eeg_tensor[i] = tens\n",
        "for i in range(len(val_eeg)):\n",
        "  tens = torch.from_numpy(val_eeg[i].copy())\n",
        "  valid_eeg_tensor[i] = tens\n",
        "for i in range(len(test_eeg)):\n",
        "  tens = torch.from_numpy(test_eeg[i].copy())\n",
        "  test_eeg_tensor[i] = tens\n",
        "\n",
        "# create zero tensor for one hot encoded labels\n",
        "#train_labels should now equal 12\n",
        "train_label_tensor = torch.zeros(len(train_labels), 2)\n",
        "valid_label_tensor = torch.zeros(len(val_labels), 2)\n",
        "test_label_tensor = torch.zeros(len(test_labels), 2)\n",
        "\n",
        "\n",
        "# add labels to tensor at correct index\n",
        "for i in range(len(train_labels)):\n",
        "  label = train_labels[i]\n",
        "  train_label_tensor[i][label] = 1\n",
        "for i in range(len(val_labels)):\n",
        "  label = val_labels[i]\n",
        "  valid_label_tensor[i][label] = 1\n",
        "for i in range(len(test_labels)):\n",
        "  label = test_labels[i]\n",
        "  test_label_tensor[i][label] = 1\n",
        "\n",
        "# convert input, target tensors to Tensor Dataset from torch\n",
        "train_ds = TData(train_eeg_tensor, train_label_tensor)\n",
        "valid_ds = TData(valid_eeg_tensor, valid_label_tensor)\n",
        "test_ds = TData(test_eeg_tensor, test_label_tensor)\n",
        "# create dataloaders to hold batched data (batch size chosen was 64)\n",
        "train_dl = DL(train_ds, batch_size=64, shuffle= True, drop_last = True)\n",
        "valid_dl = DL(valid_ds, batch_size=64, shuffle= True, drop_last = True)\n",
        "test_dl = DL(test_ds, batch_size=64, shuffle = True, drop_last = True)\n",
        "\n",
        "for i, (data, label) in enumerate(train_ds):\n",
        "  print(f\"Sample {i + 1}:\")\n",
        "  print(f\"Data shape: {data.shape}\")\n",
        "  print(data[0])\n",
        "  print(f\"Label shape: {label.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyXzaGkI9ds9",
        "outputId": "a4ebf1e3-a4f2-4f45-8d50-9892d4379974"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37852:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.7928,  0.8173,  0.8205,  0.6821,  0.3248, -0.2271, -0.8425, -1.3422,\n",
            "        -1.5874, -1.5453, -1.2946, -0.9757, -0.7188, -0.5903, -0.5794, -0.6225,\n",
            "        -0.6434, -0.5877, -0.4347, -0.1889,  0.1364,  0.5273,  0.9622,  1.3980,\n",
            "         1.7625,  1.9652,  1.9260,  1.6113,  1.0599,  0.3835, -0.2646, -0.7468,\n",
            "        -0.9952, -1.0333, -0.9499, -0.8434, -0.7712, -0.7320, -0.6849, -0.5872,\n",
            "        -0.4251, -0.2214, -0.0157,  0.1685,  0.3438,  0.5475,  0.8008,  1.0691,\n",
            "         1.2562,  1.2449,  0.9637,  0.4398, -0.1948, -0.7481, -1.0434, -0.9923,\n",
            "        -0.6365, -0.1393,  0.2786,  0.4345,  0.2647, -0.1537, -0.6519, -1.0553,\n",
            "        -1.2554, -1.2319, -1.0305, -0.7197, -0.3592,  0.0079,  0.3429,  0.5995,\n",
            "         0.7297,  0.7075,  0.5556,  0.3519,  0.2059,  0.2120,  0.4039,  0.7320,\n",
            "         1.0763,  1.2876,  1.2465,  0.9182,  0.3857, -0.1654, -0.5187, -0.5350,\n",
            "        -0.2378,  0.1879,  0.4951,  0.5099,  0.2128, -0.2772, -0.7895, -1.1914,\n",
            "        -1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37853:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.3248, -0.2271, -0.8425, -1.3422, -1.5874, -1.5453, -1.2946, -0.9757,\n",
            "        -0.7188, -0.5903, -0.5794, -0.6225, -0.6434, -0.5877, -0.4347, -0.1889,\n",
            "         0.1364,  0.5273,  0.9622,  1.3980,  1.7625,  1.9652,  1.9260,  1.6113,\n",
            "         1.0599,  0.3835, -0.2646, -0.7468, -0.9952, -1.0333, -0.9499, -0.8434,\n",
            "        -0.7712, -0.7320, -0.6849, -0.5872, -0.4251, -0.2214, -0.0157,  0.1685,\n",
            "         0.3438,  0.5475,  0.8008,  1.0691,  1.2562,  1.2449,  0.9637,  0.4398,\n",
            "        -0.1948, -0.7481, -1.0434, -0.9923, -0.6365, -0.1393,  0.2786,  0.4345,\n",
            "         0.2647, -0.1537, -0.6519, -1.0553, -1.2554, -1.2319, -1.0305, -0.7197,\n",
            "        -0.3592,  0.0079,  0.3429,  0.5995,  0.7297,  0.7075,  0.5556,  0.3519,\n",
            "         0.2059,  0.2120,  0.4039,  0.7320,  1.0763,  1.2876,  1.2465,  0.9182,\n",
            "         0.3857, -0.1654, -0.5187, -0.5350, -0.2378,  0.1879,  0.4951,  0.5099,\n",
            "         0.2128, -0.2772, -0.7895, -1.1914, -1.4339, -1.5396, -1.5557, -1.5056,\n",
            "        -1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37854:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.5874, -1.5453, -1.2946, -0.9757, -0.7188, -0.5903, -0.5794, -0.6225,\n",
            "        -0.6434, -0.5877, -0.4347, -0.1889,  0.1364,  0.5273,  0.9622,  1.3980,\n",
            "         1.7625,  1.9652,  1.9260,  1.6113,  1.0599,  0.3835, -0.2646, -0.7468,\n",
            "        -0.9952, -1.0333, -0.9499, -0.8434, -0.7712, -0.7320, -0.6849, -0.5872,\n",
            "        -0.4251, -0.2214, -0.0157,  0.1685,  0.3438,  0.5475,  0.8008,  1.0691,\n",
            "         1.2562,  1.2449,  0.9637,  0.4398, -0.1948, -0.7481, -1.0434, -0.9923,\n",
            "        -0.6365, -0.1393,  0.2786,  0.4345,  0.2647, -0.1537, -0.6519, -1.0553,\n",
            "        -1.2554, -1.2319, -1.0305, -0.7197, -0.3592,  0.0079,  0.3429,  0.5995,\n",
            "         0.7297,  0.7075,  0.5556,  0.3519,  0.2059,  0.2120,  0.4039,  0.7320,\n",
            "         1.0763,  1.2876,  1.2465,  0.9182,  0.3857, -0.1654, -0.5187, -0.5350,\n",
            "        -0.2378,  0.1879,  0.4951,  0.5099,  0.2128, -0.2772, -0.7895, -1.1914,\n",
            "        -1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37855:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.7188, -0.5903, -0.5794, -0.6225, -0.6434, -0.5877, -0.4347, -0.1889,\n",
            "         0.1364,  0.5273,  0.9622,  1.3980,  1.7625,  1.9652,  1.9260,  1.6113,\n",
            "         1.0599,  0.3835, -0.2646, -0.7468, -0.9952, -1.0333, -0.9499, -0.8434,\n",
            "        -0.7712, -0.7320, -0.6849, -0.5872, -0.4251, -0.2214, -0.0157,  0.1685,\n",
            "         0.3438,  0.5475,  0.8008,  1.0691,  1.2562,  1.2449,  0.9637,  0.4398,\n",
            "        -0.1948, -0.7481, -1.0434, -0.9923, -0.6365, -0.1393,  0.2786,  0.4345,\n",
            "         0.2647, -0.1537, -0.6519, -1.0553, -1.2554, -1.2319, -1.0305, -0.7197,\n",
            "        -0.3592,  0.0079,  0.3429,  0.5995,  0.7297,  0.7075,  0.5556,  0.3519,\n",
            "         0.2059,  0.2120,  0.4039,  0.7320,  1.0763,  1.2876,  1.2465,  0.9182,\n",
            "         0.3857, -0.1654, -0.5187, -0.5350, -0.2378,  0.1879,  0.4951,  0.5099,\n",
            "         0.2128, -0.2772, -0.7895, -1.1914, -1.4339, -1.5396, -1.5557, -1.5056,\n",
            "        -1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37856:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.6434, -0.5877, -0.4347, -0.1889,  0.1364,  0.5273,  0.9622,  1.3980,\n",
            "         1.7625,  1.9652,  1.9260,  1.6113,  1.0599,  0.3835, -0.2646, -0.7468,\n",
            "        -0.9952, -1.0333, -0.9499, -0.8434, -0.7712, -0.7320, -0.6849, -0.5872,\n",
            "        -0.4251, -0.2214, -0.0157,  0.1685,  0.3438,  0.5475,  0.8008,  1.0691,\n",
            "         1.2562,  1.2449,  0.9637,  0.4398, -0.1948, -0.7481, -1.0434, -0.9923,\n",
            "        -0.6365, -0.1393,  0.2786,  0.4345,  0.2647, -0.1537, -0.6519, -1.0553,\n",
            "        -1.2554, -1.2319, -1.0305, -0.7197, -0.3592,  0.0079,  0.3429,  0.5995,\n",
            "         0.7297,  0.7075,  0.5556,  0.3519,  0.2059,  0.2120,  0.4039,  0.7320,\n",
            "         1.0763,  1.2876,  1.2465,  0.9182,  0.3857, -0.1654, -0.5187, -0.5350,\n",
            "        -0.2378,  0.1879,  0.4951,  0.5099,  0.2128, -0.2772, -0.7895, -1.1914,\n",
            "        -1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37857:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.1364,  0.5273,  0.9622,  1.3980,  1.7625,  1.9652,  1.9260,  1.6113,\n",
            "         1.0599,  0.3835, -0.2646, -0.7468, -0.9952, -1.0333, -0.9499, -0.8434,\n",
            "        -0.7712, -0.7320, -0.6849, -0.5872, -0.4251, -0.2214, -0.0157,  0.1685,\n",
            "         0.3438,  0.5475,  0.8008,  1.0691,  1.2562,  1.2449,  0.9637,  0.4398,\n",
            "        -0.1948, -0.7481, -1.0434, -0.9923, -0.6365, -0.1393,  0.2786,  0.4345,\n",
            "         0.2647, -0.1537, -0.6519, -1.0553, -1.2554, -1.2319, -1.0305, -0.7197,\n",
            "        -0.3592,  0.0079,  0.3429,  0.5995,  0.7297,  0.7075,  0.5556,  0.3519,\n",
            "         0.2059,  0.2120,  0.4039,  0.7320,  1.0763,  1.2876,  1.2465,  0.9182,\n",
            "         0.3857, -0.1654, -0.5187, -0.5350, -0.2378,  0.1879,  0.4951,  0.5099,\n",
            "         0.2128, -0.2772, -0.7895, -1.1914, -1.4339, -1.5396, -1.5557, -1.5056,\n",
            "        -1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37858:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.7625,  1.9652,  1.9260,  1.6113,  1.0599,  0.3835, -0.2646, -0.7468,\n",
            "        -0.9952, -1.0333, -0.9499, -0.8434, -0.7712, -0.7320, -0.6849, -0.5872,\n",
            "        -0.4251, -0.2214, -0.0157,  0.1685,  0.3438,  0.5475,  0.8008,  1.0691,\n",
            "         1.2562,  1.2449,  0.9637,  0.4398, -0.1948, -0.7481, -1.0434, -0.9923,\n",
            "        -0.6365, -0.1393,  0.2786,  0.4345,  0.2647, -0.1537, -0.6519, -1.0553,\n",
            "        -1.2554, -1.2319, -1.0305, -0.7197, -0.3592,  0.0079,  0.3429,  0.5995,\n",
            "         0.7297,  0.7075,  0.5556,  0.3519,  0.2059,  0.2120,  0.4039,  0.7320,\n",
            "         1.0763,  1.2876,  1.2465,  0.9182,  0.3857, -0.1654, -0.5187, -0.5350,\n",
            "        -0.2378,  0.1879,  0.4951,  0.5099,  0.2128, -0.2772, -0.7895, -1.1914,\n",
            "        -1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37859:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.0599,  0.3835, -0.2646, -0.7468, -0.9952, -1.0333, -0.9499, -0.8434,\n",
            "        -0.7712, -0.7320, -0.6849, -0.5872, -0.4251, -0.2214, -0.0157,  0.1685,\n",
            "         0.3438,  0.5475,  0.8008,  1.0691,  1.2562,  1.2449,  0.9637,  0.4398,\n",
            "        -0.1948, -0.7481, -1.0434, -0.9923, -0.6365, -0.1393,  0.2786,  0.4345,\n",
            "         0.2647, -0.1537, -0.6519, -1.0553, -1.2554, -1.2319, -1.0305, -0.7197,\n",
            "        -0.3592,  0.0079,  0.3429,  0.5995,  0.7297,  0.7075,  0.5556,  0.3519,\n",
            "         0.2059,  0.2120,  0.4039,  0.7320,  1.0763,  1.2876,  1.2465,  0.9182,\n",
            "         0.3857, -0.1654, -0.5187, -0.5350, -0.2378,  0.1879,  0.4951,  0.5099,\n",
            "         0.2128, -0.2772, -0.7895, -1.1914, -1.4339, -1.5396, -1.5557, -1.5056,\n",
            "        -1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37860:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.9952, -1.0333, -0.9499, -0.8434, -0.7712, -0.7320, -0.6849, -0.5872,\n",
            "        -0.4251, -0.2214, -0.0157,  0.1685,  0.3438,  0.5475,  0.8008,  1.0691,\n",
            "         1.2562,  1.2449,  0.9637,  0.4398, -0.1948, -0.7481, -1.0434, -0.9923,\n",
            "        -0.6365, -0.1393,  0.2786,  0.4345,  0.2647, -0.1537, -0.6519, -1.0553,\n",
            "        -1.2554, -1.2319, -1.0305, -0.7197, -0.3592,  0.0079,  0.3429,  0.5995,\n",
            "         0.7297,  0.7075,  0.5556,  0.3519,  0.2059,  0.2120,  0.4039,  0.7320,\n",
            "         1.0763,  1.2876,  1.2465,  0.9182,  0.3857, -0.1654, -0.5187, -0.5350,\n",
            "        -0.2378,  0.1879,  0.4951,  0.5099,  0.2128, -0.2772, -0.7895, -1.1914,\n",
            "        -1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37861:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.7712, -0.7320, -0.6849, -0.5872, -0.4251, -0.2214, -0.0157,  0.1685,\n",
            "         0.3438,  0.5475,  0.8008,  1.0691,  1.2562,  1.2449,  0.9637,  0.4398,\n",
            "        -0.1948, -0.7481, -1.0434, -0.9923, -0.6365, -0.1393,  0.2786,  0.4345,\n",
            "         0.2647, -0.1537, -0.6519, -1.0553, -1.2554, -1.2319, -1.0305, -0.7197,\n",
            "        -0.3592,  0.0079,  0.3429,  0.5995,  0.7297,  0.7075,  0.5556,  0.3519,\n",
            "         0.2059,  0.2120,  0.4039,  0.7320,  1.0763,  1.2876,  1.2465,  0.9182,\n",
            "         0.3857, -0.1654, -0.5187, -0.5350, -0.2378,  0.1879,  0.4951,  0.5099,\n",
            "         0.2128, -0.2772, -0.7895, -1.1914, -1.4339, -1.5396, -1.5557, -1.5056,\n",
            "        -1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37862:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.4251, -0.2214, -0.0157,  0.1685,  0.3438,  0.5475,  0.8008,  1.0691,\n",
            "         1.2562,  1.2449,  0.9637,  0.4398, -0.1948, -0.7481, -1.0434, -0.9923,\n",
            "        -0.6365, -0.1393,  0.2786,  0.4345,  0.2647, -0.1537, -0.6519, -1.0553,\n",
            "        -1.2554, -1.2319, -1.0305, -0.7197, -0.3592,  0.0079,  0.3429,  0.5995,\n",
            "         0.7297,  0.7075,  0.5556,  0.3519,  0.2059,  0.2120,  0.4039,  0.7320,\n",
            "         1.0763,  1.2876,  1.2465,  0.9182,  0.3857, -0.1654, -0.5187, -0.5350,\n",
            "        -0.2378,  0.1879,  0.4951,  0.5099,  0.2128, -0.2772, -0.7895, -1.1914,\n",
            "        -1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37863:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.3438,  0.5475,  0.8008,  1.0691,  1.2562,  1.2449,  0.9637,  0.4398,\n",
            "        -0.1948, -0.7481, -1.0434, -0.9923, -0.6365, -0.1393,  0.2786,  0.4345,\n",
            "         0.2647, -0.1537, -0.6519, -1.0553, -1.2554, -1.2319, -1.0305, -0.7197,\n",
            "        -0.3592,  0.0079,  0.3429,  0.5995,  0.7297,  0.7075,  0.5556,  0.3519,\n",
            "         0.2059,  0.2120,  0.4039,  0.7320,  1.0763,  1.2876,  1.2465,  0.9182,\n",
            "         0.3857, -0.1654, -0.5187, -0.5350, -0.2378,  0.1879,  0.4951,  0.5099,\n",
            "         0.2128, -0.2772, -0.7895, -1.1914, -1.4339, -1.5396, -1.5557, -1.5056,\n",
            "        -1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37864:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.2562,  1.2449,  0.9637,  0.4398, -0.1948, -0.7481, -1.0434, -0.9923,\n",
            "        -0.6365, -0.1393,  0.2786,  0.4345,  0.2647, -0.1537, -0.6519, -1.0553,\n",
            "        -1.2554, -1.2319, -1.0305, -0.7197, -0.3592,  0.0079,  0.3429,  0.5995,\n",
            "         0.7297,  0.7075,  0.5556,  0.3519,  0.2059,  0.2120,  0.4039,  0.7320,\n",
            "         1.0763,  1.2876,  1.2465,  0.9182,  0.3857, -0.1654, -0.5187, -0.5350,\n",
            "        -0.2378,  0.1879,  0.4951,  0.5099,  0.2128, -0.2772, -0.7895, -1.1914,\n",
            "        -1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37865:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.1948, -0.7481, -1.0434, -0.9923, -0.6365, -0.1393,  0.2786,  0.4345,\n",
            "         0.2647, -0.1537, -0.6519, -1.0553, -1.2554, -1.2319, -1.0305, -0.7197,\n",
            "        -0.3592,  0.0079,  0.3429,  0.5995,  0.7297,  0.7075,  0.5556,  0.3519,\n",
            "         0.2059,  0.2120,  0.4039,  0.7320,  1.0763,  1.2876,  1.2465,  0.9182,\n",
            "         0.3857, -0.1654, -0.5187, -0.5350, -0.2378,  0.1879,  0.4951,  0.5099,\n",
            "         0.2128, -0.2772, -0.7895, -1.1914, -1.4339, -1.5396, -1.5557, -1.5056,\n",
            "        -1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37866:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.6365, -0.1393,  0.2786,  0.4345,  0.2647, -0.1537, -0.6519, -1.0553,\n",
            "        -1.2554, -1.2319, -1.0305, -0.7197, -0.3592,  0.0079,  0.3429,  0.5995,\n",
            "         0.7297,  0.7075,  0.5556,  0.3519,  0.2059,  0.2120,  0.4039,  0.7320,\n",
            "         1.0763,  1.2876,  1.2465,  0.9182,  0.3857, -0.1654, -0.5187, -0.5350,\n",
            "        -0.2378,  0.1879,  0.4951,  0.5099,  0.2128, -0.2772, -0.7895, -1.1914,\n",
            "        -1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37867:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.2647, -0.1537, -0.6519, -1.0553, -1.2554, -1.2319, -1.0305, -0.7197,\n",
            "        -0.3592,  0.0079,  0.3429,  0.5995,  0.7297,  0.7075,  0.5556,  0.3519,\n",
            "         0.2059,  0.2120,  0.4039,  0.7320,  1.0763,  1.2876,  1.2465,  0.9182,\n",
            "         0.3857, -0.1654, -0.5187, -0.5350, -0.2378,  0.1879,  0.4951,  0.5099,\n",
            "         0.2128, -0.2772, -0.7895, -1.1914, -1.4339, -1.5396, -1.5557, -1.5056,\n",
            "        -1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37868:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.2554, -1.2319, -1.0305, -0.7197, -0.3592,  0.0079,  0.3429,  0.5995,\n",
            "         0.7297,  0.7075,  0.5556,  0.3519,  0.2059,  0.2120,  0.4039,  0.7320,\n",
            "         1.0763,  1.2876,  1.2465,  0.9182,  0.3857, -0.1654, -0.5187, -0.5350,\n",
            "        -0.2378,  0.1879,  0.4951,  0.5099,  0.2128, -0.2772, -0.7895, -1.1914,\n",
            "        -1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37869:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.3592,  0.0079,  0.3429,  0.5995,  0.7297,  0.7075,  0.5556,  0.3519,\n",
            "         0.2059,  0.2120,  0.4039,  0.7320,  1.0763,  1.2876,  1.2465,  0.9182,\n",
            "         0.3857, -0.1654, -0.5187, -0.5350, -0.2378,  0.1879,  0.4951,  0.5099,\n",
            "         0.2128, -0.2772, -0.7895, -1.1914, -1.4339, -1.5396, -1.5557, -1.5056,\n",
            "        -1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37870:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.7297,  0.7075,  0.5556,  0.3519,  0.2059,  0.2120,  0.4039,  0.7320,\n",
            "         1.0763,  1.2876,  1.2465,  0.9182,  0.3857, -0.1654, -0.5187, -0.5350,\n",
            "        -0.2378,  0.1879,  0.4951,  0.5099,  0.2128, -0.2772, -0.7895, -1.1914,\n",
            "        -1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37871:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.2059,  0.2120,  0.4039,  0.7320,  1.0763,  1.2876,  1.2465,  0.9182,\n",
            "         0.3857, -0.1654, -0.5187, -0.5350, -0.2378,  0.1879,  0.4951,  0.5099,\n",
            "         0.2128, -0.2772, -0.7895, -1.1914, -1.4339, -1.5396, -1.5557, -1.5056,\n",
            "        -1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37872:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.0763,  1.2876,  1.2465,  0.9182,  0.3857, -0.1654, -0.5187, -0.5350,\n",
            "        -0.2378,  0.1879,  0.4951,  0.5099,  0.2128, -0.2772, -0.7895, -1.1914,\n",
            "        -1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37873:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.3857, -0.1654, -0.5187, -0.5350, -0.2378,  0.1879,  0.4951,  0.5099,\n",
            "         0.2128, -0.2772, -0.7895, -1.1914, -1.4339, -1.5396, -1.5557, -1.5056,\n",
            "        -1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37874:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.2378,  0.1879,  0.4951,  0.5099,  0.2128, -0.2772, -0.7895, -1.1914,\n",
            "        -1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37875:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.2128, -0.2772, -0.7895, -1.1914, -1.4339, -1.5396, -1.5557, -1.5056,\n",
            "        -1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37876:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.4339, -1.5396, -1.5557, -1.5056, -1.3705, -1.1121, -0.7174, -0.2331,\n",
            "         0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37877:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.3705, -1.1121, -0.7174, -0.2331,  0.2403,  0.5920,  0.7579,  0.7562,\n",
            "         0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37878:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.2403,  0.5920,  0.7579,  0.7562,  0.6805,  0.6510,  0.7503,  0.9802,\n",
            "         1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575, -0.3340, -0.3620, -0.3717, -0.2853, -0.0703,  0.2334,\n",
            "         0.5332,  0.7376])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37879:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.6805,  0.6510,  0.7503,  0.9802,  1.2620,  1.4782,  1.5322,  1.3915,\n",
            "         1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853, -0.0703,  0.2334,  0.5332,  0.7376,  0.8070,  0.7669,\n",
            "         0.6790,  0.5985])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37880:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.2620,  1.4782,  1.5322,  1.3915,  1.0912,  0.7018,  0.2880, -0.1131,\n",
            "        -0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575, -0.3340, -0.3620, -0.3717, -0.2853, -0.0703,  0.2334,\n",
            "         0.5332,  0.7376,  0.8070,  0.7669,  0.6790,  0.5985,  0.5476,  0.5189,\n",
            "         0.4899,  0.4349])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37881:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.0912,  0.7018,  0.2880, -0.1131, -0.4859, -0.8173, -1.0857, -1.2643,\n",
            "        -1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853, -0.0703,  0.2334,  0.5332,  0.7376,  0.8070,  0.7669,\n",
            "         0.6790,  0.5985,  0.5476,  0.5189,  0.4899,  0.4349,  0.3310,  0.1691,\n",
            "        -0.0287, -0.2053])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37882:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.4859, -0.8173, -1.0857, -1.2643, -1.3306, -1.2735, -1.0978, -0.8261,\n",
            "        -0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575, -0.3340, -0.3620, -0.3717, -0.2853, -0.0703,  0.2334,\n",
            "         0.5332,  0.7376,  0.8070,  0.7669,  0.6790,  0.5985,  0.5476,  0.5189,\n",
            "         0.4899,  0.4349,  0.3310,  0.1691, -0.0287, -0.2053, -0.2941, -0.2662,\n",
            "        -0.1649, -0.0945])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37883:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.3306, -1.2735, -1.0978, -0.8261, -0.4988, -0.1663,  0.1225,  0.3326,\n",
            "         0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853, -0.0703,  0.2334,  0.5332,  0.7376,  0.8070,  0.7669,\n",
            "         0.6790,  0.5985,  0.5476,  0.5189,  0.4899,  0.4349,  0.3310,  0.1691,\n",
            "        -0.0287, -0.2053, -0.2941, -0.2662, -0.1649, -0.0945, -0.1604, -0.4000,\n",
            "        -0.7481, -1.0631])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37884:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.4988, -0.1663,  0.1225,  0.3326,  0.4514,  0.4916,  0.4876,  0.4814,\n",
            "         0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575, -0.3340, -0.3620, -0.3717, -0.2853, -0.0703,  0.2334,\n",
            "         0.5332,  0.7376,  0.8070,  0.7669,  0.6790,  0.5985,  0.5476,  0.5189,\n",
            "         0.4899,  0.4349,  0.3310,  0.1691, -0.0287, -0.2053, -0.2941, -0.2662,\n",
            "        -0.1649, -0.0945, -0.1604, -0.4000, -0.7481, -1.0631, -1.1964, -1.0635,\n",
            "        -0.6828, -0.1672])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37885:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.4514,  0.4916,  0.4876,  0.4814,  0.5030,  0.5501,  0.5812,  0.5299,\n",
            "         0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853, -0.0703,  0.2334,  0.5332,  0.7376,  0.8070,  0.7669,\n",
            "         0.6790,  0.5985,  0.5476,  0.5189,  0.4899,  0.4349,  0.3310,  0.1691,\n",
            "        -0.0287, -0.2053, -0.2941, -0.2662, -0.1649, -0.0945, -0.1604, -0.4000,\n",
            "        -0.7481, -1.0631, -1.1964, -1.0635, -0.6828, -0.1672,  0.3201,  0.6269,\n",
            "         0.6667,  0.4484])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37886:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.5030,  0.5501,  0.5812,  0.5299,  0.3361, -0.0221, -0.5132, -1.0600,\n",
            "        -1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575, -0.3340, -0.3620, -0.3717, -0.2853, -0.0703,  0.2334,\n",
            "         0.5332,  0.7376,  0.8070,  0.7669,  0.6790,  0.5985,  0.5476,  0.5189,\n",
            "         0.4899,  0.4349,  0.3310,  0.1691, -0.0287, -0.2053, -0.2941, -0.2662,\n",
            "        -0.1649, -0.0945, -0.1604, -0.4000, -0.7481, -1.0631, -1.1964, -1.0635,\n",
            "        -0.6828, -0.1672,  0.3201,  0.6269,  0.6667,  0.4484,  0.0700, -0.3227,\n",
            "        -0.5950, -0.6741])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37887:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 0.3361, -0.0221, -0.5132, -1.0600, -1.5637, -1.9297, -2.0867, -1.9935,\n",
            "        -1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853, -0.0703,  0.2334,  0.5332,  0.7376,  0.8070,  0.7669,\n",
            "         0.6790,  0.5985,  0.5476,  0.5189,  0.4899,  0.4349,  0.3310,  0.1691,\n",
            "        -0.0287, -0.2053, -0.2941, -0.2662, -0.1649, -0.0945, -0.1604, -0.4000,\n",
            "        -0.7481, -1.0631, -1.1964, -1.0635, -0.6828, -0.1672,  0.3201,  0.6269,\n",
            "         0.6667,  0.4484,  0.0700, -0.3227, -0.5950, -0.6741, -0.5680, -0.3441,\n",
            "        -0.0818,  0.1700])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37888:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.5637, -1.9297, -2.0867, -1.9935, -1.6399, -1.0464, -0.2675,  0.6052,\n",
            "         1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575, -0.3340, -0.3620, -0.3717, -0.2853, -0.0703,  0.2334,\n",
            "         0.5332,  0.7376,  0.8070,  0.7669,  0.6790,  0.5985,  0.5476,  0.5189,\n",
            "         0.4899,  0.4349,  0.3310,  0.1691, -0.0287, -0.2053, -0.2941, -0.2662,\n",
            "        -0.1649, -0.0945, -0.1604, -0.4000, -0.7481, -1.0631, -1.1964, -1.0635,\n",
            "        -0.6828, -0.1672,  0.3201,  0.6269,  0.6667,  0.4484,  0.0700, -0.3227,\n",
            "        -0.5950, -0.6741, -0.5680, -0.3441, -0.0818,  0.1700,  0.4065,  0.6447,\n",
            "         0.8851,  1.0897])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37889:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.6399, -1.0464, -0.2675,  0.6052,  1.4524,  2.1565,  2.6425,  2.9048,\n",
            "         2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853, -0.0703,  0.2334,  0.5332,  0.7376,  0.8070,  0.7669,\n",
            "         0.6790,  0.5985,  0.5476,  0.5189,  0.4899,  0.4349,  0.3310,  0.1691,\n",
            "        -0.0287, -0.2053, -0.2941, -0.2662, -0.1649, -0.0945, -0.1604, -0.4000,\n",
            "        -0.7481, -1.0631, -1.1964, -1.0635, -0.6828, -0.1672,  0.3201,  0.6269,\n",
            "         0.6667,  0.4484,  0.0700, -0.3227, -0.5950, -0.6741, -0.5680, -0.3441,\n",
            "        -0.0818,  0.1700,  0.4065,  0.6447,  0.8851,  1.0897,  1.1940,  1.1451,\n",
            "         0.9319,  0.5890])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37890:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.4524,  2.1565,  2.6425,  2.9048,  2.9936,  2.9666,  2.8406,  2.5838,\n",
            "         2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575, -0.3340, -0.3620, -0.3717, -0.2853, -0.0703,  0.2334,\n",
            "         0.5332,  0.7376,  0.8070,  0.7669,  0.6790,  0.5985,  0.5476,  0.5189,\n",
            "         0.4899,  0.4349,  0.3310,  0.1691, -0.0287, -0.2053, -0.2941, -0.2662,\n",
            "        -0.1649, -0.0945, -0.1604, -0.4000, -0.7481, -1.0631, -1.1964, -1.0635,\n",
            "        -0.6828, -0.1672,  0.3201,  0.6269,  0.6667,  0.4484,  0.0700, -0.3227,\n",
            "        -0.5950, -0.6741, -0.5680, -0.3441, -0.0818,  0.1700,  0.4065,  0.6447,\n",
            "         0.8851,  1.0897,  1.1940,  1.1451,  0.9319,  0.5890,  0.1765, -0.2419,\n",
            "        -0.6073, -0.8693])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37891:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 2.9936,  2.9666,  2.8406,  2.5838,  2.1525,  1.5407,  0.7989,  0.0094,\n",
            "        -0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853, -0.0703,  0.2334,  0.5332,  0.7376,  0.8070,  0.7669,\n",
            "         0.6790,  0.5985,  0.5476,  0.5189,  0.4899,  0.4349,  0.3310,  0.1691,\n",
            "        -0.0287, -0.2053, -0.2941, -0.2662, -0.1649, -0.0945, -0.1604, -0.4000,\n",
            "        -0.7481, -1.0631, -1.1964, -1.0635, -0.6828, -0.1672,  0.3201,  0.6269,\n",
            "         0.6667,  0.4484,  0.0700, -0.3227, -0.5950, -0.6741, -0.5680, -0.3441,\n",
            "        -0.0818,  0.1700,  0.4065,  0.6447,  0.8851,  1.0897,  1.1940,  1.1451,\n",
            "         0.9319,  0.5890,  0.1765, -0.2419, -0.6073, -0.8693, -0.9936, -0.9753,\n",
            "        -0.8464, -0.6676])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37892:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 2.1525,  1.5407,  0.7989,  0.0094, -0.7583, -1.4709, -2.1186, -2.6807,\n",
            "        -3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575, -0.3340, -0.3620, -0.3717, -0.2853, -0.0703,  0.2334,\n",
            "         0.5332,  0.7376,  0.8070,  0.7669,  0.6790,  0.5985,  0.5476,  0.5189,\n",
            "         0.4899,  0.4349,  0.3310,  0.1691, -0.0287, -0.2053, -0.2941, -0.2662,\n",
            "        -0.1649, -0.0945, -0.1604, -0.4000, -0.7481, -1.0631, -1.1964, -1.0635,\n",
            "        -0.6828, -0.1672,  0.3201,  0.6269,  0.6667,  0.4484,  0.0700, -0.3227,\n",
            "        -0.5950, -0.6741, -0.5680, -0.3441, -0.0818,  0.1700,  0.4065,  0.6447,\n",
            "         0.8851,  1.0897,  1.1940,  1.1451,  0.9319,  0.5890,  0.1765, -0.2419,\n",
            "        -0.6073, -0.8693, -0.9936, -0.9753, -0.8464, -0.6676, -0.5046, -0.3986,\n",
            "        -0.3443, -0.2906])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37893:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.7583, -1.4709, -2.1186, -2.6807, -3.1045, -3.3215, -3.2925, -3.0513,\n",
            "        -2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853, -0.0703,  0.2334,  0.5332,  0.7376,  0.8070,  0.7669,\n",
            "         0.6790,  0.5985,  0.5476,  0.5189,  0.4899,  0.4349,  0.3310,  0.1691,\n",
            "        -0.0287, -0.2053, -0.2941, -0.2662, -0.1649, -0.0945, -0.1604, -0.4000,\n",
            "        -0.7481, -1.0631, -1.1964, -1.0635, -0.6828, -0.1672,  0.3201,  0.6269,\n",
            "         0.6667,  0.4484,  0.0700, -0.3227, -0.5950, -0.6741, -0.5680, -0.3441,\n",
            "        -0.0818,  0.1700,  0.4065,  0.6447,  0.8851,  1.0897,  1.1940,  1.1451,\n",
            "         0.9319,  0.5890,  0.1765, -0.2419, -0.6073, -0.8693, -0.9936, -0.9753,\n",
            "        -0.8464, -0.6676, -0.5046, -0.3986, -0.3443, -0.2906, -0.1649,  0.0844,\n",
            "         0.4503,  0.8554])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37894:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-3.1045, -3.3215, -3.2925, -3.0513, -2.7064, -2.3918, -2.1899, -2.0754,\n",
            "        -1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575, -0.3340, -0.3620, -0.3717, -0.2853, -0.0703,  0.2334,\n",
            "         0.5332,  0.7376,  0.8070,  0.7669,  0.6790,  0.5985,  0.5476,  0.5189,\n",
            "         0.4899,  0.4349,  0.3310,  0.1691, -0.0287, -0.2053, -0.2941, -0.2662,\n",
            "        -0.1649, -0.0945, -0.1604, -0.4000, -0.7481, -1.0631, -1.1964, -1.0635,\n",
            "        -0.6828, -0.1672,  0.3201,  0.6269,  0.6667,  0.4484,  0.0700, -0.3227,\n",
            "        -0.5950, -0.6741, -0.5680, -0.3441, -0.0818,  0.1700,  0.4065,  0.6447,\n",
            "         0.8851,  1.0897,  1.1940,  1.1451,  0.9319,  0.5890,  0.1765, -0.2419,\n",
            "        -0.6073, -0.8693, -0.9936, -0.9753, -0.8464, -0.6676, -0.5046, -0.3986,\n",
            "        -0.3443, -0.2906, -0.1649,  0.0844,  0.4503,  0.8554,  1.1780,  1.3045,\n",
            "         1.1790,  0.8259])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37895:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-2.7064, -2.3918, -2.1899, -2.0754, -1.9213, -1.5676, -0.9144,  0.0183,\n",
            "         1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853, -0.0703,  0.2334,  0.5332,  0.7376,  0.8070,  0.7669,\n",
            "         0.6790,  0.5985,  0.5476,  0.5189,  0.4899,  0.4349,  0.3310,  0.1691,\n",
            "        -0.0287, -0.2053, -0.2941, -0.2662, -0.1649, -0.0945, -0.1604, -0.4000,\n",
            "        -0.7481, -1.0631, -1.1964, -1.0635, -0.6828, -0.1672,  0.3201,  0.6269,\n",
            "         0.6667,  0.4484,  0.0700, -0.3227, -0.5950, -0.6741, -0.5680, -0.3441,\n",
            "        -0.0818,  0.1700,  0.4065,  0.6447,  0.8851,  1.0897,  1.1940,  1.1451,\n",
            "         0.9319,  0.5890,  0.1765, -0.2419, -0.6073, -0.8693, -0.9936, -0.9753,\n",
            "        -0.8464, -0.6676, -0.5046, -0.3986, -0.3443, -0.2906, -0.1649,  0.0844,\n",
            "         0.4503,  0.8554,  1.1780,  1.3045,  1.1790,  0.8259,  0.3390, -0.1548,\n",
            "        -0.5380, -0.7398])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37896:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.9213, -1.5676, -0.9144,  0.0183,  1.0960,  2.1306,  2.9540,  3.4665,\n",
            "         3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575, -0.3340, -0.3620, -0.3717, -0.2853, -0.0703,  0.2334,\n",
            "         0.5332,  0.7376,  0.8070,  0.7669,  0.6790,  0.5985,  0.5476,  0.5189,\n",
            "         0.4899,  0.4349,  0.3310,  0.1691, -0.0287, -0.2053, -0.2941, -0.2662,\n",
            "        -0.1649, -0.0945, -0.1604, -0.4000, -0.7481, -1.0631, -1.1964, -1.0635,\n",
            "        -0.6828, -0.1672,  0.3201,  0.6269,  0.6667,  0.4484,  0.0700, -0.3227,\n",
            "        -0.5950, -0.6741, -0.5680, -0.3441, -0.0818,  0.1700,  0.4065,  0.6447,\n",
            "         0.8851,  1.0897,  1.1940,  1.1451,  0.9319,  0.5890,  0.1765, -0.2419,\n",
            "        -0.6073, -0.8693, -0.9936, -0.9753, -0.8464, -0.6676, -0.5046, -0.3986,\n",
            "        -0.3443, -0.2906, -0.1649,  0.0844,  0.4503,  0.8554,  1.1780,  1.3045,\n",
            "         1.1790,  0.8259,  0.3390, -0.1548, -0.5380, -0.7398, -0.7532, -0.6262,\n",
            "        -0.4310, -0.2312])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37897:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.0960,  2.1306,  2.9540,  3.4665,  3.6475,  3.5372,  3.2043,  2.7173,\n",
            "         2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853, -0.0703,  0.2334,  0.5332,  0.7376,  0.8070,  0.7669,\n",
            "         0.6790,  0.5985,  0.5476,  0.5189,  0.4899,  0.4349,  0.3310,  0.1691,\n",
            "        -0.0287, -0.2053, -0.2941, -0.2662, -0.1649, -0.0945, -0.1604, -0.4000,\n",
            "        -0.7481, -1.0631, -1.1964, -1.0635, -0.6828, -0.1672,  0.3201,  0.6269,\n",
            "         0.6667,  0.4484,  0.0700, -0.3227, -0.5950, -0.6741, -0.5680, -0.3441,\n",
            "        -0.0818,  0.1700,  0.4065,  0.6447,  0.8851,  1.0897,  1.1940,  1.1451,\n",
            "         0.9319,  0.5890,  0.1765, -0.2419, -0.6073, -0.8693, -0.9936, -0.9753,\n",
            "        -0.8464, -0.6676, -0.5046, -0.3986, -0.3443, -0.2906, -0.1649,  0.0844,\n",
            "         0.4503,  0.8554,  1.1780,  1.3045,  1.1790,  0.8259,  0.3390, -0.1548,\n",
            "        -0.5380, -0.7398, -0.7532, -0.6262, -0.4310, -0.2312, -0.0637,  0.0572,\n",
            "         0.1245,  0.1305])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37898:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 3.6475,  3.5372,  3.2043,  2.7173,  2.1318,  1.4995,  0.8824,  0.3520,\n",
            "        -0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575, -0.3340, -0.3620, -0.3717, -0.2853, -0.0703,  0.2334,\n",
            "         0.5332,  0.7376,  0.8070,  0.7669,  0.6790,  0.5985,  0.5476,  0.5189,\n",
            "         0.4899,  0.4349,  0.3310,  0.1691, -0.0287, -0.2053, -0.2941, -0.2662,\n",
            "        -0.1649, -0.0945, -0.1604, -0.4000, -0.7481, -1.0631, -1.1964, -1.0635,\n",
            "        -0.6828, -0.1672,  0.3201,  0.6269,  0.6667,  0.4484,  0.0700, -0.3227,\n",
            "        -0.5950, -0.6741, -0.5680, -0.3441, -0.0818,  0.1700,  0.4065,  0.6447,\n",
            "         0.8851,  1.0897,  1.1940,  1.1451,  0.9319,  0.5890,  0.1765, -0.2419,\n",
            "        -0.6073, -0.8693, -0.9936, -0.9753, -0.8464, -0.6676, -0.5046, -0.3986,\n",
            "        -0.3443, -0.2906, -0.1649,  0.0844,  0.4503,  0.8554,  1.1780,  1.3045,\n",
            "         1.1790,  0.8259,  0.3390, -0.1548, -0.5380, -0.7398, -0.7532, -0.6262,\n",
            "        -0.4310, -0.2312, -0.0637,  0.0572,  0.1245,  0.1305,  0.0737, -0.0279,\n",
            "        -0.1316, -0.1819])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37899:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 2.1318,  1.4995,  0.8824,  0.3520, -0.0329, -0.2541, -0.3453, -0.3759,\n",
            "        -0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853, -0.0703,  0.2334,  0.5332,  0.7376,  0.8070,  0.7669,\n",
            "         0.6790,  0.5985,  0.5476,  0.5189,  0.4899,  0.4349,  0.3310,  0.1691,\n",
            "        -0.0287, -0.2053, -0.2941, -0.2662, -0.1649, -0.0945, -0.1604, -0.4000,\n",
            "        -0.7481, -1.0631, -1.1964, -1.0635, -0.6828, -0.1672,  0.3201,  0.6269,\n",
            "         0.6667,  0.4484,  0.0700, -0.3227, -0.5950, -0.6741, -0.5680, -0.3441,\n",
            "        -0.0818,  0.1700,  0.4065,  0.6447,  0.8851,  1.0897,  1.1940,  1.1451,\n",
            "         0.9319,  0.5890,  0.1765, -0.2419, -0.6073, -0.8693, -0.9936, -0.9753,\n",
            "        -0.8464, -0.6676, -0.5046, -0.3986, -0.3443, -0.2906, -0.1649,  0.0844,\n",
            "         0.4503,  0.8554,  1.1780,  1.3045,  1.1790,  0.8259,  0.3390, -0.1548,\n",
            "        -0.5380, -0.7398, -0.7532, -0.6262, -0.4310, -0.2312, -0.0637,  0.0572,\n",
            "         0.1245,  0.1305,  0.0737, -0.0279, -0.1316, -0.1819, -0.1373,  0.0025,\n",
            "         0.1847,  0.3192])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37900:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.0329, -0.2541, -0.3453, -0.3759, -0.4178, -0.5147, -0.6681, -0.8417,\n",
            "        -0.9812, -1.0393, -1.0005, -0.8938, -0.7836, -0.7397, -0.8008, -0.9515,\n",
            "        -1.1260, -1.2360, -1.2110, -1.0341, -0.7512, -0.4460, -0.1911, -0.0071,\n",
            "         0.1423,  0.3205,  0.5729,  0.8986,  1.2433,  1.5126,  1.5989,  1.4237,\n",
            "         0.9836,  0.3746, -0.2311, -0.6539, -0.7881, -0.6467, -0.3445, -0.0320,\n",
            "         0.1761,  0.2412,  0.1973,  0.1171,  0.0740,  0.1139,  0.2453,  0.4444,\n",
            "         0.6682,  0.8670,  0.9904,  0.9913,  0.8349,  0.5125,  0.0502, -0.4936,\n",
            "        -1.0412, -1.5094, -1.8232, -1.9290, -1.8101, -1.4959, -1.0548, -0.5738,\n",
            "        -0.1351,  0.1999,  0.4029,  0.4856,  0.4978,  0.5093,  0.5790,  0.7267,\n",
            "         0.9246,  1.1077,  1.1953,  1.1146,  0.8251,  0.3428, -0.2480, -0.8097,\n",
            "        -1.1984, -1.3196, -1.1642, -0.8061, -0.3668,  0.0337,  0.3168,  0.4647,\n",
            "         0.5134,  0.5262,  0.5623,  0.6576,  0.8194,  1.0270,  1.2300,  1.3494,\n",
            "         1.2973,  1.0190,  0.5333, -0.0650, -0.6525, -1.1406, -1.5102, -1.7965,\n",
            "        -2.0431, -2.2611, -2.4131, -2.4273, -2.2299, -1.7831, -1.1105, -0.2969,\n",
            "         0.5365,  1.2707,  1.8234,  2.1697,  2.3387,  2.3893,  2.3739,  2.3111,\n",
            "         2.1812,  1.9463,  1.5789,  1.0782,  0.4687, -0.2091, -0.9031, -1.5456,\n",
            "        -2.0533, -2.3446, -2.3722, -2.1501, -1.7503, -1.2689, -0.7821, -0.3254,\n",
            "         0.0953,  0.4741,  0.7866,  0.9951,  1.0707,  1.0130,  0.8532,  0.6406,\n",
            "         0.4178,  0.2024, -0.0115, -0.2299, -0.4340, -0.5785, -0.6213, -0.5610,\n",
            "        -0.4485, -0.3575, -0.3340, -0.3620, -0.3717, -0.2853, -0.0703,  0.2334,\n",
            "         0.5332,  0.7376,  0.8070,  0.7669,  0.6790,  0.5985,  0.5476,  0.5189,\n",
            "         0.4899,  0.4349,  0.3310,  0.1691, -0.0287, -0.2053, -0.2941, -0.2662,\n",
            "        -0.1649, -0.0945, -0.1604, -0.4000, -0.7481, -1.0631, -1.1964, -1.0635,\n",
            "        -0.6828, -0.1672,  0.3201,  0.6269,  0.6667,  0.4484,  0.0700, -0.3227,\n",
            "        -0.5950, -0.6741, -0.5680, -0.3441, -0.0818,  0.1700,  0.4065,  0.6447,\n",
            "         0.8851,  1.0897,  1.1940,  1.1451,  0.9319,  0.5890,  0.1765, -0.2419,\n",
            "        -0.6073, -0.8693, -0.9936, -0.9753, -0.8464, -0.6676, -0.5046, -0.3986,\n",
            "        -0.3443, -0.2906, -0.1649,  0.0844,  0.4503,  0.8554,  1.1780,  1.3045,\n",
            "         1.1790,  0.8259,  0.3390, -0.1548, -0.5380, -0.7398, -0.7532, -0.6262,\n",
            "        -0.4310, -0.2312, -0.0637,  0.0572,  0.1245,  0.1305,  0.0737, -0.0279,\n",
            "        -0.1316, -0.1819, -0.1373,  0.0025,  0.1847,  0.3192,  0.3242,  0.1754,\n",
            "        -0.0720, -0.3102])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37901:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-0.4178, -0.5147, -0.6681, -0.8417, -0.9812, -1.0393, -1.0005, -0.8938,\n",
            "        -0.7836, -0.7397, -0.8008, -0.9515, -1.1260, -1.2360, -1.2110, -1.0341,\n",
            "        -0.7512, -0.4460, -0.1911, -0.0071,  0.1423,  0.3205,  0.5729,  0.8986,\n",
            "         1.2433,  1.5126,  1.5989,  1.4237,  0.9836,  0.3746, -0.2311, -0.6539,\n",
            "        -0.7881, -0.6467, -0.3445, -0.0320,  0.1761,  0.2412,  0.1973,  0.1171,\n",
            "         0.0740,  0.1139,  0.2453,  0.4444,  0.6682,  0.8670,  0.9904,  0.9913,\n",
            "         0.8349,  0.5125,  0.0502, -0.4936, -1.0412, -1.5094, -1.8232, -1.9290,\n",
            "        -1.8101, -1.4959, -1.0548, -0.5738, -0.1351,  0.1999,  0.4029,  0.4856,\n",
            "         0.4978,  0.5093,  0.5790,  0.7267,  0.9246,  1.1077,  1.1953,  1.1146,\n",
            "         0.8251,  0.3428, -0.2480, -0.8097, -1.1984, -1.3196, -1.1642, -0.8061,\n",
            "        -0.3668,  0.0337,  0.3168,  0.4647,  0.5134,  0.5262,  0.5623,  0.6576,\n",
            "         0.8194,  1.0270,  1.2300,  1.3494,  1.2973,  1.0190,  0.5333, -0.0650,\n",
            "        -0.6525, -1.1406, -1.5102, -1.7965, -2.0431, -2.2611, -2.4131, -2.4273,\n",
            "        -2.2299, -1.7831, -1.1105, -0.2969,  0.5365,  1.2707,  1.8234,  2.1697,\n",
            "         2.3387,  2.3893,  2.3739,  2.3111,  2.1812,  1.9463,  1.5789,  1.0782,\n",
            "         0.4687, -0.2091, -0.9031, -1.5456, -2.0533, -2.3446, -2.3722, -2.1501,\n",
            "        -1.7503, -1.2689, -0.7821, -0.3254,  0.0953,  0.4741,  0.7866,  0.9951,\n",
            "         1.0707,  1.0130,  0.8532,  0.6406,  0.4178,  0.2024, -0.0115, -0.2299,\n",
            "        -0.4340, -0.5785, -0.6213, -0.5610, -0.4485, -0.3575, -0.3340, -0.3620,\n",
            "        -0.3717, -0.2853, -0.0703,  0.2334,  0.5332,  0.7376,  0.8070,  0.7669,\n",
            "         0.6790,  0.5985,  0.5476,  0.5189,  0.4899,  0.4349,  0.3310,  0.1691,\n",
            "        -0.0287, -0.2053, -0.2941, -0.2662, -0.1649, -0.0945, -0.1604, -0.4000,\n",
            "        -0.7481, -1.0631, -1.1964, -1.0635, -0.6828, -0.1672,  0.3201,  0.6269,\n",
            "         0.6667,  0.4484,  0.0700, -0.3227, -0.5950, -0.6741, -0.5680, -0.3441,\n",
            "        -0.0818,  0.1700,  0.4065,  0.6447,  0.8851,  1.0897,  1.1940,  1.1451,\n",
            "         0.9319,  0.5890,  0.1765, -0.2419, -0.6073, -0.8693, -0.9936, -0.9753,\n",
            "        -0.8464, -0.6676, -0.5046, -0.3986, -0.3443, -0.2906, -0.1649,  0.0844,\n",
            "         0.4503,  0.8554,  1.1780,  1.3045,  1.1790,  0.8259,  0.3390, -0.1548,\n",
            "        -0.5380, -0.7398, -0.7532, -0.6262, -0.4310, -0.2312, -0.0637,  0.0572,\n",
            "         0.1245,  0.1305,  0.0737, -0.0279, -0.1316, -0.1819, -0.1373,  0.0025,\n",
            "         0.1847,  0.3192,  0.3242,  0.1754, -0.0720, -0.3102, -0.4393, -0.4218,\n",
            "        -0.2953, -0.1408])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37902:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-9.8123e-01, -1.0393e+00, -1.0005e+00, -8.9384e-01, -7.8361e-01,\n",
            "        -7.3972e-01, -8.0079e-01, -9.5150e-01, -1.1260e+00, -1.2360e+00,\n",
            "        -1.2110e+00, -1.0341e+00, -7.5122e-01, -4.4604e-01, -1.9107e-01,\n",
            "        -7.1455e-03,  1.4235e-01,  3.2046e-01,  5.7293e-01,  8.9858e-01,\n",
            "         1.2433e+00,  1.5126e+00,  1.5989e+00,  1.4237e+00,  9.8365e-01,\n",
            "         3.7461e-01, -2.3109e-01, -6.5392e-01, -7.8810e-01, -6.4674e-01,\n",
            "        -3.4449e-01, -3.2012e-02,  1.7608e-01,  2.4124e-01,  1.9726e-01,\n",
            "         1.1710e-01,  7.3978e-02,  1.1388e-01,  2.4532e-01,  4.4441e-01,\n",
            "         6.6823e-01,  8.6703e-01,  9.9041e-01,  9.9130e-01,  8.3494e-01,\n",
            "         5.1252e-01,  5.0220e-02, -4.9365e-01, -1.0412e+00, -1.5094e+00,\n",
            "        -1.8232e+00, -1.9290e+00, -1.8101e+00, -1.4959e+00, -1.0548e+00,\n",
            "        -5.7376e-01, -1.3511e-01,  1.9994e-01,  4.0292e-01,  4.8555e-01,\n",
            "         4.9777e-01,  5.0934e-01,  5.7900e-01,  7.2675e-01,  9.2464e-01,\n",
            "         1.1077e+00,  1.1953e+00,  1.1146e+00,  8.2514e-01,  3.4278e-01,\n",
            "        -2.4795e-01, -8.0973e-01, -1.1984e+00, -1.3196e+00, -1.1642e+00,\n",
            "        -8.0615e-01, -3.6679e-01,  3.3749e-02,  3.1685e-01,  4.6468e-01,\n",
            "         5.1338e-01,  5.2616e-01,  5.6231e-01,  6.5762e-01,  8.1940e-01,\n",
            "         1.0270e+00,  1.2300e+00,  1.3494e+00,  1.2973e+00,  1.0190e+00,\n",
            "         5.3332e-01, -6.4991e-02, -6.5245e-01, -1.1406e+00, -1.5102e+00,\n",
            "        -1.7965e+00, -2.0431e+00, -2.2611e+00, -2.4131e+00, -2.4273e+00,\n",
            "        -2.2299e+00, -1.7831e+00, -1.1105e+00, -2.9692e-01,  5.3652e-01,\n",
            "         1.2707e+00,  1.8234e+00,  2.1697e+00,  2.3387e+00,  2.3893e+00,\n",
            "         2.3739e+00,  2.3111e+00,  2.1812e+00,  1.9463e+00,  1.5789e+00,\n",
            "         1.0782e+00,  4.6867e-01, -2.0911e-01, -9.0306e-01, -1.5456e+00,\n",
            "        -2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00,\n",
            "        -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,\n",
            "         7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,\n",
            "         6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01,\n",
            "        -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01,\n",
            "        -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01,\n",
            "        -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,\n",
            "         7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,\n",
            "         4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02,\n",
            "        -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02,\n",
            "        -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00,\n",
            "        -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,\n",
            "         6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01,\n",
            "        -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,\n",
            "         4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,\n",
            "         1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01,\n",
            "        -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01,\n",
            "        -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01,\n",
            "        -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,\n",
            "         1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01,\n",
            "        -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01,\n",
            "        -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,\n",
            "         7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,\n",
            "         2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01,\n",
            "        -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37903:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-7.8361e-01, -7.3972e-01, -8.0079e-01, -9.5150e-01, -1.1260e+00,\n",
            "        -1.2360e+00, -1.2110e+00, -1.0341e+00, -7.5122e-01, -4.4604e-01,\n",
            "        -1.9107e-01, -7.1455e-03,  1.4235e-01,  3.2046e-01,  5.7293e-01,\n",
            "         8.9858e-01,  1.2433e+00,  1.5126e+00,  1.5989e+00,  1.4237e+00,\n",
            "         9.8365e-01,  3.7461e-01, -2.3109e-01, -6.5392e-01, -7.8810e-01,\n",
            "        -6.4674e-01, -3.4449e-01, -3.2012e-02,  1.7608e-01,  2.4124e-01,\n",
            "         1.9726e-01,  1.1710e-01,  7.3978e-02,  1.1388e-01,  2.4532e-01,\n",
            "         4.4441e-01,  6.6823e-01,  8.6703e-01,  9.9041e-01,  9.9130e-01,\n",
            "         8.3494e-01,  5.1252e-01,  5.0220e-02, -4.9365e-01, -1.0412e+00,\n",
            "        -1.5094e+00, -1.8232e+00, -1.9290e+00, -1.8101e+00, -1.4959e+00,\n",
            "        -1.0548e+00, -5.7376e-01, -1.3511e-01,  1.9994e-01,  4.0292e-01,\n",
            "         4.8555e-01,  4.9777e-01,  5.0934e-01,  5.7900e-01,  7.2675e-01,\n",
            "         9.2464e-01,  1.1077e+00,  1.1953e+00,  1.1146e+00,  8.2514e-01,\n",
            "         3.4278e-01, -2.4795e-01, -8.0973e-01, -1.1984e+00, -1.3196e+00,\n",
            "        -1.1642e+00, -8.0615e-01, -3.6679e-01,  3.3749e-02,  3.1685e-01,\n",
            "         4.6468e-01,  5.1338e-01,  5.2616e-01,  5.6231e-01,  6.5762e-01,\n",
            "         8.1940e-01,  1.0270e+00,  1.2300e+00,  1.3494e+00,  1.2973e+00,\n",
            "         1.0190e+00,  5.3332e-01, -6.4991e-02, -6.5245e-01, -1.1406e+00,\n",
            "        -1.5102e+00, -1.7965e+00, -2.0431e+00, -2.2611e+00, -2.4131e+00,\n",
            "        -2.4273e+00, -2.2299e+00, -1.7831e+00, -1.1105e+00, -2.9692e-01,\n",
            "         5.3652e-01,  1.2707e+00,  1.8234e+00,  2.1697e+00,  2.3387e+00,\n",
            "         2.3893e+00,  2.3739e+00,  2.3111e+00,  2.1812e+00,  1.9463e+00,\n",
            "         1.5789e+00,  1.0782e+00,  4.6867e-01, -2.0911e-01, -9.0306e-01,\n",
            "        -1.5456e+00, -2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00,\n",
            "        -1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,\n",
            "         4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,\n",
            "         8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02,\n",
            "        -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01,\n",
            "        -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01,\n",
            "        -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,\n",
            "         8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,\n",
            "         5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01,\n",
            "        -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01,\n",
            "        -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00,\n",
            "        -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,\n",
            "         6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01,\n",
            "        -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,\n",
            "         1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,\n",
            "         1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01,\n",
            "        -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01,\n",
            "        -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01,\n",
            "        -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,\n",
            "         1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01,\n",
            "        -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01,\n",
            "        -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,\n",
            "         1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01,\n",
            "        -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,\n",
            "         1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01,\n",
            "        -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02,\n",
            "        -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37904:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.1260e+00, -1.2360e+00, -1.2110e+00, -1.0341e+00, -7.5122e-01,\n",
            "        -4.4604e-01, -1.9107e-01, -7.1455e-03,  1.4235e-01,  3.2046e-01,\n",
            "         5.7293e-01,  8.9858e-01,  1.2433e+00,  1.5126e+00,  1.5989e+00,\n",
            "         1.4237e+00,  9.8365e-01,  3.7461e-01, -2.3109e-01, -6.5392e-01,\n",
            "        -7.8810e-01, -6.4674e-01, -3.4449e-01, -3.2012e-02,  1.7608e-01,\n",
            "         2.4124e-01,  1.9726e-01,  1.1710e-01,  7.3978e-02,  1.1388e-01,\n",
            "         2.4532e-01,  4.4441e-01,  6.6823e-01,  8.6703e-01,  9.9041e-01,\n",
            "         9.9130e-01,  8.3494e-01,  5.1252e-01,  5.0220e-02, -4.9365e-01,\n",
            "        -1.0412e+00, -1.5094e+00, -1.8232e+00, -1.9290e+00, -1.8101e+00,\n",
            "        -1.4959e+00, -1.0548e+00, -5.7376e-01, -1.3511e-01,  1.9994e-01,\n",
            "         4.0292e-01,  4.8555e-01,  4.9777e-01,  5.0934e-01,  5.7900e-01,\n",
            "         7.2675e-01,  9.2464e-01,  1.1077e+00,  1.1953e+00,  1.1146e+00,\n",
            "         8.2514e-01,  3.4278e-01, -2.4795e-01, -8.0973e-01, -1.1984e+00,\n",
            "        -1.3196e+00, -1.1642e+00, -8.0615e-01, -3.6679e-01,  3.3749e-02,\n",
            "         3.1685e-01,  4.6468e-01,  5.1338e-01,  5.2616e-01,  5.6231e-01,\n",
            "         6.5762e-01,  8.1940e-01,  1.0270e+00,  1.2300e+00,  1.3494e+00,\n",
            "         1.2973e+00,  1.0190e+00,  5.3332e-01, -6.4991e-02, -6.5245e-01,\n",
            "        -1.1406e+00, -1.5102e+00, -1.7965e+00, -2.0431e+00, -2.2611e+00,\n",
            "        -2.4131e+00, -2.4273e+00, -2.2299e+00, -1.7831e+00, -1.1105e+00,\n",
            "        -2.9692e-01,  5.3652e-01,  1.2707e+00,  1.8234e+00,  2.1697e+00,\n",
            "         2.3387e+00,  2.3893e+00,  2.3739e+00,  2.3111e+00,  2.1812e+00,\n",
            "         1.9463e+00,  1.5789e+00,  1.0782e+00,  4.6867e-01, -2.0911e-01,\n",
            "        -9.0306e-01, -1.5456e+00, -2.0533e+00, -2.3446e+00, -2.3722e+00,\n",
            "        -2.1501e+00, -1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,\n",
            "         9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,\n",
            "         1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01,\n",
            "        -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01,\n",
            "        -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01,\n",
            "        -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,\n",
            "         7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,\n",
            "         5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,\n",
            "         1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01,\n",
            "        -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01,\n",
            "        -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,\n",
            "         3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02,\n",
            "        -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01,\n",
            "        -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,\n",
            "         1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,\n",
            "         1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01,\n",
            "        -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01,\n",
            "        -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,\n",
            "         8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,\n",
            "         3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01,\n",
            "        -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,\n",
            "         1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01,\n",
            "        -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,\n",
            "         3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01,\n",
            "        -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03,\n",
            "        -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,\n",
            "         2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37905:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-7.5122e-01, -4.4604e-01, -1.9107e-01, -7.1455e-03,  1.4235e-01,\n",
            "         3.2046e-01,  5.7293e-01,  8.9858e-01,  1.2433e+00,  1.5126e+00,\n",
            "         1.5989e+00,  1.4237e+00,  9.8365e-01,  3.7461e-01, -2.3109e-01,\n",
            "        -6.5392e-01, -7.8810e-01, -6.4674e-01, -3.4449e-01, -3.2012e-02,\n",
            "         1.7608e-01,  2.4124e-01,  1.9726e-01,  1.1710e-01,  7.3978e-02,\n",
            "         1.1388e-01,  2.4532e-01,  4.4441e-01,  6.6823e-01,  8.6703e-01,\n",
            "         9.9041e-01,  9.9130e-01,  8.3494e-01,  5.1252e-01,  5.0220e-02,\n",
            "        -4.9365e-01, -1.0412e+00, -1.5094e+00, -1.8232e+00, -1.9290e+00,\n",
            "        -1.8101e+00, -1.4959e+00, -1.0548e+00, -5.7376e-01, -1.3511e-01,\n",
            "         1.9994e-01,  4.0292e-01,  4.8555e-01,  4.9777e-01,  5.0934e-01,\n",
            "         5.7900e-01,  7.2675e-01,  9.2464e-01,  1.1077e+00,  1.1953e+00,\n",
            "         1.1146e+00,  8.2514e-01,  3.4278e-01, -2.4795e-01, -8.0973e-01,\n",
            "        -1.1984e+00, -1.3196e+00, -1.1642e+00, -8.0615e-01, -3.6679e-01,\n",
            "         3.3749e-02,  3.1685e-01,  4.6468e-01,  5.1338e-01,  5.2616e-01,\n",
            "         5.6231e-01,  6.5762e-01,  8.1940e-01,  1.0270e+00,  1.2300e+00,\n",
            "         1.3494e+00,  1.2973e+00,  1.0190e+00,  5.3332e-01, -6.4991e-02,\n",
            "        -6.5245e-01, -1.1406e+00, -1.5102e+00, -1.7965e+00, -2.0431e+00,\n",
            "        -2.2611e+00, -2.4131e+00, -2.4273e+00, -2.2299e+00, -1.7831e+00,\n",
            "        -1.1105e+00, -2.9692e-01,  5.3652e-01,  1.2707e+00,  1.8234e+00,\n",
            "         2.1697e+00,  2.3387e+00,  2.3893e+00,  2.3739e+00,  2.3111e+00,\n",
            "         2.1812e+00,  1.9463e+00,  1.5789e+00,  1.0782e+00,  4.6867e-01,\n",
            "        -2.0911e-01, -9.0306e-01, -1.5456e+00, -2.0533e+00, -2.3446e+00,\n",
            "        -2.3722e+00, -2.1501e+00, -1.7503e+00, -1.2689e+00, -7.8211e-01,\n",
            "        -3.2541e-01,  9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,\n",
            "         1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,\n",
            "         2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01,\n",
            "        -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01,\n",
            "        -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,\n",
            "         5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,\n",
            "         5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,\n",
            "         3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01,\n",
            "        -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01,\n",
            "        -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01,\n",
            "        -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,\n",
            "         7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01,\n",
            "        -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,\n",
            "         8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,\n",
            "         5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01,\n",
            "        -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01,\n",
            "        -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,\n",
            "         4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,\n",
            "         8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01,\n",
            "        -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,\n",
            "         5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02,\n",
            "        -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,\n",
            "         3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01,\n",
            "        -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,\n",
            "         1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02,\n",
            "        -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02,\n",
            "        -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37906:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.4235e-01,  3.2046e-01,  5.7293e-01,  8.9858e-01,  1.2433e+00,\n",
            "         1.5126e+00,  1.5989e+00,  1.4237e+00,  9.8365e-01,  3.7461e-01,\n",
            "        -2.3109e-01, -6.5392e-01, -7.8810e-01, -6.4674e-01, -3.4449e-01,\n",
            "        -3.2012e-02,  1.7608e-01,  2.4124e-01,  1.9726e-01,  1.1710e-01,\n",
            "         7.3978e-02,  1.1388e-01,  2.4532e-01,  4.4441e-01,  6.6823e-01,\n",
            "         8.6703e-01,  9.9041e-01,  9.9130e-01,  8.3494e-01,  5.1252e-01,\n",
            "         5.0220e-02, -4.9365e-01, -1.0412e+00, -1.5094e+00, -1.8232e+00,\n",
            "        -1.9290e+00, -1.8101e+00, -1.4959e+00, -1.0548e+00, -5.7376e-01,\n",
            "        -1.3511e-01,  1.9994e-01,  4.0292e-01,  4.8555e-01,  4.9777e-01,\n",
            "         5.0934e-01,  5.7900e-01,  7.2675e-01,  9.2464e-01,  1.1077e+00,\n",
            "         1.1953e+00,  1.1146e+00,  8.2514e-01,  3.4278e-01, -2.4795e-01,\n",
            "        -8.0973e-01, -1.1984e+00, -1.3196e+00, -1.1642e+00, -8.0615e-01,\n",
            "        -3.6679e-01,  3.3749e-02,  3.1685e-01,  4.6468e-01,  5.1338e-01,\n",
            "         5.2616e-01,  5.6231e-01,  6.5762e-01,  8.1940e-01,  1.0270e+00,\n",
            "         1.2300e+00,  1.3494e+00,  1.2973e+00,  1.0190e+00,  5.3332e-01,\n",
            "        -6.4991e-02, -6.5245e-01, -1.1406e+00, -1.5102e+00, -1.7965e+00,\n",
            "        -2.0431e+00, -2.2611e+00, -2.4131e+00, -2.4273e+00, -2.2299e+00,\n",
            "        -1.7831e+00, -1.1105e+00, -2.9692e-01,  5.3652e-01,  1.2707e+00,\n",
            "         1.8234e+00,  2.1697e+00,  2.3387e+00,  2.3893e+00,  2.3739e+00,\n",
            "         2.3111e+00,  2.1812e+00,  1.9463e+00,  1.5789e+00,  1.0782e+00,\n",
            "         4.6867e-01, -2.0911e-01, -9.0306e-01, -1.5456e+00, -2.0533e+00,\n",
            "        -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00, -1.2689e+00,\n",
            "        -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,  7.8659e-01,\n",
            "         9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,\n",
            "         4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01,\n",
            "        -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01,\n",
            "        -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,\n",
            "         2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,\n",
            "         6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,\n",
            "         4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01,\n",
            "        -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01,\n",
            "        -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00,\n",
            "        -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,\n",
            "         4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01,\n",
            "        -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,\n",
            "         6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,\n",
            "         9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01,\n",
            "        -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01,\n",
            "        -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,\n",
            "         8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,\n",
            "         1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01,\n",
            "        -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01,\n",
            "        -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02,\n",
            "        -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,\n",
            "         1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02,\n",
            "        -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01,\n",
            "        -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02,\n",
            "        -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02,\n",
            "        -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,\n",
            "         5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37907:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.2433e+00,  1.5126e+00,  1.5989e+00,  1.4237e+00,  9.8365e-01,\n",
            "         3.7461e-01, -2.3109e-01, -6.5392e-01, -7.8810e-01, -6.4674e-01,\n",
            "        -3.4449e-01, -3.2012e-02,  1.7608e-01,  2.4124e-01,  1.9726e-01,\n",
            "         1.1710e-01,  7.3978e-02,  1.1388e-01,  2.4532e-01,  4.4441e-01,\n",
            "         6.6823e-01,  8.6703e-01,  9.9041e-01,  9.9130e-01,  8.3494e-01,\n",
            "         5.1252e-01,  5.0220e-02, -4.9365e-01, -1.0412e+00, -1.5094e+00,\n",
            "        -1.8232e+00, -1.9290e+00, -1.8101e+00, -1.4959e+00, -1.0548e+00,\n",
            "        -5.7376e-01, -1.3511e-01,  1.9994e-01,  4.0292e-01,  4.8555e-01,\n",
            "         4.9777e-01,  5.0934e-01,  5.7900e-01,  7.2675e-01,  9.2464e-01,\n",
            "         1.1077e+00,  1.1953e+00,  1.1146e+00,  8.2514e-01,  3.4278e-01,\n",
            "        -2.4795e-01, -8.0973e-01, -1.1984e+00, -1.3196e+00, -1.1642e+00,\n",
            "        -8.0615e-01, -3.6679e-01,  3.3749e-02,  3.1685e-01,  4.6468e-01,\n",
            "         5.1338e-01,  5.2616e-01,  5.6231e-01,  6.5762e-01,  8.1940e-01,\n",
            "         1.0270e+00,  1.2300e+00,  1.3494e+00,  1.2973e+00,  1.0190e+00,\n",
            "         5.3332e-01, -6.4991e-02, -6.5245e-01, -1.1406e+00, -1.5102e+00,\n",
            "        -1.7965e+00, -2.0431e+00, -2.2611e+00, -2.4131e+00, -2.4273e+00,\n",
            "        -2.2299e+00, -1.7831e+00, -1.1105e+00, -2.9692e-01,  5.3652e-01,\n",
            "         1.2707e+00,  1.8234e+00,  2.1697e+00,  2.3387e+00,  2.3893e+00,\n",
            "         2.3739e+00,  2.3111e+00,  2.1812e+00,  1.9463e+00,  1.5789e+00,\n",
            "         1.0782e+00,  4.6867e-01, -2.0911e-01, -9.0306e-01, -1.5456e+00,\n",
            "        -2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00,\n",
            "        -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,\n",
            "         7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,\n",
            "         6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01,\n",
            "        -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01,\n",
            "        -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01,\n",
            "        -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,\n",
            "         7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,\n",
            "         4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02,\n",
            "        -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02,\n",
            "        -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00,\n",
            "        -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,\n",
            "         6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01,\n",
            "        -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,\n",
            "         4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,\n",
            "         1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01,\n",
            "        -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01,\n",
            "        -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01,\n",
            "        -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,\n",
            "         1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01,\n",
            "        -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01,\n",
            "        -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,\n",
            "         7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,\n",
            "         2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01,\n",
            "        -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02,\n",
            "        -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,\n",
            "         1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,\n",
            "         2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,\n",
            "         5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37908:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 9.8365e-01,  3.7461e-01, -2.3109e-01, -6.5392e-01, -7.8810e-01,\n",
            "        -6.4674e-01, -3.4449e-01, -3.2012e-02,  1.7608e-01,  2.4124e-01,\n",
            "         1.9726e-01,  1.1710e-01,  7.3978e-02,  1.1388e-01,  2.4532e-01,\n",
            "         4.4441e-01,  6.6823e-01,  8.6703e-01,  9.9041e-01,  9.9130e-01,\n",
            "         8.3494e-01,  5.1252e-01,  5.0220e-02, -4.9365e-01, -1.0412e+00,\n",
            "        -1.5094e+00, -1.8232e+00, -1.9290e+00, -1.8101e+00, -1.4959e+00,\n",
            "        -1.0548e+00, -5.7376e-01, -1.3511e-01,  1.9994e-01,  4.0292e-01,\n",
            "         4.8555e-01,  4.9777e-01,  5.0934e-01,  5.7900e-01,  7.2675e-01,\n",
            "         9.2464e-01,  1.1077e+00,  1.1953e+00,  1.1146e+00,  8.2514e-01,\n",
            "         3.4278e-01, -2.4795e-01, -8.0973e-01, -1.1984e+00, -1.3196e+00,\n",
            "        -1.1642e+00, -8.0615e-01, -3.6679e-01,  3.3749e-02,  3.1685e-01,\n",
            "         4.6468e-01,  5.1338e-01,  5.2616e-01,  5.6231e-01,  6.5762e-01,\n",
            "         8.1940e-01,  1.0270e+00,  1.2300e+00,  1.3494e+00,  1.2973e+00,\n",
            "         1.0190e+00,  5.3332e-01, -6.4991e-02, -6.5245e-01, -1.1406e+00,\n",
            "        -1.5102e+00, -1.7965e+00, -2.0431e+00, -2.2611e+00, -2.4131e+00,\n",
            "        -2.4273e+00, -2.2299e+00, -1.7831e+00, -1.1105e+00, -2.9692e-01,\n",
            "         5.3652e-01,  1.2707e+00,  1.8234e+00,  2.1697e+00,  2.3387e+00,\n",
            "         2.3893e+00,  2.3739e+00,  2.3111e+00,  2.1812e+00,  1.9463e+00,\n",
            "         1.5789e+00,  1.0782e+00,  4.6867e-01, -2.0911e-01, -9.0306e-01,\n",
            "        -1.5456e+00, -2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00,\n",
            "        -1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,\n",
            "         4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,\n",
            "         8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02,\n",
            "        -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01,\n",
            "        -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01,\n",
            "        -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,\n",
            "         8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,\n",
            "         5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01,\n",
            "        -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01,\n",
            "        -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00,\n",
            "        -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,\n",
            "         6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01,\n",
            "        -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,\n",
            "         1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,\n",
            "         1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01,\n",
            "        -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01,\n",
            "        -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01,\n",
            "        -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,\n",
            "         1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01,\n",
            "        -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01,\n",
            "        -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,\n",
            "         1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01,\n",
            "        -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,\n",
            "         1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01,\n",
            "        -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02,\n",
            "        -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,\n",
            "         4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,\n",
            "         3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,\n",
            "         8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01,\n",
            "        -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37909:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-7.8810e-01, -6.4674e-01, -3.4449e-01, -3.2012e-02,  1.7608e-01,\n",
            "         2.4124e-01,  1.9726e-01,  1.1710e-01,  7.3978e-02,  1.1388e-01,\n",
            "         2.4532e-01,  4.4441e-01,  6.6823e-01,  8.6703e-01,  9.9041e-01,\n",
            "         9.9130e-01,  8.3494e-01,  5.1252e-01,  5.0220e-02, -4.9365e-01,\n",
            "        -1.0412e+00, -1.5094e+00, -1.8232e+00, -1.9290e+00, -1.8101e+00,\n",
            "        -1.4959e+00, -1.0548e+00, -5.7376e-01, -1.3511e-01,  1.9994e-01,\n",
            "         4.0292e-01,  4.8555e-01,  4.9777e-01,  5.0934e-01,  5.7900e-01,\n",
            "         7.2675e-01,  9.2464e-01,  1.1077e+00,  1.1953e+00,  1.1146e+00,\n",
            "         8.2514e-01,  3.4278e-01, -2.4795e-01, -8.0973e-01, -1.1984e+00,\n",
            "        -1.3196e+00, -1.1642e+00, -8.0615e-01, -3.6679e-01,  3.3749e-02,\n",
            "         3.1685e-01,  4.6468e-01,  5.1338e-01,  5.2616e-01,  5.6231e-01,\n",
            "         6.5762e-01,  8.1940e-01,  1.0270e+00,  1.2300e+00,  1.3494e+00,\n",
            "         1.2973e+00,  1.0190e+00,  5.3332e-01, -6.4991e-02, -6.5245e-01,\n",
            "        -1.1406e+00, -1.5102e+00, -1.7965e+00, -2.0431e+00, -2.2611e+00,\n",
            "        -2.4131e+00, -2.4273e+00, -2.2299e+00, -1.7831e+00, -1.1105e+00,\n",
            "        -2.9692e-01,  5.3652e-01,  1.2707e+00,  1.8234e+00,  2.1697e+00,\n",
            "         2.3387e+00,  2.3893e+00,  2.3739e+00,  2.3111e+00,  2.1812e+00,\n",
            "         1.9463e+00,  1.5789e+00,  1.0782e+00,  4.6867e-01, -2.0911e-01,\n",
            "        -9.0306e-01, -1.5456e+00, -2.0533e+00, -2.3446e+00, -2.3722e+00,\n",
            "        -2.1501e+00, -1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,\n",
            "         9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,\n",
            "         1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01,\n",
            "        -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01,\n",
            "        -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01,\n",
            "        -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,\n",
            "         7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,\n",
            "         5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,\n",
            "         1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01,\n",
            "        -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01,\n",
            "        -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,\n",
            "         3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02,\n",
            "        -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01,\n",
            "        -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,\n",
            "         1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,\n",
            "         1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01,\n",
            "        -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01,\n",
            "        -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,\n",
            "         8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,\n",
            "         3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01,\n",
            "        -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,\n",
            "         1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01,\n",
            "        -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,\n",
            "         3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01,\n",
            "        -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03,\n",
            "        -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,\n",
            "         2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01,\n",
            "        -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,\n",
            "         9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01,\n",
            "        -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01,\n",
            "        -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37910:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.7608e-01,  2.4124e-01,  1.9726e-01,  1.1710e-01,  7.3978e-02,\n",
            "         1.1388e-01,  2.4532e-01,  4.4441e-01,  6.6823e-01,  8.6703e-01,\n",
            "         9.9041e-01,  9.9130e-01,  8.3494e-01,  5.1252e-01,  5.0220e-02,\n",
            "        -4.9365e-01, -1.0412e+00, -1.5094e+00, -1.8232e+00, -1.9290e+00,\n",
            "        -1.8101e+00, -1.4959e+00, -1.0548e+00, -5.7376e-01, -1.3511e-01,\n",
            "         1.9994e-01,  4.0292e-01,  4.8555e-01,  4.9777e-01,  5.0934e-01,\n",
            "         5.7900e-01,  7.2675e-01,  9.2464e-01,  1.1077e+00,  1.1953e+00,\n",
            "         1.1146e+00,  8.2514e-01,  3.4278e-01, -2.4795e-01, -8.0973e-01,\n",
            "        -1.1984e+00, -1.3196e+00, -1.1642e+00, -8.0615e-01, -3.6679e-01,\n",
            "         3.3749e-02,  3.1685e-01,  4.6468e-01,  5.1338e-01,  5.2616e-01,\n",
            "         5.6231e-01,  6.5762e-01,  8.1940e-01,  1.0270e+00,  1.2300e+00,\n",
            "         1.3494e+00,  1.2973e+00,  1.0190e+00,  5.3332e-01, -6.4991e-02,\n",
            "        -6.5245e-01, -1.1406e+00, -1.5102e+00, -1.7965e+00, -2.0431e+00,\n",
            "        -2.2611e+00, -2.4131e+00, -2.4273e+00, -2.2299e+00, -1.7831e+00,\n",
            "        -1.1105e+00, -2.9692e-01,  5.3652e-01,  1.2707e+00,  1.8234e+00,\n",
            "         2.1697e+00,  2.3387e+00,  2.3893e+00,  2.3739e+00,  2.3111e+00,\n",
            "         2.1812e+00,  1.9463e+00,  1.5789e+00,  1.0782e+00,  4.6867e-01,\n",
            "        -2.0911e-01, -9.0306e-01, -1.5456e+00, -2.0533e+00, -2.3446e+00,\n",
            "        -2.3722e+00, -2.1501e+00, -1.7503e+00, -1.2689e+00, -7.8211e-01,\n",
            "        -3.2541e-01,  9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,\n",
            "         1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,\n",
            "         2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01,\n",
            "        -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01,\n",
            "        -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,\n",
            "         5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,\n",
            "         5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,\n",
            "         3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01,\n",
            "        -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01,\n",
            "        -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01,\n",
            "        -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,\n",
            "         7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01,\n",
            "        -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,\n",
            "         8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,\n",
            "         5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01,\n",
            "        -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01,\n",
            "        -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,\n",
            "         4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,\n",
            "         8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01,\n",
            "        -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,\n",
            "         5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02,\n",
            "        -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,\n",
            "         3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01,\n",
            "        -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,\n",
            "         1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02,\n",
            "        -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02,\n",
            "        -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,\n",
            "         7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01,\n",
            "        -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01,\n",
            "        -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01,\n",
            "        -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37911:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 7.3978e-02,  1.1388e-01,  2.4532e-01,  4.4441e-01,  6.6823e-01,\n",
            "         8.6703e-01,  9.9041e-01,  9.9130e-01,  8.3494e-01,  5.1252e-01,\n",
            "         5.0220e-02, -4.9365e-01, -1.0412e+00, -1.5094e+00, -1.8232e+00,\n",
            "        -1.9290e+00, -1.8101e+00, -1.4959e+00, -1.0548e+00, -5.7376e-01,\n",
            "        -1.3511e-01,  1.9994e-01,  4.0292e-01,  4.8555e-01,  4.9777e-01,\n",
            "         5.0934e-01,  5.7900e-01,  7.2675e-01,  9.2464e-01,  1.1077e+00,\n",
            "         1.1953e+00,  1.1146e+00,  8.2514e-01,  3.4278e-01, -2.4795e-01,\n",
            "        -8.0973e-01, -1.1984e+00, -1.3196e+00, -1.1642e+00, -8.0615e-01,\n",
            "        -3.6679e-01,  3.3749e-02,  3.1685e-01,  4.6468e-01,  5.1338e-01,\n",
            "         5.2616e-01,  5.6231e-01,  6.5762e-01,  8.1940e-01,  1.0270e+00,\n",
            "         1.2300e+00,  1.3494e+00,  1.2973e+00,  1.0190e+00,  5.3332e-01,\n",
            "        -6.4991e-02, -6.5245e-01, -1.1406e+00, -1.5102e+00, -1.7965e+00,\n",
            "        -2.0431e+00, -2.2611e+00, -2.4131e+00, -2.4273e+00, -2.2299e+00,\n",
            "        -1.7831e+00, -1.1105e+00, -2.9692e-01,  5.3652e-01,  1.2707e+00,\n",
            "         1.8234e+00,  2.1697e+00,  2.3387e+00,  2.3893e+00,  2.3739e+00,\n",
            "         2.3111e+00,  2.1812e+00,  1.9463e+00,  1.5789e+00,  1.0782e+00,\n",
            "         4.6867e-01, -2.0911e-01, -9.0306e-01, -1.5456e+00, -2.0533e+00,\n",
            "        -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00, -1.2689e+00,\n",
            "        -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,  7.8659e-01,\n",
            "         9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,\n",
            "         4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01,\n",
            "        -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01,\n",
            "        -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,\n",
            "         2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,\n",
            "         6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,\n",
            "         4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01,\n",
            "        -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01,\n",
            "        -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00,\n",
            "        -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,\n",
            "         4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01,\n",
            "        -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,\n",
            "         6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,\n",
            "         9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01,\n",
            "        -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01,\n",
            "        -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,\n",
            "         8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,\n",
            "         1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01,\n",
            "        -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01,\n",
            "        -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02,\n",
            "        -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,\n",
            "         1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02,\n",
            "        -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01,\n",
            "        -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02,\n",
            "        -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02,\n",
            "        -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,\n",
            "         5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,\n",
            "         2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01,\n",
            "        -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01,\n",
            "        -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,\n",
            "         1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37912:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 6.6823e-01,  8.6703e-01,  9.9041e-01,  9.9130e-01,  8.3494e-01,\n",
            "         5.1252e-01,  5.0220e-02, -4.9365e-01, -1.0412e+00, -1.5094e+00,\n",
            "        -1.8232e+00, -1.9290e+00, -1.8101e+00, -1.4959e+00, -1.0548e+00,\n",
            "        -5.7376e-01, -1.3511e-01,  1.9994e-01,  4.0292e-01,  4.8555e-01,\n",
            "         4.9777e-01,  5.0934e-01,  5.7900e-01,  7.2675e-01,  9.2464e-01,\n",
            "         1.1077e+00,  1.1953e+00,  1.1146e+00,  8.2514e-01,  3.4278e-01,\n",
            "        -2.4795e-01, -8.0973e-01, -1.1984e+00, -1.3196e+00, -1.1642e+00,\n",
            "        -8.0615e-01, -3.6679e-01,  3.3749e-02,  3.1685e-01,  4.6468e-01,\n",
            "         5.1338e-01,  5.2616e-01,  5.6231e-01,  6.5762e-01,  8.1940e-01,\n",
            "         1.0270e+00,  1.2300e+00,  1.3494e+00,  1.2973e+00,  1.0190e+00,\n",
            "         5.3332e-01, -6.4991e-02, -6.5245e-01, -1.1406e+00, -1.5102e+00,\n",
            "        -1.7965e+00, -2.0431e+00, -2.2611e+00, -2.4131e+00, -2.4273e+00,\n",
            "        -2.2299e+00, -1.7831e+00, -1.1105e+00, -2.9692e-01,  5.3652e-01,\n",
            "         1.2707e+00,  1.8234e+00,  2.1697e+00,  2.3387e+00,  2.3893e+00,\n",
            "         2.3739e+00,  2.3111e+00,  2.1812e+00,  1.9463e+00,  1.5789e+00,\n",
            "         1.0782e+00,  4.6867e-01, -2.0911e-01, -9.0306e-01, -1.5456e+00,\n",
            "        -2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00,\n",
            "        -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,\n",
            "         7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,\n",
            "         6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01,\n",
            "        -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01,\n",
            "        -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01,\n",
            "        -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,\n",
            "         7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,\n",
            "         4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02,\n",
            "        -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02,\n",
            "        -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00,\n",
            "        -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,\n",
            "         6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01,\n",
            "        -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,\n",
            "         4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,\n",
            "         1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01,\n",
            "        -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01,\n",
            "        -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01,\n",
            "        -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,\n",
            "         1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01,\n",
            "        -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01,\n",
            "        -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,\n",
            "         7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,\n",
            "         2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01,\n",
            "        -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02,\n",
            "        -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,\n",
            "         1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,\n",
            "         2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,\n",
            "         5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01,\n",
            "        -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01,\n",
            "        -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01,\n",
            "        -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,\n",
            "         8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37913:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 8.3494e-01,  5.1252e-01,  5.0220e-02, -4.9365e-01, -1.0412e+00,\n",
            "        -1.5094e+00, -1.8232e+00, -1.9290e+00, -1.8101e+00, -1.4959e+00,\n",
            "        -1.0548e+00, -5.7376e-01, -1.3511e-01,  1.9994e-01,  4.0292e-01,\n",
            "         4.8555e-01,  4.9777e-01,  5.0934e-01,  5.7900e-01,  7.2675e-01,\n",
            "         9.2464e-01,  1.1077e+00,  1.1953e+00,  1.1146e+00,  8.2514e-01,\n",
            "         3.4278e-01, -2.4795e-01, -8.0973e-01, -1.1984e+00, -1.3196e+00,\n",
            "        -1.1642e+00, -8.0615e-01, -3.6679e-01,  3.3749e-02,  3.1685e-01,\n",
            "         4.6468e-01,  5.1338e-01,  5.2616e-01,  5.6231e-01,  6.5762e-01,\n",
            "         8.1940e-01,  1.0270e+00,  1.2300e+00,  1.3494e+00,  1.2973e+00,\n",
            "         1.0190e+00,  5.3332e-01, -6.4991e-02, -6.5245e-01, -1.1406e+00,\n",
            "        -1.5102e+00, -1.7965e+00, -2.0431e+00, -2.2611e+00, -2.4131e+00,\n",
            "        -2.4273e+00, -2.2299e+00, -1.7831e+00, -1.1105e+00, -2.9692e-01,\n",
            "         5.3652e-01,  1.2707e+00,  1.8234e+00,  2.1697e+00,  2.3387e+00,\n",
            "         2.3893e+00,  2.3739e+00,  2.3111e+00,  2.1812e+00,  1.9463e+00,\n",
            "         1.5789e+00,  1.0782e+00,  4.6867e-01, -2.0911e-01, -9.0306e-01,\n",
            "        -1.5456e+00, -2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00,\n",
            "        -1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,\n",
            "         4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,\n",
            "         8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02,\n",
            "        -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01,\n",
            "        -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01,\n",
            "        -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,\n",
            "         8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,\n",
            "         5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01,\n",
            "        -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01,\n",
            "        -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00,\n",
            "        -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,\n",
            "         6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01,\n",
            "        -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,\n",
            "         1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,\n",
            "         1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01,\n",
            "        -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01,\n",
            "        -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01,\n",
            "        -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,\n",
            "         1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01,\n",
            "        -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01,\n",
            "        -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,\n",
            "         1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01,\n",
            "        -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,\n",
            "         1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01,\n",
            "        -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02,\n",
            "        -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,\n",
            "         4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,\n",
            "         3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,\n",
            "         8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01,\n",
            "        -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01,\n",
            "        -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01,\n",
            "        -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,\n",
            "         7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,\n",
            "         8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37914:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.0412e+00, -1.5094e+00, -1.8232e+00, -1.9290e+00, -1.8101e+00,\n",
            "        -1.4959e+00, -1.0548e+00, -5.7376e-01, -1.3511e-01,  1.9994e-01,\n",
            "         4.0292e-01,  4.8555e-01,  4.9777e-01,  5.0934e-01,  5.7900e-01,\n",
            "         7.2675e-01,  9.2464e-01,  1.1077e+00,  1.1953e+00,  1.1146e+00,\n",
            "         8.2514e-01,  3.4278e-01, -2.4795e-01, -8.0973e-01, -1.1984e+00,\n",
            "        -1.3196e+00, -1.1642e+00, -8.0615e-01, -3.6679e-01,  3.3749e-02,\n",
            "         3.1685e-01,  4.6468e-01,  5.1338e-01,  5.2616e-01,  5.6231e-01,\n",
            "         6.5762e-01,  8.1940e-01,  1.0270e+00,  1.2300e+00,  1.3494e+00,\n",
            "         1.2973e+00,  1.0190e+00,  5.3332e-01, -6.4991e-02, -6.5245e-01,\n",
            "        -1.1406e+00, -1.5102e+00, -1.7965e+00, -2.0431e+00, -2.2611e+00,\n",
            "        -2.4131e+00, -2.4273e+00, -2.2299e+00, -1.7831e+00, -1.1105e+00,\n",
            "        -2.9692e-01,  5.3652e-01,  1.2707e+00,  1.8234e+00,  2.1697e+00,\n",
            "         2.3387e+00,  2.3893e+00,  2.3739e+00,  2.3111e+00,  2.1812e+00,\n",
            "         1.9463e+00,  1.5789e+00,  1.0782e+00,  4.6867e-01, -2.0911e-01,\n",
            "        -9.0306e-01, -1.5456e+00, -2.0533e+00, -2.3446e+00, -2.3722e+00,\n",
            "        -2.1501e+00, -1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,\n",
            "         9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,\n",
            "         1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01,\n",
            "        -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01,\n",
            "        -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01,\n",
            "        -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,\n",
            "         7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,\n",
            "         5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,\n",
            "         1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01,\n",
            "        -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01,\n",
            "        -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,\n",
            "         3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02,\n",
            "        -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01,\n",
            "        -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,\n",
            "         1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,\n",
            "         1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01,\n",
            "        -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01,\n",
            "        -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,\n",
            "         8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,\n",
            "         3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01,\n",
            "        -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,\n",
            "         1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01,\n",
            "        -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,\n",
            "         3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01,\n",
            "        -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03,\n",
            "        -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,\n",
            "         2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01,\n",
            "        -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,\n",
            "         9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01,\n",
            "        -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01,\n",
            "        -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01,\n",
            "        -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,\n",
            "         5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,\n",
            "         9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02,\n",
            "        -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37915:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.8101e+00, -1.4959e+00, -1.0548e+00, -5.7376e-01, -1.3511e-01,\n",
            "         1.9994e-01,  4.0292e-01,  4.8555e-01,  4.9777e-01,  5.0934e-01,\n",
            "         5.7900e-01,  7.2675e-01,  9.2464e-01,  1.1077e+00,  1.1953e+00,\n",
            "         1.1146e+00,  8.2514e-01,  3.4278e-01, -2.4795e-01, -8.0973e-01,\n",
            "        -1.1984e+00, -1.3196e+00, -1.1642e+00, -8.0615e-01, -3.6679e-01,\n",
            "         3.3749e-02,  3.1685e-01,  4.6468e-01,  5.1338e-01,  5.2616e-01,\n",
            "         5.6231e-01,  6.5762e-01,  8.1940e-01,  1.0270e+00,  1.2300e+00,\n",
            "         1.3494e+00,  1.2973e+00,  1.0190e+00,  5.3332e-01, -6.4991e-02,\n",
            "        -6.5245e-01, -1.1406e+00, -1.5102e+00, -1.7965e+00, -2.0431e+00,\n",
            "        -2.2611e+00, -2.4131e+00, -2.4273e+00, -2.2299e+00, -1.7831e+00,\n",
            "        -1.1105e+00, -2.9692e-01,  5.3652e-01,  1.2707e+00,  1.8234e+00,\n",
            "         2.1697e+00,  2.3387e+00,  2.3893e+00,  2.3739e+00,  2.3111e+00,\n",
            "         2.1812e+00,  1.9463e+00,  1.5789e+00,  1.0782e+00,  4.6867e-01,\n",
            "        -2.0911e-01, -9.0306e-01, -1.5456e+00, -2.0533e+00, -2.3446e+00,\n",
            "        -2.3722e+00, -2.1501e+00, -1.7503e+00, -1.2689e+00, -7.8211e-01,\n",
            "        -3.2541e-01,  9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,\n",
            "         1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,\n",
            "         2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01,\n",
            "        -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01,\n",
            "        -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,\n",
            "         5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,\n",
            "         5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,\n",
            "         3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01,\n",
            "        -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01,\n",
            "        -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01,\n",
            "        -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,\n",
            "         7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01,\n",
            "        -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,\n",
            "         8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,\n",
            "         5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01,\n",
            "        -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01,\n",
            "        -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,\n",
            "         4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,\n",
            "         8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01,\n",
            "        -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,\n",
            "         5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02,\n",
            "        -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,\n",
            "         3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01,\n",
            "        -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,\n",
            "         1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02,\n",
            "        -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02,\n",
            "        -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,\n",
            "         7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01,\n",
            "        -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01,\n",
            "        -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01,\n",
            "        -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,\n",
            "         2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,\n",
            "         9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01,\n",
            "        -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00,\n",
            "        -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37916:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.3511e-01,  1.9994e-01,  4.0292e-01,  4.8555e-01,  4.9777e-01,\n",
            "         5.0934e-01,  5.7900e-01,  7.2675e-01,  9.2464e-01,  1.1077e+00,\n",
            "         1.1953e+00,  1.1146e+00,  8.2514e-01,  3.4278e-01, -2.4795e-01,\n",
            "        -8.0973e-01, -1.1984e+00, -1.3196e+00, -1.1642e+00, -8.0615e-01,\n",
            "        -3.6679e-01,  3.3749e-02,  3.1685e-01,  4.6468e-01,  5.1338e-01,\n",
            "         5.2616e-01,  5.6231e-01,  6.5762e-01,  8.1940e-01,  1.0270e+00,\n",
            "         1.2300e+00,  1.3494e+00,  1.2973e+00,  1.0190e+00,  5.3332e-01,\n",
            "        -6.4991e-02, -6.5245e-01, -1.1406e+00, -1.5102e+00, -1.7965e+00,\n",
            "        -2.0431e+00, -2.2611e+00, -2.4131e+00, -2.4273e+00, -2.2299e+00,\n",
            "        -1.7831e+00, -1.1105e+00, -2.9692e-01,  5.3652e-01,  1.2707e+00,\n",
            "         1.8234e+00,  2.1697e+00,  2.3387e+00,  2.3893e+00,  2.3739e+00,\n",
            "         2.3111e+00,  2.1812e+00,  1.9463e+00,  1.5789e+00,  1.0782e+00,\n",
            "         4.6867e-01, -2.0911e-01, -9.0306e-01, -1.5456e+00, -2.0533e+00,\n",
            "        -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00, -1.2689e+00,\n",
            "        -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,  7.8659e-01,\n",
            "         9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,\n",
            "         4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01,\n",
            "        -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01,\n",
            "        -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,\n",
            "         2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,\n",
            "         6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,\n",
            "         4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01,\n",
            "        -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01,\n",
            "        -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00,\n",
            "        -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,\n",
            "         4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01,\n",
            "        -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,\n",
            "         6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,\n",
            "         9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01,\n",
            "        -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01,\n",
            "        -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,\n",
            "         8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,\n",
            "         1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01,\n",
            "        -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01,\n",
            "        -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02,\n",
            "        -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,\n",
            "         1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02,\n",
            "        -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01,\n",
            "        -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02,\n",
            "        -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02,\n",
            "        -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,\n",
            "         5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,\n",
            "         2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01,\n",
            "        -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01,\n",
            "        -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,\n",
            "         1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,\n",
            "         9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,\n",
            "         3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00,\n",
            "        -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00,\n",
            "        -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37917:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 4.9777e-01,  5.0934e-01,  5.7900e-01,  7.2675e-01,  9.2464e-01,\n",
            "         1.1077e+00,  1.1953e+00,  1.1146e+00,  8.2514e-01,  3.4278e-01,\n",
            "        -2.4795e-01, -8.0973e-01, -1.1984e+00, -1.3196e+00, -1.1642e+00,\n",
            "        -8.0615e-01, -3.6679e-01,  3.3749e-02,  3.1685e-01,  4.6468e-01,\n",
            "         5.1338e-01,  5.2616e-01,  5.6231e-01,  6.5762e-01,  8.1940e-01,\n",
            "         1.0270e+00,  1.2300e+00,  1.3494e+00,  1.2973e+00,  1.0190e+00,\n",
            "         5.3332e-01, -6.4991e-02, -6.5245e-01, -1.1406e+00, -1.5102e+00,\n",
            "        -1.7965e+00, -2.0431e+00, -2.2611e+00, -2.4131e+00, -2.4273e+00,\n",
            "        -2.2299e+00, -1.7831e+00, -1.1105e+00, -2.9692e-01,  5.3652e-01,\n",
            "         1.2707e+00,  1.8234e+00,  2.1697e+00,  2.3387e+00,  2.3893e+00,\n",
            "         2.3739e+00,  2.3111e+00,  2.1812e+00,  1.9463e+00,  1.5789e+00,\n",
            "         1.0782e+00,  4.6867e-01, -2.0911e-01, -9.0306e-01, -1.5456e+00,\n",
            "        -2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00,\n",
            "        -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,\n",
            "         7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,\n",
            "         6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01,\n",
            "        -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01,\n",
            "        -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01,\n",
            "        -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,\n",
            "         7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,\n",
            "         4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02,\n",
            "        -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02,\n",
            "        -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00,\n",
            "        -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,\n",
            "         6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01,\n",
            "        -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,\n",
            "         4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,\n",
            "         1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01,\n",
            "        -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01,\n",
            "        -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01,\n",
            "        -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,\n",
            "         1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01,\n",
            "        -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01,\n",
            "        -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,\n",
            "         7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,\n",
            "         2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01,\n",
            "        -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02,\n",
            "        -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,\n",
            "         1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,\n",
            "         2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,\n",
            "         5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01,\n",
            "        -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01,\n",
            "        -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01,\n",
            "        -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,\n",
            "         8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,\n",
            "         6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01,\n",
            "        -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00,\n",
            "        -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,\n",
            "         2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37918:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 9.2464e-01,  1.1077e+00,  1.1953e+00,  1.1146e+00,  8.2514e-01,\n",
            "         3.4278e-01, -2.4795e-01, -8.0973e-01, -1.1984e+00, -1.3196e+00,\n",
            "        -1.1642e+00, -8.0615e-01, -3.6679e-01,  3.3749e-02,  3.1685e-01,\n",
            "         4.6468e-01,  5.1338e-01,  5.2616e-01,  5.6231e-01,  6.5762e-01,\n",
            "         8.1940e-01,  1.0270e+00,  1.2300e+00,  1.3494e+00,  1.2973e+00,\n",
            "         1.0190e+00,  5.3332e-01, -6.4991e-02, -6.5245e-01, -1.1406e+00,\n",
            "        -1.5102e+00, -1.7965e+00, -2.0431e+00, -2.2611e+00, -2.4131e+00,\n",
            "        -2.4273e+00, -2.2299e+00, -1.7831e+00, -1.1105e+00, -2.9692e-01,\n",
            "         5.3652e-01,  1.2707e+00,  1.8234e+00,  2.1697e+00,  2.3387e+00,\n",
            "         2.3893e+00,  2.3739e+00,  2.3111e+00,  2.1812e+00,  1.9463e+00,\n",
            "         1.5789e+00,  1.0782e+00,  4.6867e-01, -2.0911e-01, -9.0306e-01,\n",
            "        -1.5456e+00, -2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00,\n",
            "        -1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,\n",
            "         4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,\n",
            "         8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02,\n",
            "        -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01,\n",
            "        -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01,\n",
            "        -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,\n",
            "         8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,\n",
            "         5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01,\n",
            "        -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01,\n",
            "        -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00,\n",
            "        -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,\n",
            "         6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01,\n",
            "        -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,\n",
            "         1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,\n",
            "         1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01,\n",
            "        -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01,\n",
            "        -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01,\n",
            "        -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,\n",
            "         1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01,\n",
            "        -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01,\n",
            "        -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,\n",
            "         1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01,\n",
            "        -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,\n",
            "         1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01,\n",
            "        -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02,\n",
            "        -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,\n",
            "         4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,\n",
            "         3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,\n",
            "         8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01,\n",
            "        -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01,\n",
            "        -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01,\n",
            "        -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,\n",
            "         7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,\n",
            "         8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01,\n",
            "        -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00,\n",
            "        -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01,\n",
            "        -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,\n",
            "         1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37919:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 8.2514e-01,  3.4278e-01, -2.4795e-01, -8.0973e-01, -1.1984e+00,\n",
            "        -1.3196e+00, -1.1642e+00, -8.0615e-01, -3.6679e-01,  3.3749e-02,\n",
            "         3.1685e-01,  4.6468e-01,  5.1338e-01,  5.2616e-01,  5.6231e-01,\n",
            "         6.5762e-01,  8.1940e-01,  1.0270e+00,  1.2300e+00,  1.3494e+00,\n",
            "         1.2973e+00,  1.0190e+00,  5.3332e-01, -6.4991e-02, -6.5245e-01,\n",
            "        -1.1406e+00, -1.5102e+00, -1.7965e+00, -2.0431e+00, -2.2611e+00,\n",
            "        -2.4131e+00, -2.4273e+00, -2.2299e+00, -1.7831e+00, -1.1105e+00,\n",
            "        -2.9692e-01,  5.3652e-01,  1.2707e+00,  1.8234e+00,  2.1697e+00,\n",
            "         2.3387e+00,  2.3893e+00,  2.3739e+00,  2.3111e+00,  2.1812e+00,\n",
            "         1.9463e+00,  1.5789e+00,  1.0782e+00,  4.6867e-01, -2.0911e-01,\n",
            "        -9.0306e-01, -1.5456e+00, -2.0533e+00, -2.3446e+00, -2.3722e+00,\n",
            "        -2.1501e+00, -1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,\n",
            "         9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,\n",
            "         1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01,\n",
            "        -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01,\n",
            "        -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01,\n",
            "        -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,\n",
            "         7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,\n",
            "         5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,\n",
            "         1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01,\n",
            "        -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01,\n",
            "        -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,\n",
            "         3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02,\n",
            "        -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01,\n",
            "        -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,\n",
            "         1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,\n",
            "         1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01,\n",
            "        -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01,\n",
            "        -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,\n",
            "         8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,\n",
            "         3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01,\n",
            "        -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,\n",
            "         1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01,\n",
            "        -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,\n",
            "         3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01,\n",
            "        -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03,\n",
            "        -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,\n",
            "         2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01,\n",
            "        -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,\n",
            "         9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01,\n",
            "        -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01,\n",
            "        -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01,\n",
            "        -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,\n",
            "         5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,\n",
            "         9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02,\n",
            "        -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00,\n",
            "        -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01,\n",
            "        -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,\n",
            "         9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,\n",
            "         9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37920:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.1984e+00, -1.3196e+00, -1.1642e+00, -8.0615e-01, -3.6679e-01,\n",
            "         3.3749e-02,  3.1685e-01,  4.6468e-01,  5.1338e-01,  5.2616e-01,\n",
            "         5.6231e-01,  6.5762e-01,  8.1940e-01,  1.0270e+00,  1.2300e+00,\n",
            "         1.3494e+00,  1.2973e+00,  1.0190e+00,  5.3332e-01, -6.4991e-02,\n",
            "        -6.5245e-01, -1.1406e+00, -1.5102e+00, -1.7965e+00, -2.0431e+00,\n",
            "        -2.2611e+00, -2.4131e+00, -2.4273e+00, -2.2299e+00, -1.7831e+00,\n",
            "        -1.1105e+00, -2.9692e-01,  5.3652e-01,  1.2707e+00,  1.8234e+00,\n",
            "         2.1697e+00,  2.3387e+00,  2.3893e+00,  2.3739e+00,  2.3111e+00,\n",
            "         2.1812e+00,  1.9463e+00,  1.5789e+00,  1.0782e+00,  4.6867e-01,\n",
            "        -2.0911e-01, -9.0306e-01, -1.5456e+00, -2.0533e+00, -2.3446e+00,\n",
            "        -2.3722e+00, -2.1501e+00, -1.7503e+00, -1.2689e+00, -7.8211e-01,\n",
            "        -3.2541e-01,  9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,\n",
            "         1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,\n",
            "         2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01,\n",
            "        -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01,\n",
            "        -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,\n",
            "         5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,\n",
            "         5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,\n",
            "         3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01,\n",
            "        -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01,\n",
            "        -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01,\n",
            "        -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,\n",
            "         7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01,\n",
            "        -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,\n",
            "         8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,\n",
            "         5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01,\n",
            "        -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01,\n",
            "        -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,\n",
            "         4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,\n",
            "         8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01,\n",
            "        -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,\n",
            "         5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02,\n",
            "        -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,\n",
            "         3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01,\n",
            "        -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,\n",
            "         1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02,\n",
            "        -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02,\n",
            "        -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,\n",
            "         7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01,\n",
            "        -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01,\n",
            "        -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01,\n",
            "        -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,\n",
            "         2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,\n",
            "         9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01,\n",
            "        -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00,\n",
            "        -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01,\n",
            "        -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,\n",
            "         6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,\n",
            "         1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,\n",
            "         5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37921:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-3.6679e-01,  3.3749e-02,  3.1685e-01,  4.6468e-01,  5.1338e-01,\n",
            "         5.2616e-01,  5.6231e-01,  6.5762e-01,  8.1940e-01,  1.0270e+00,\n",
            "         1.2300e+00,  1.3494e+00,  1.2973e+00,  1.0190e+00,  5.3332e-01,\n",
            "        -6.4991e-02, -6.5245e-01, -1.1406e+00, -1.5102e+00, -1.7965e+00,\n",
            "        -2.0431e+00, -2.2611e+00, -2.4131e+00, -2.4273e+00, -2.2299e+00,\n",
            "        -1.7831e+00, -1.1105e+00, -2.9692e-01,  5.3652e-01,  1.2707e+00,\n",
            "         1.8234e+00,  2.1697e+00,  2.3387e+00,  2.3893e+00,  2.3739e+00,\n",
            "         2.3111e+00,  2.1812e+00,  1.9463e+00,  1.5789e+00,  1.0782e+00,\n",
            "         4.6867e-01, -2.0911e-01, -9.0306e-01, -1.5456e+00, -2.0533e+00,\n",
            "        -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00, -1.2689e+00,\n",
            "        -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,  7.8659e-01,\n",
            "         9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,\n",
            "         4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01,\n",
            "        -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01,\n",
            "        -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,\n",
            "         2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,\n",
            "         6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,\n",
            "         4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01,\n",
            "        -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01,\n",
            "        -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00,\n",
            "        -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,\n",
            "         4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01,\n",
            "        -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,\n",
            "         6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,\n",
            "         9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01,\n",
            "        -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01,\n",
            "        -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,\n",
            "         8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,\n",
            "         1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01,\n",
            "        -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01,\n",
            "        -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02,\n",
            "        -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,\n",
            "         1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02,\n",
            "        -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01,\n",
            "        -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02,\n",
            "        -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02,\n",
            "        -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,\n",
            "         5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,\n",
            "         2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01,\n",
            "        -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01,\n",
            "        -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,\n",
            "         1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,\n",
            "         9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,\n",
            "         3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00,\n",
            "        -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00,\n",
            "        -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,\n",
            "         4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,\n",
            "         1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,\n",
            "         5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01,\n",
            "        -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37922:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 5.1338e-01,  5.2616e-01,  5.6231e-01,  6.5762e-01,  8.1940e-01,\n",
            "         1.0270e+00,  1.2300e+00,  1.3494e+00,  1.2973e+00,  1.0190e+00,\n",
            "         5.3332e-01, -6.4991e-02, -6.5245e-01, -1.1406e+00, -1.5102e+00,\n",
            "        -1.7965e+00, -2.0431e+00, -2.2611e+00, -2.4131e+00, -2.4273e+00,\n",
            "        -2.2299e+00, -1.7831e+00, -1.1105e+00, -2.9692e-01,  5.3652e-01,\n",
            "         1.2707e+00,  1.8234e+00,  2.1697e+00,  2.3387e+00,  2.3893e+00,\n",
            "         2.3739e+00,  2.3111e+00,  2.1812e+00,  1.9463e+00,  1.5789e+00,\n",
            "         1.0782e+00,  4.6867e-01, -2.0911e-01, -9.0306e-01, -1.5456e+00,\n",
            "        -2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00,\n",
            "        -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,\n",
            "         7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,\n",
            "         6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01,\n",
            "        -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01,\n",
            "        -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01,\n",
            "        -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,\n",
            "         7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,\n",
            "         4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02,\n",
            "        -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02,\n",
            "        -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00,\n",
            "        -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,\n",
            "         6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01,\n",
            "        -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,\n",
            "         4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,\n",
            "         1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01,\n",
            "        -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01,\n",
            "        -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01,\n",
            "        -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,\n",
            "         1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01,\n",
            "        -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01,\n",
            "        -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,\n",
            "         7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,\n",
            "         2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01,\n",
            "        -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02,\n",
            "        -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,\n",
            "         1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,\n",
            "         2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,\n",
            "         5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01,\n",
            "        -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01,\n",
            "        -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01,\n",
            "        -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,\n",
            "         8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,\n",
            "         6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01,\n",
            "        -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00,\n",
            "        -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,\n",
            "         2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,\n",
            "         1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,\n",
            "         6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01,\n",
            "        -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00,\n",
            "        -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37923:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 8.1940e-01,  1.0270e+00,  1.2300e+00,  1.3494e+00,  1.2973e+00,\n",
            "         1.0190e+00,  5.3332e-01, -6.4991e-02, -6.5245e-01, -1.1406e+00,\n",
            "        -1.5102e+00, -1.7965e+00, -2.0431e+00, -2.2611e+00, -2.4131e+00,\n",
            "        -2.4273e+00, -2.2299e+00, -1.7831e+00, -1.1105e+00, -2.9692e-01,\n",
            "         5.3652e-01,  1.2707e+00,  1.8234e+00,  2.1697e+00,  2.3387e+00,\n",
            "         2.3893e+00,  2.3739e+00,  2.3111e+00,  2.1812e+00,  1.9463e+00,\n",
            "         1.5789e+00,  1.0782e+00,  4.6867e-01, -2.0911e-01, -9.0306e-01,\n",
            "        -1.5456e+00, -2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00,\n",
            "        -1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,\n",
            "         4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,\n",
            "         8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02,\n",
            "        -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01,\n",
            "        -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01,\n",
            "        -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,\n",
            "         8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,\n",
            "         5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01,\n",
            "        -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01,\n",
            "        -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00,\n",
            "        -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,\n",
            "         6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01,\n",
            "        -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,\n",
            "         1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,\n",
            "         1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01,\n",
            "        -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01,\n",
            "        -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01,\n",
            "        -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,\n",
            "         1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01,\n",
            "        -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01,\n",
            "        -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,\n",
            "         1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01,\n",
            "        -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,\n",
            "         1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01,\n",
            "        -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02,\n",
            "        -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,\n",
            "         4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,\n",
            "         3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,\n",
            "         8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01,\n",
            "        -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01,\n",
            "        -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01,\n",
            "        -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,\n",
            "         7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,\n",
            "         8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01,\n",
            "        -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00,\n",
            "        -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01,\n",
            "        -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,\n",
            "         1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,\n",
            "         7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,\n",
            "         2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00,\n",
            "        -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,\n",
            "         2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37924:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.2973e+00,  1.0190e+00,  5.3332e-01, -6.4991e-02, -6.5245e-01,\n",
            "        -1.1406e+00, -1.5102e+00, -1.7965e+00, -2.0431e+00, -2.2611e+00,\n",
            "        -2.4131e+00, -2.4273e+00, -2.2299e+00, -1.7831e+00, -1.1105e+00,\n",
            "        -2.9692e-01,  5.3652e-01,  1.2707e+00,  1.8234e+00,  2.1697e+00,\n",
            "         2.3387e+00,  2.3893e+00,  2.3739e+00,  2.3111e+00,  2.1812e+00,\n",
            "         1.9463e+00,  1.5789e+00,  1.0782e+00,  4.6867e-01, -2.0911e-01,\n",
            "        -9.0306e-01, -1.5456e+00, -2.0533e+00, -2.3446e+00, -2.3722e+00,\n",
            "        -2.1501e+00, -1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,\n",
            "         9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,\n",
            "         1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01,\n",
            "        -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01,\n",
            "        -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01,\n",
            "        -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,\n",
            "         7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,\n",
            "         5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,\n",
            "         1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01,\n",
            "        -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01,\n",
            "        -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,\n",
            "         3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02,\n",
            "        -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01,\n",
            "        -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,\n",
            "         1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,\n",
            "         1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01,\n",
            "        -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01,\n",
            "        -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,\n",
            "         8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,\n",
            "         3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01,\n",
            "        -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,\n",
            "         1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01,\n",
            "        -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,\n",
            "         3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01,\n",
            "        -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03,\n",
            "        -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,\n",
            "         2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01,\n",
            "        -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,\n",
            "         9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01,\n",
            "        -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01,\n",
            "        -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01,\n",
            "        -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,\n",
            "         5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,\n",
            "         9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02,\n",
            "        -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00,\n",
            "        -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01,\n",
            "        -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,\n",
            "         9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,\n",
            "         9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,\n",
            "         4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00,\n",
            "        -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01,\n",
            "        -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,\n",
            "         1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37925:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-6.5245e-01, -1.1406e+00, -1.5102e+00, -1.7965e+00, -2.0431e+00,\n",
            "        -2.2611e+00, -2.4131e+00, -2.4273e+00, -2.2299e+00, -1.7831e+00,\n",
            "        -1.1105e+00, -2.9692e-01,  5.3652e-01,  1.2707e+00,  1.8234e+00,\n",
            "         2.1697e+00,  2.3387e+00,  2.3893e+00,  2.3739e+00,  2.3111e+00,\n",
            "         2.1812e+00,  1.9463e+00,  1.5789e+00,  1.0782e+00,  4.6867e-01,\n",
            "        -2.0911e-01, -9.0306e-01, -1.5456e+00, -2.0533e+00, -2.3446e+00,\n",
            "        -2.3722e+00, -2.1501e+00, -1.7503e+00, -1.2689e+00, -7.8211e-01,\n",
            "        -3.2541e-01,  9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,\n",
            "         1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,\n",
            "         2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01,\n",
            "        -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01,\n",
            "        -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,\n",
            "         5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,\n",
            "         5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,\n",
            "         3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01,\n",
            "        -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01,\n",
            "        -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01,\n",
            "        -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,\n",
            "         7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01,\n",
            "        -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,\n",
            "         8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,\n",
            "         5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01,\n",
            "        -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01,\n",
            "        -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,\n",
            "         4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,\n",
            "         8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01,\n",
            "        -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,\n",
            "         5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02,\n",
            "        -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,\n",
            "         3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01,\n",
            "        -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,\n",
            "         1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02,\n",
            "        -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02,\n",
            "        -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,\n",
            "         7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01,\n",
            "        -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01,\n",
            "        -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01,\n",
            "        -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,\n",
            "         2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,\n",
            "         9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01,\n",
            "        -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00,\n",
            "        -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01,\n",
            "        -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,\n",
            "         6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,\n",
            "         1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,\n",
            "         5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01,\n",
            "        -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00,\n",
            "        -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,\n",
            "         1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,\n",
            "         3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37926:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-2.0431e+00, -2.2611e+00, -2.4131e+00, -2.4273e+00, -2.2299e+00,\n",
            "        -1.7831e+00, -1.1105e+00, -2.9692e-01,  5.3652e-01,  1.2707e+00,\n",
            "         1.8234e+00,  2.1697e+00,  2.3387e+00,  2.3893e+00,  2.3739e+00,\n",
            "         2.3111e+00,  2.1812e+00,  1.9463e+00,  1.5789e+00,  1.0782e+00,\n",
            "         4.6867e-01, -2.0911e-01, -9.0306e-01, -1.5456e+00, -2.0533e+00,\n",
            "        -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00, -1.2689e+00,\n",
            "        -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,  7.8659e-01,\n",
            "         9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,\n",
            "         4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01,\n",
            "        -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01,\n",
            "        -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,\n",
            "         2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,\n",
            "         6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,\n",
            "         4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01,\n",
            "        -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01,\n",
            "        -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00,\n",
            "        -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,\n",
            "         4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01,\n",
            "        -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,\n",
            "         6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,\n",
            "         9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01,\n",
            "        -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01,\n",
            "        -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,\n",
            "         8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,\n",
            "         1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01,\n",
            "        -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01,\n",
            "        -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02,\n",
            "        -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,\n",
            "         1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02,\n",
            "        -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01,\n",
            "        -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02,\n",
            "        -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02,\n",
            "        -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,\n",
            "         5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,\n",
            "         2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01,\n",
            "        -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01,\n",
            "        -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,\n",
            "         1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,\n",
            "         9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,\n",
            "         3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00,\n",
            "        -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00,\n",
            "        -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,\n",
            "         4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,\n",
            "         1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,\n",
            "         5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01,\n",
            "        -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00,\n",
            "        -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,\n",
            "         9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,\n",
            "         8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01,\n",
            "        -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37927:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-2.2299e+00, -1.7831e+00, -1.1105e+00, -2.9692e-01,  5.3652e-01,\n",
            "         1.2707e+00,  1.8234e+00,  2.1697e+00,  2.3387e+00,  2.3893e+00,\n",
            "         2.3739e+00,  2.3111e+00,  2.1812e+00,  1.9463e+00,  1.5789e+00,\n",
            "         1.0782e+00,  4.6867e-01, -2.0911e-01, -9.0306e-01, -1.5456e+00,\n",
            "        -2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00,\n",
            "        -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,\n",
            "         7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,\n",
            "         6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01,\n",
            "        -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01,\n",
            "        -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01,\n",
            "        -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,\n",
            "         7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,\n",
            "         4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02,\n",
            "        -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02,\n",
            "        -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00,\n",
            "        -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,\n",
            "         6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01,\n",
            "        -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,\n",
            "         4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,\n",
            "         1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01,\n",
            "        -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01,\n",
            "        -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01,\n",
            "        -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,\n",
            "         1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01,\n",
            "        -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01,\n",
            "        -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,\n",
            "         7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,\n",
            "         2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01,\n",
            "        -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02,\n",
            "        -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,\n",
            "         1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,\n",
            "         2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,\n",
            "         5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01,\n",
            "        -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01,\n",
            "        -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01,\n",
            "        -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,\n",
            "         8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,\n",
            "         6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01,\n",
            "        -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00,\n",
            "        -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,\n",
            "         2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,\n",
            "         1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,\n",
            "         6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01,\n",
            "        -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00,\n",
            "        -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,\n",
            "         6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,\n",
            "         1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01,\n",
            "        -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02,\n",
            "        -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37928:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 5.3652e-01,  1.2707e+00,  1.8234e+00,  2.1697e+00,  2.3387e+00,\n",
            "         2.3893e+00,  2.3739e+00,  2.3111e+00,  2.1812e+00,  1.9463e+00,\n",
            "         1.5789e+00,  1.0782e+00,  4.6867e-01, -2.0911e-01, -9.0306e-01,\n",
            "        -1.5456e+00, -2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00,\n",
            "        -1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,\n",
            "         4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,\n",
            "         8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02,\n",
            "        -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01,\n",
            "        -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01,\n",
            "        -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,\n",
            "         8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,\n",
            "         5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01,\n",
            "        -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01,\n",
            "        -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00,\n",
            "        -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,\n",
            "         6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01,\n",
            "        -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,\n",
            "         1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,\n",
            "         1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01,\n",
            "        -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01,\n",
            "        -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01,\n",
            "        -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,\n",
            "         1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01,\n",
            "        -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01,\n",
            "        -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,\n",
            "         1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01,\n",
            "        -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,\n",
            "         1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01,\n",
            "        -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02,\n",
            "        -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,\n",
            "         4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,\n",
            "         3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,\n",
            "         8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01,\n",
            "        -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01,\n",
            "        -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01,\n",
            "        -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,\n",
            "         7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,\n",
            "         8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01,\n",
            "        -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00,\n",
            "        -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01,\n",
            "        -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,\n",
            "         1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,\n",
            "         7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,\n",
            "         2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00,\n",
            "        -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,\n",
            "         2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,\n",
            "         1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01,\n",
            "        -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,\n",
            "         1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01,\n",
            "        -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37929:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 2.3387e+00,  2.3893e+00,  2.3739e+00,  2.3111e+00,  2.1812e+00,\n",
            "         1.9463e+00,  1.5789e+00,  1.0782e+00,  4.6867e-01, -2.0911e-01,\n",
            "        -9.0306e-01, -1.5456e+00, -2.0533e+00, -2.3446e+00, -2.3722e+00,\n",
            "        -2.1501e+00, -1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,\n",
            "         9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,\n",
            "         1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01,\n",
            "        -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01,\n",
            "        -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01,\n",
            "        -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,\n",
            "         7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,\n",
            "         5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,\n",
            "         1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01,\n",
            "        -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01,\n",
            "        -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,\n",
            "         3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02,\n",
            "        -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01,\n",
            "        -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,\n",
            "         1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,\n",
            "         1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01,\n",
            "        -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01,\n",
            "        -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,\n",
            "         8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,\n",
            "         3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01,\n",
            "        -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,\n",
            "         1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01,\n",
            "        -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,\n",
            "         3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01,\n",
            "        -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03,\n",
            "        -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,\n",
            "         2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01,\n",
            "        -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,\n",
            "         9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01,\n",
            "        -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01,\n",
            "        -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01,\n",
            "        -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,\n",
            "         5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,\n",
            "         9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02,\n",
            "        -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00,\n",
            "        -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01,\n",
            "        -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,\n",
            "         9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,\n",
            "         9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,\n",
            "         4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00,\n",
            "        -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01,\n",
            "        -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,\n",
            "         1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01,\n",
            "        -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,\n",
            "         8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01,\n",
            "        -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01,\n",
            "        -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37930:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 2.1812e+00,  1.9463e+00,  1.5789e+00,  1.0782e+00,  4.6867e-01,\n",
            "        -2.0911e-01, -9.0306e-01, -1.5456e+00, -2.0533e+00, -2.3446e+00,\n",
            "        -2.3722e+00, -2.1501e+00, -1.7503e+00, -1.2689e+00, -7.8211e-01,\n",
            "        -3.2541e-01,  9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,\n",
            "         1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,\n",
            "         2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01,\n",
            "        -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01,\n",
            "        -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,\n",
            "         5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,\n",
            "         5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,\n",
            "         3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01,\n",
            "        -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01,\n",
            "        -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01,\n",
            "        -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,\n",
            "         7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01,\n",
            "        -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,\n",
            "         8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,\n",
            "         5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01,\n",
            "        -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01,\n",
            "        -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,\n",
            "         4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,\n",
            "         8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01,\n",
            "        -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,\n",
            "         5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02,\n",
            "        -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,\n",
            "         3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01,\n",
            "        -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,\n",
            "         1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02,\n",
            "        -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02,\n",
            "        -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,\n",
            "         7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01,\n",
            "        -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01,\n",
            "        -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01,\n",
            "        -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,\n",
            "         2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,\n",
            "         9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01,\n",
            "        -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00,\n",
            "        -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01,\n",
            "        -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,\n",
            "         6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,\n",
            "         1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,\n",
            "         5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01,\n",
            "        -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00,\n",
            "        -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,\n",
            "         1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,\n",
            "         3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01,\n",
            "        -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01,\n",
            "        -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01,\n",
            "        -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,\n",
            "         3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37931:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 4.6867e-01, -2.0911e-01, -9.0306e-01, -1.5456e+00, -2.0533e+00,\n",
            "        -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00, -1.2689e+00,\n",
            "        -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,  7.8659e-01,\n",
            "         9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,\n",
            "         4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01,\n",
            "        -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01,\n",
            "        -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,\n",
            "         2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,\n",
            "         6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,\n",
            "         4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01,\n",
            "        -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01,\n",
            "        -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00,\n",
            "        -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,\n",
            "         4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01,\n",
            "        -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,\n",
            "         6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,\n",
            "         9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01,\n",
            "        -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01,\n",
            "        -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,\n",
            "         8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,\n",
            "         1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01,\n",
            "        -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01,\n",
            "        -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02,\n",
            "        -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,\n",
            "         1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02,\n",
            "        -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01,\n",
            "        -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02,\n",
            "        -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02,\n",
            "        -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,\n",
            "         5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,\n",
            "         2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01,\n",
            "        -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01,\n",
            "        -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,\n",
            "         1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,\n",
            "         9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,\n",
            "         3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00,\n",
            "        -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00,\n",
            "        -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,\n",
            "         4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,\n",
            "         1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,\n",
            "         5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01,\n",
            "        -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00,\n",
            "        -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,\n",
            "         9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,\n",
            "         8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01,\n",
            "        -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01,\n",
            "        -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01,\n",
            "        -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,\n",
            "         1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,\n",
            "         4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37932:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-2.0533e+00, -2.3446e+00, -2.3722e+00, -2.1501e+00, -1.7503e+00,\n",
            "        -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,  4.7410e-01,\n",
            "         7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,  8.5321e-01,\n",
            "         6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01,\n",
            "        -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01,\n",
            "        -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01,\n",
            "        -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,\n",
            "         7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,\n",
            "         4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02,\n",
            "        -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02,\n",
            "        -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00,\n",
            "        -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,\n",
            "         6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01,\n",
            "        -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,\n",
            "         4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,\n",
            "         1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01,\n",
            "        -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01,\n",
            "        -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01,\n",
            "        -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,\n",
            "         1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01,\n",
            "        -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01,\n",
            "        -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,\n",
            "         7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,\n",
            "         2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01,\n",
            "        -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02,\n",
            "        -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,\n",
            "         1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,\n",
            "         2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,\n",
            "         5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01,\n",
            "        -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01,\n",
            "        -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01,\n",
            "        -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,\n",
            "         8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,\n",
            "         6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01,\n",
            "        -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00,\n",
            "        -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,\n",
            "         2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,\n",
            "         1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,\n",
            "         6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01,\n",
            "        -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00,\n",
            "        -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,\n",
            "         6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,\n",
            "         1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01,\n",
            "        -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02,\n",
            "        -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01,\n",
            "        -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01,\n",
            "        -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,\n",
            "         6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02,\n",
            "        -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37933:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.7503e+00, -1.2689e+00, -7.8211e-01, -3.2541e-01,  9.5262e-02,\n",
            "         4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,  1.0130e+00,\n",
            "         8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01, -1.1531e-02,\n",
            "        -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01,\n",
            "        -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01,\n",
            "        -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,\n",
            "         8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,\n",
            "         5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01,\n",
            "        -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01,\n",
            "        -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00,\n",
            "        -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,\n",
            "         6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01,\n",
            "        -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,\n",
            "         1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,\n",
            "         1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01,\n",
            "        -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01,\n",
            "        -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01,\n",
            "        -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,\n",
            "         1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01,\n",
            "        -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01,\n",
            "        -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,\n",
            "         1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01,\n",
            "        -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,\n",
            "         1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01,\n",
            "        -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02,\n",
            "        -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,\n",
            "         4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,\n",
            "         3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,\n",
            "         8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01,\n",
            "        -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01,\n",
            "        -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01,\n",
            "        -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,\n",
            "         7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,\n",
            "         8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01,\n",
            "        -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00,\n",
            "        -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01,\n",
            "        -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,\n",
            "         1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,\n",
            "         7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,\n",
            "         2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00,\n",
            "        -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,\n",
            "         2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,\n",
            "         1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01,\n",
            "        -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,\n",
            "         1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01,\n",
            "        -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01,\n",
            "        -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,\n",
            "         6.4014e-01,  6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,\n",
            "         1.9666e-02, -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,\n",
            "         3.3524e-01,  5.3167e-01,  7.3288e-01,  8.7637e-01,  8.9447e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37934:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 9.5262e-02,  4.7410e-01,  7.8659e-01,  9.9509e-01,  1.0707e+00,\n",
            "         1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,  2.0236e-01,\n",
            "        -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01, -6.2128e-01,\n",
            "        -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01,\n",
            "        -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,\n",
            "         7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,\n",
            "         5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,\n",
            "         1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01,\n",
            "        -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01,\n",
            "        -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,\n",
            "         3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02,\n",
            "        -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01,\n",
            "        -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,\n",
            "         1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,\n",
            "         1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01,\n",
            "        -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01,\n",
            "        -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,\n",
            "         8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,\n",
            "         3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01,\n",
            "        -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,\n",
            "         1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01,\n",
            "        -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,\n",
            "         3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01,\n",
            "        -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03,\n",
            "        -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,\n",
            "         2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01,\n",
            "        -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,\n",
            "         9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01,\n",
            "        -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01,\n",
            "        -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01,\n",
            "        -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,\n",
            "         5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,\n",
            "         9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02,\n",
            "        -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00,\n",
            "        -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01,\n",
            "        -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,\n",
            "         9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,\n",
            "         9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,\n",
            "         4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00,\n",
            "        -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01,\n",
            "        -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,\n",
            "         1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01,\n",
            "        -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,\n",
            "         8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01,\n",
            "        -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01,\n",
            "        -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01,\n",
            "         5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01,  3.0302e-01,\n",
            "         1.3249e-01,  1.9666e-02, -2.1144e-02, -9.9446e-05,  6.7880e-02,\n",
            "         1.7843e-01,  3.3524e-01,  5.3167e-01,  7.3288e-01,  8.7637e-01,\n",
            "         8.9447e-01,  7.4531e-01,  4.3306e-01,  8.4539e-03, -4.4684e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37935:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.0707e+00,  1.0130e+00,  8.5321e-01,  6.4060e-01,  4.1779e-01,\n",
            "         2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01, -5.7845e-01,\n",
            "        -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01, -3.3400e-01,\n",
            "        -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,\n",
            "         5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,\n",
            "         5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,\n",
            "         3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01,\n",
            "        -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01,\n",
            "        -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01,\n",
            "        -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,\n",
            "         7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01,\n",
            "        -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,\n",
            "         8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,\n",
            "         5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01,\n",
            "        -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01,\n",
            "        -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,\n",
            "         4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,\n",
            "         8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01,\n",
            "        -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,\n",
            "         5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02,\n",
            "        -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,\n",
            "         3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01,\n",
            "        -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,\n",
            "         1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02,\n",
            "        -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02,\n",
            "        -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,\n",
            "         7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01,\n",
            "        -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01,\n",
            "        -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01,\n",
            "        -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,\n",
            "         2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,\n",
            "         9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01,\n",
            "        -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00,\n",
            "        -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01,\n",
            "        -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,\n",
            "         6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,\n",
            "         1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,\n",
            "         5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01,\n",
            "        -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00,\n",
            "        -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,\n",
            "         1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,\n",
            "         3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01,\n",
            "        -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01,\n",
            "        -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01,\n",
            "        -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,\n",
            "         3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01,\n",
            "         3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02, -9.9446e-05,\n",
            "         6.7880e-02,  1.7843e-01,  3.3524e-01,  5.3167e-01,  7.3288e-01,\n",
            "         8.7637e-01,  8.9447e-01,  7.4531e-01,  4.3306e-01,  8.4539e-03,\n",
            "        -4.4684e-01, -8.4486e-01, -1.1186e+00, -1.2427e+00, -1.2366e+00])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37936:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 4.1779e-01,  2.0236e-01, -1.1531e-02, -2.2992e-01, -4.3395e-01,\n",
            "        -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01, -3.5751e-01,\n",
            "        -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01, -7.0302e-02,\n",
            "         2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,\n",
            "         6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,\n",
            "         4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01,\n",
            "        -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01,\n",
            "        -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00,\n",
            "        -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,\n",
            "         4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01,\n",
            "        -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,\n",
            "         6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,\n",
            "         9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01,\n",
            "        -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01,\n",
            "        -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,\n",
            "         8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,\n",
            "         1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01,\n",
            "        -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01,\n",
            "        -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02,\n",
            "        -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,\n",
            "         1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02,\n",
            "        -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01,\n",
            "        -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02,\n",
            "        -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02,\n",
            "        -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,\n",
            "         5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,\n",
            "         2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01,\n",
            "        -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01,\n",
            "        -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,\n",
            "         1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,\n",
            "         9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,\n",
            "         3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00,\n",
            "        -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00,\n",
            "        -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,\n",
            "         4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,\n",
            "         1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,\n",
            "         5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01,\n",
            "        -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00,\n",
            "        -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,\n",
            "         9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,\n",
            "         8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01,\n",
            "        -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01,\n",
            "        -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01,\n",
            "        -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,\n",
            "         1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,\n",
            "         4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02,\n",
            "        -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01,  5.3167e-01,\n",
            "         7.3288e-01,  8.7637e-01,  8.9447e-01,  7.4531e-01,  4.3306e-01,\n",
            "         8.4539e-03, -4.4684e-01, -8.4486e-01, -1.1186e+00, -1.2427e+00,\n",
            "        -1.2366e+00, -1.1480e+00, -1.0266e+00, -9.0682e-01, -8.0169e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37937:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-4.3395e-01, -5.7845e-01, -6.2128e-01, -5.6099e-01, -4.4848e-01,\n",
            "        -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01, -2.8526e-01,\n",
            "        -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,  8.0701e-01,\n",
            "         7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,\n",
            "         4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02,\n",
            "        -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02,\n",
            "        -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00,\n",
            "        -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,\n",
            "         6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01,\n",
            "        -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,\n",
            "         4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,\n",
            "         1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01,\n",
            "        -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01,\n",
            "        -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01,\n",
            "        -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,\n",
            "         1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01,\n",
            "        -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01,\n",
            "        -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,\n",
            "         7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,\n",
            "         2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01,\n",
            "        -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02,\n",
            "        -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,\n",
            "         1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,\n",
            "         2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,\n",
            "         5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01,\n",
            "        -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01,\n",
            "        -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01,\n",
            "        -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,\n",
            "         8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,\n",
            "         6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01,\n",
            "        -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00,\n",
            "        -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,\n",
            "         2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,\n",
            "         1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,\n",
            "         6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01,\n",
            "        -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00,\n",
            "        -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,\n",
            "         6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,\n",
            "         1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01,\n",
            "        -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02,\n",
            "        -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01,\n",
            "        -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01,\n",
            "        -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,\n",
            "         6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02,\n",
            "        -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01,\n",
            "         5.3167e-01,  7.3288e-01,  8.7637e-01,  8.9447e-01,  7.4531e-01,\n",
            "         4.3306e-01,  8.4539e-03, -4.4684e-01, -8.4486e-01, -1.1186e+00,\n",
            "        -1.2427e+00, -1.2366e+00, -1.1480e+00, -1.0266e+00, -9.0682e-01,\n",
            "        -8.0169e-01, -7.0644e-01, -6.0223e-01, -4.6095e-01, -2.5555e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37938:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-4.4848e-01, -3.5751e-01, -3.3400e-01, -3.6195e-01, -3.7167e-01,\n",
            "        -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,  7.3763e-01,\n",
            "         8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,  5.4765e-01,\n",
            "         5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01,\n",
            "        -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01,\n",
            "        -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00,\n",
            "        -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,\n",
            "         6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01,\n",
            "        -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,\n",
            "         1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,\n",
            "         1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01,\n",
            "        -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01,\n",
            "        -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01,\n",
            "        -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,\n",
            "         1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01,\n",
            "        -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01,\n",
            "        -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,\n",
            "         1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01,\n",
            "        -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,\n",
            "         1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01,\n",
            "        -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02,\n",
            "        -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,\n",
            "         4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,\n",
            "         3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,\n",
            "         8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01,\n",
            "        -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01,\n",
            "        -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01,\n",
            "        -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,\n",
            "         7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,\n",
            "         8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01,\n",
            "        -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00,\n",
            "        -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01,\n",
            "        -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,\n",
            "         1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,\n",
            "         7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,\n",
            "         2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00,\n",
            "        -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,\n",
            "         2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,\n",
            "         1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01,\n",
            "        -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,\n",
            "         1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01,\n",
            "        -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01,\n",
            "        -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,\n",
            "         6.4014e-01,  6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,\n",
            "         1.9666e-02, -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,\n",
            "         3.3524e-01,  5.3167e-01,  7.3288e-01,  8.7637e-01,  8.9447e-01,\n",
            "         7.4531e-01,  4.3306e-01,  8.4539e-03, -4.4684e-01, -8.4486e-01,\n",
            "        -1.1186e+00, -1.2427e+00, -1.2366e+00, -1.1480e+00, -1.0266e+00,\n",
            "        -9.0682e-01, -8.0169e-01, -7.0644e-01, -6.0223e-01, -4.6095e-01,\n",
            "        -2.5555e-01,  2.3599e-02,  3.5616e-01,  6.9432e-01,  9.8070e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37939:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-3.7167e-01, -2.8526e-01, -7.0302e-02,  2.3340e-01,  5.3322e-01,\n",
            "         7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,  5.9846e-01,\n",
            "         5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,  3.3098e-01,\n",
            "         1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01,\n",
            "        -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01,\n",
            "        -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,\n",
            "         3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02,\n",
            "        -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01,\n",
            "        -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,\n",
            "         1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,\n",
            "         1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01,\n",
            "        -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01,\n",
            "        -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,\n",
            "         8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,\n",
            "         3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01,\n",
            "        -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,\n",
            "         1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01,\n",
            "        -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,\n",
            "         3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01,\n",
            "        -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03,\n",
            "        -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,\n",
            "         2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01,\n",
            "        -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,\n",
            "         9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01,\n",
            "        -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01,\n",
            "        -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01,\n",
            "        -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,\n",
            "         5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,\n",
            "         9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02,\n",
            "        -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00,\n",
            "        -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01,\n",
            "        -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,\n",
            "         9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,\n",
            "         9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,\n",
            "         4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00,\n",
            "        -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01,\n",
            "        -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,\n",
            "         1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01,\n",
            "        -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,\n",
            "         8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01,\n",
            "        -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01,\n",
            "        -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01,\n",
            "         5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01,  3.0302e-01,\n",
            "         1.3249e-01,  1.9666e-02, -2.1144e-02, -9.9446e-05,  6.7880e-02,\n",
            "         1.7843e-01,  3.3524e-01,  5.3167e-01,  7.3288e-01,  8.7637e-01,\n",
            "         8.9447e-01,  7.4531e-01,  4.3306e-01,  8.4539e-03, -4.4684e-01,\n",
            "        -8.4486e-01, -1.1186e+00, -1.2427e+00, -1.2366e+00, -1.1480e+00,\n",
            "        -1.0266e+00, -9.0682e-01, -8.0169e-01, -7.0644e-01, -6.0223e-01,\n",
            "        -4.6095e-01, -2.5555e-01,  2.3599e-02,  3.5616e-01,  6.9432e-01,\n",
            "         9.8070e-01,  1.1713e+00,  1.2524e+00,  1.2458e+00,  1.1988e+00])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37940:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 5.3322e-01,  7.3763e-01,  8.0701e-01,  7.6686e-01,  6.7902e-01,\n",
            "         5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,  4.3491e-01,\n",
            "         3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01, -2.9407e-01,\n",
            "        -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01,\n",
            "        -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01,\n",
            "        -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,\n",
            "         7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01,\n",
            "        -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,\n",
            "         8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,\n",
            "         5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01,\n",
            "        -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01,\n",
            "        -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,\n",
            "         4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,\n",
            "         8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01,\n",
            "        -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,\n",
            "         5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02,\n",
            "        -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,\n",
            "         3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01,\n",
            "        -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,\n",
            "         1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02,\n",
            "        -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02,\n",
            "        -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,\n",
            "         7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01,\n",
            "        -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01,\n",
            "        -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01,\n",
            "        -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,\n",
            "         2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,\n",
            "         9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01,\n",
            "        -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00,\n",
            "        -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01,\n",
            "        -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,\n",
            "         6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,\n",
            "         1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,\n",
            "         5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01,\n",
            "        -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00,\n",
            "        -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,\n",
            "         1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,\n",
            "         3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01,\n",
            "        -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01,\n",
            "        -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01,\n",
            "        -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,\n",
            "         3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01,\n",
            "         3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02, -9.9446e-05,\n",
            "         6.7880e-02,  1.7843e-01,  3.3524e-01,  5.3167e-01,  7.3288e-01,\n",
            "         8.7637e-01,  8.9447e-01,  7.4531e-01,  4.3306e-01,  8.4539e-03,\n",
            "        -4.4684e-01, -8.4486e-01, -1.1186e+00, -1.2427e+00, -1.2366e+00,\n",
            "        -1.1480e+00, -1.0266e+00, -9.0682e-01, -8.0169e-01, -7.0644e-01,\n",
            "        -6.0223e-01, -4.6095e-01, -2.5555e-01,  2.3599e-02,  3.5616e-01,\n",
            "         6.9432e-01,  9.8070e-01,  1.1713e+00,  1.2524e+00,  1.2458e+00,\n",
            "         1.1988e+00,  1.1586e+00,  1.1427e+00,  1.1216e+00,  1.0305e+00])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37941:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 6.7902e-01,  5.9846e-01,  5.4765e-01,  5.1887e-01,  4.8985e-01,\n",
            "         4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02, -2.0527e-01,\n",
            "        -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02, -1.6044e-01,\n",
            "        -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00,\n",
            "        -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,\n",
            "         4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01,\n",
            "        -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,\n",
            "         6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,\n",
            "         9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01,\n",
            "        -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01,\n",
            "        -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,\n",
            "         8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,\n",
            "         1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01,\n",
            "        -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01,\n",
            "        -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02,\n",
            "        -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,\n",
            "         1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02,\n",
            "        -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01,\n",
            "        -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02,\n",
            "        -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02,\n",
            "        -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,\n",
            "         5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,\n",
            "         2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01,\n",
            "        -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01,\n",
            "        -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,\n",
            "         1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,\n",
            "         9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,\n",
            "         3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00,\n",
            "        -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00,\n",
            "        -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,\n",
            "         4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,\n",
            "         1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,\n",
            "         5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01,\n",
            "        -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00,\n",
            "        -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,\n",
            "         9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,\n",
            "         8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01,\n",
            "        -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01,\n",
            "        -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01,\n",
            "        -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,\n",
            "         1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,\n",
            "         4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02,\n",
            "        -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01,  5.3167e-01,\n",
            "         7.3288e-01,  8.7637e-01,  8.9447e-01,  7.4531e-01,  4.3306e-01,\n",
            "         8.4539e-03, -4.4684e-01, -8.4486e-01, -1.1186e+00, -1.2427e+00,\n",
            "        -1.2366e+00, -1.1480e+00, -1.0266e+00, -9.0682e-01, -8.0169e-01,\n",
            "        -7.0644e-01, -6.0223e-01, -4.6095e-01, -2.5555e-01,  2.3599e-02,\n",
            "         3.5616e-01,  6.9432e-01,  9.8070e-01,  1.1713e+00,  1.2524e+00,\n",
            "         1.2458e+00,  1.1988e+00,  1.1586e+00,  1.1427e+00,  1.1216e+00,\n",
            "         1.0305e+00,  8.0576e-01,  4.2371e-01, -8.0183e-02, -6.2234e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37942:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 4.8985e-01,  4.3491e-01,  3.3098e-01,  1.6910e-01, -2.8689e-02,\n",
            "        -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01, -9.4450e-02,\n",
            "        -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00, -1.1964e+00,\n",
            "        -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,\n",
            "         6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01,\n",
            "        -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,\n",
            "         4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,\n",
            "         1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01,\n",
            "        -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01,\n",
            "        -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01,\n",
            "        -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,\n",
            "         1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01,\n",
            "        -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01,\n",
            "        -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,\n",
            "         7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,\n",
            "         2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01,\n",
            "        -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02,\n",
            "        -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,\n",
            "         1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,\n",
            "         2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,\n",
            "         5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01,\n",
            "        -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01,\n",
            "        -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01,\n",
            "        -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,\n",
            "         8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,\n",
            "         6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01,\n",
            "        -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00,\n",
            "        -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,\n",
            "         2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,\n",
            "         1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,\n",
            "         6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01,\n",
            "        -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00,\n",
            "        -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,\n",
            "         6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,\n",
            "         1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01,\n",
            "        -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02,\n",
            "        -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01,\n",
            "        -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01,\n",
            "        -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,\n",
            "         6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02,\n",
            "        -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01,\n",
            "         5.3167e-01,  7.3288e-01,  8.7637e-01,  8.9447e-01,  7.4531e-01,\n",
            "         4.3306e-01,  8.4539e-03, -4.4684e-01, -8.4486e-01, -1.1186e+00,\n",
            "        -1.2427e+00, -1.2366e+00, -1.1480e+00, -1.0266e+00, -9.0682e-01,\n",
            "        -8.0169e-01, -7.0644e-01, -6.0223e-01, -4.6095e-01, -2.5555e-01,\n",
            "         2.3599e-02,  3.5616e-01,  6.9432e-01,  9.8070e-01,  1.1713e+00,\n",
            "         1.2524e+00,  1.2458e+00,  1.1988e+00,  1.1586e+00,  1.1427e+00,\n",
            "         1.1216e+00,  1.0305e+00,  8.0576e-01,  4.2371e-01, -8.0183e-02,\n",
            "        -6.2234e-01, -1.1018e+00, -1.4334e+00, -1.5702e+00, -1.5117e+00])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37943:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-2.8689e-02, -2.0527e-01, -2.9407e-01, -2.6618e-01, -1.6495e-01,\n",
            "        -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01, -1.0631e+00,\n",
            "        -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,  3.2007e-01,\n",
            "         6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01,\n",
            "        -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,\n",
            "         1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,\n",
            "         1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01,\n",
            "        -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01,\n",
            "        -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01,\n",
            "        -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,\n",
            "         1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01,\n",
            "        -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01,\n",
            "        -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,\n",
            "         1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01,\n",
            "        -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,\n",
            "         1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01,\n",
            "        -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02,\n",
            "        -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,\n",
            "         4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,\n",
            "         3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,\n",
            "         8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01,\n",
            "        -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01,\n",
            "        -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01,\n",
            "        -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,\n",
            "         7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,\n",
            "         8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01,\n",
            "        -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00,\n",
            "        -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01,\n",
            "        -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,\n",
            "         1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,\n",
            "         7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,\n",
            "         2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00,\n",
            "        -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,\n",
            "         2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,\n",
            "         1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01,\n",
            "        -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,\n",
            "         1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01,\n",
            "        -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01,\n",
            "        -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,\n",
            "         6.4014e-01,  6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,\n",
            "         1.9666e-02, -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,\n",
            "         3.3524e-01,  5.3167e-01,  7.3288e-01,  8.7637e-01,  8.9447e-01,\n",
            "         7.4531e-01,  4.3306e-01,  8.4539e-03, -4.4684e-01, -8.4486e-01,\n",
            "        -1.1186e+00, -1.2427e+00, -1.2366e+00, -1.1480e+00, -1.0266e+00,\n",
            "        -9.0682e-01, -8.0169e-01, -7.0644e-01, -6.0223e-01, -4.6095e-01,\n",
            "        -2.5555e-01,  2.3599e-02,  3.5616e-01,  6.9432e-01,  9.8070e-01,\n",
            "         1.1713e+00,  1.2524e+00,  1.2458e+00,  1.1988e+00,  1.1586e+00,\n",
            "         1.1427e+00,  1.1216e+00,  1.0305e+00,  8.0576e-01,  4.2371e-01,\n",
            "        -8.0183e-02, -6.2234e-01, -1.1018e+00, -1.4334e+00, -1.5702e+00,\n",
            "        -1.5117e+00, -1.2962e+00, -9.8357e-01, -6.3689e-01, -3.1085e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37944:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.6495e-01, -9.4450e-02, -1.6044e-01, -4.0004e-01, -7.4808e-01,\n",
            "        -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01, -1.6721e-01,\n",
            "         3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,  7.0018e-02,\n",
            "        -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01,\n",
            "        -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,\n",
            "         1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,\n",
            "         1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01,\n",
            "        -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01,\n",
            "        -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,\n",
            "         8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,\n",
            "         3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01,\n",
            "        -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,\n",
            "         1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01,\n",
            "        -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,\n",
            "         3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01,\n",
            "        -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03,\n",
            "        -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,\n",
            "         2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01,\n",
            "        -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,\n",
            "         9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01,\n",
            "        -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01,\n",
            "        -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01,\n",
            "        -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,\n",
            "         5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,\n",
            "         9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02,\n",
            "        -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00,\n",
            "        -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01,\n",
            "        -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,\n",
            "         9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,\n",
            "         9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,\n",
            "         4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00,\n",
            "        -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01,\n",
            "        -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,\n",
            "         1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01,\n",
            "        -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,\n",
            "         8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01,\n",
            "        -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01,\n",
            "        -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01,\n",
            "         5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01,  3.0302e-01,\n",
            "         1.3249e-01,  1.9666e-02, -2.1144e-02, -9.9446e-05,  6.7880e-02,\n",
            "         1.7843e-01,  3.3524e-01,  5.3167e-01,  7.3288e-01,  8.7637e-01,\n",
            "         8.9447e-01,  7.4531e-01,  4.3306e-01,  8.4539e-03, -4.4684e-01,\n",
            "        -8.4486e-01, -1.1186e+00, -1.2427e+00, -1.2366e+00, -1.1480e+00,\n",
            "        -1.0266e+00, -9.0682e-01, -8.0169e-01, -7.0644e-01, -6.0223e-01,\n",
            "        -4.6095e-01, -2.5555e-01,  2.3599e-02,  3.5616e-01,  6.9432e-01,\n",
            "         9.8070e-01,  1.1713e+00,  1.2524e+00,  1.2458e+00,  1.1988e+00,\n",
            "         1.1586e+00,  1.1427e+00,  1.1216e+00,  1.0305e+00,  8.0576e-01,\n",
            "         4.2371e-01, -8.0183e-02, -6.2234e-01, -1.1018e+00, -1.4334e+00,\n",
            "        -1.5702e+00, -1.5117e+00, -1.2962e+00, -9.8357e-01, -6.3689e-01,\n",
            "        -3.1085e-01, -4.8778e-02,  1.1739e-01,  1.7297e-01,  1.3392e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37945:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-7.4808e-01, -1.0631e+00, -1.1964e+00, -1.0635e+00, -6.8277e-01,\n",
            "        -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,  4.4844e-01,\n",
            "         7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01, -5.6803e-01,\n",
            "        -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,\n",
            "         8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,\n",
            "         5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01,\n",
            "        -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01,\n",
            "        -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,\n",
            "         4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,\n",
            "         8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01,\n",
            "        -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,\n",
            "         5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02,\n",
            "        -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,\n",
            "         3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01,\n",
            "        -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,\n",
            "         1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02,\n",
            "        -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02,\n",
            "        -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,\n",
            "         7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01,\n",
            "        -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01,\n",
            "        -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01,\n",
            "        -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,\n",
            "         2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,\n",
            "         9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01,\n",
            "        -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00,\n",
            "        -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01,\n",
            "        -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,\n",
            "         6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,\n",
            "         1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,\n",
            "         5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01,\n",
            "        -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00,\n",
            "        -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,\n",
            "         1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,\n",
            "         3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01,\n",
            "        -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01,\n",
            "        -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01,\n",
            "        -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,\n",
            "         3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01,\n",
            "         3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02, -9.9446e-05,\n",
            "         6.7880e-02,  1.7843e-01,  3.3524e-01,  5.3167e-01,  7.3288e-01,\n",
            "         8.7637e-01,  8.9447e-01,  7.4531e-01,  4.3306e-01,  8.4539e-03,\n",
            "        -4.4684e-01, -8.4486e-01, -1.1186e+00, -1.2427e+00, -1.2366e+00,\n",
            "        -1.1480e+00, -1.0266e+00, -9.0682e-01, -8.0169e-01, -7.0644e-01,\n",
            "        -6.0223e-01, -4.6095e-01, -2.5555e-01,  2.3599e-02,  3.5616e-01,\n",
            "         6.9432e-01,  9.8070e-01,  1.1713e+00,  1.2524e+00,  1.2458e+00,\n",
            "         1.1988e+00,  1.1586e+00,  1.1427e+00,  1.1216e+00,  1.0305e+00,\n",
            "         8.0576e-01,  4.2371e-01, -8.0183e-02, -6.2234e-01, -1.1018e+00,\n",
            "        -1.4334e+00, -1.5702e+00, -1.5117e+00, -1.2962e+00, -9.8357e-01,\n",
            "        -6.3689e-01, -3.1085e-01, -4.8778e-02,  1.1739e-01,  1.7297e-01,\n",
            "         1.3392e-01,  5.5365e-02,  1.6689e-02,  8.0910e-02,  2.5174e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37946:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-6.8277e-01, -1.6721e-01,  3.2007e-01,  6.2687e-01,  6.6669e-01,\n",
            "         4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01, -6.7414e-01,\n",
            "        -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,  4.0654e-01,\n",
            "         6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,\n",
            "         9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01,\n",
            "        -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01,\n",
            "        -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,\n",
            "         8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,\n",
            "         1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01,\n",
            "        -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01,\n",
            "        -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02,\n",
            "        -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,\n",
            "         1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02,\n",
            "        -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01,\n",
            "        -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02,\n",
            "        -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02,\n",
            "        -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,\n",
            "         5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,\n",
            "         2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01,\n",
            "        -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01,\n",
            "        -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,\n",
            "         1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,\n",
            "         9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,\n",
            "         3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00,\n",
            "        -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00,\n",
            "        -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,\n",
            "         4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,\n",
            "         1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,\n",
            "         5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01,\n",
            "        -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00,\n",
            "        -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,\n",
            "         9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,\n",
            "         8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01,\n",
            "        -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01,\n",
            "        -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01,\n",
            "        -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,\n",
            "         1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,\n",
            "         4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02,\n",
            "        -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01,  5.3167e-01,\n",
            "         7.3288e-01,  8.7637e-01,  8.9447e-01,  7.4531e-01,  4.3306e-01,\n",
            "         8.4539e-03, -4.4684e-01, -8.4486e-01, -1.1186e+00, -1.2427e+00,\n",
            "        -1.2366e+00, -1.1480e+00, -1.0266e+00, -9.0682e-01, -8.0169e-01,\n",
            "        -7.0644e-01, -6.0223e-01, -4.6095e-01, -2.5555e-01,  2.3599e-02,\n",
            "         3.5616e-01,  6.9432e-01,  9.8070e-01,  1.1713e+00,  1.2524e+00,\n",
            "         1.2458e+00,  1.1988e+00,  1.1586e+00,  1.1427e+00,  1.1216e+00,\n",
            "         1.0305e+00,  8.0576e-01,  4.2371e-01, -8.0183e-02, -6.2234e-01,\n",
            "        -1.1018e+00, -1.4334e+00, -1.5702e+00, -1.5117e+00, -1.2962e+00,\n",
            "        -9.8357e-01, -6.3689e-01, -3.1085e-01, -4.8778e-02,  1.1739e-01,\n",
            "         1.7297e-01,  1.3392e-01,  5.5365e-02,  1.6689e-02,  8.0910e-02,\n",
            "         2.5174e-01,  4.6122e-01,  6.0108e-01,  5.7989e-01,  3.7153e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37947:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 6.6669e-01,  4.4844e-01,  7.0018e-02, -3.2273e-01, -5.9505e-01,\n",
            "        -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,  1.6996e-01,\n",
            "         4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,  1.1940e+00,\n",
            "         1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01,\n",
            "        -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01,\n",
            "        -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01,\n",
            "        -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,\n",
            "         1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01,\n",
            "        -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01,\n",
            "        -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,\n",
            "         7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,\n",
            "         2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01,\n",
            "        -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02,\n",
            "        -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,\n",
            "         1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,\n",
            "         2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,\n",
            "         5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01,\n",
            "        -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01,\n",
            "        -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01,\n",
            "        -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,\n",
            "         8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,\n",
            "         6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01,\n",
            "        -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00,\n",
            "        -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,\n",
            "         2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,\n",
            "         1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,\n",
            "         6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01,\n",
            "        -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00,\n",
            "        -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,\n",
            "         6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,\n",
            "         1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01,\n",
            "        -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02,\n",
            "        -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01,\n",
            "        -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01,\n",
            "        -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,\n",
            "         6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02,\n",
            "        -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01,\n",
            "         5.3167e-01,  7.3288e-01,  8.7637e-01,  8.9447e-01,  7.4531e-01,\n",
            "         4.3306e-01,  8.4539e-03, -4.4684e-01, -8.4486e-01, -1.1186e+00,\n",
            "        -1.2427e+00, -1.2366e+00, -1.1480e+00, -1.0266e+00, -9.0682e-01,\n",
            "        -8.0169e-01, -7.0644e-01, -6.0223e-01, -4.6095e-01, -2.5555e-01,\n",
            "         2.3599e-02,  3.5616e-01,  6.9432e-01,  9.8070e-01,  1.1713e+00,\n",
            "         1.2524e+00,  1.2458e+00,  1.1988e+00,  1.1586e+00,  1.1427e+00,\n",
            "         1.1216e+00,  1.0305e+00,  8.0576e-01,  4.2371e-01, -8.0183e-02,\n",
            "        -6.2234e-01, -1.1018e+00, -1.4334e+00, -1.5702e+00, -1.5117e+00,\n",
            "        -1.2962e+00, -9.8357e-01, -6.3689e-01, -3.1085e-01, -4.8778e-02,\n",
            "         1.1739e-01,  1.7297e-01,  1.3392e-01,  5.5365e-02,  1.6689e-02,\n",
            "         8.0910e-02,  2.5174e-01,  4.6122e-01,  6.0108e-01,  5.7989e-01,\n",
            "         3.7153e-01,  2.8285e-02, -3.4546e-01, -6.4086e-01, -7.8600e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37948:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-5.9505e-01, -6.7414e-01, -5.6803e-01, -3.4407e-01, -8.1846e-02,\n",
            "         1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,  1.0897e+00,\n",
            "         1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,  1.7646e-01,\n",
            "        -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01,\n",
            "        -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01,\n",
            "        -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,\n",
            "         1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01,\n",
            "        -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01,\n",
            "        -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,\n",
            "         1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01,\n",
            "        -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,\n",
            "         1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01,\n",
            "        -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02,\n",
            "        -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,\n",
            "         4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,\n",
            "         3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,\n",
            "         8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01,\n",
            "        -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01,\n",
            "        -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01,\n",
            "        -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,\n",
            "         7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,\n",
            "         8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01,\n",
            "        -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00,\n",
            "        -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01,\n",
            "        -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,\n",
            "         1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,\n",
            "         7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,\n",
            "         2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00,\n",
            "        -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,\n",
            "         2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,\n",
            "         1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01,\n",
            "        -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,\n",
            "         1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01,\n",
            "        -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01,\n",
            "        -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,\n",
            "         6.4014e-01,  6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,\n",
            "         1.9666e-02, -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,\n",
            "         3.3524e-01,  5.3167e-01,  7.3288e-01,  8.7637e-01,  8.9447e-01,\n",
            "         7.4531e-01,  4.3306e-01,  8.4539e-03, -4.4684e-01, -8.4486e-01,\n",
            "        -1.1186e+00, -1.2427e+00, -1.2366e+00, -1.1480e+00, -1.0266e+00,\n",
            "        -9.0682e-01, -8.0169e-01, -7.0644e-01, -6.0223e-01, -4.6095e-01,\n",
            "        -2.5555e-01,  2.3599e-02,  3.5616e-01,  6.9432e-01,  9.8070e-01,\n",
            "         1.1713e+00,  1.2524e+00,  1.2458e+00,  1.1988e+00,  1.1586e+00,\n",
            "         1.1427e+00,  1.1216e+00,  1.0305e+00,  8.0576e-01,  4.2371e-01,\n",
            "        -8.0183e-02, -6.2234e-01, -1.1018e+00, -1.4334e+00, -1.5702e+00,\n",
            "        -1.5117e+00, -1.2962e+00, -9.8357e-01, -6.3689e-01, -3.1085e-01,\n",
            "        -4.8778e-02,  1.1739e-01,  1.7297e-01,  1.3392e-01,  5.5365e-02,\n",
            "         1.6689e-02,  8.0910e-02,  2.5174e-01,  4.6122e-01,  6.0108e-01,\n",
            "         5.7989e-01,  3.7153e-01,  2.8285e-02, -3.4546e-01, -6.4086e-01,\n",
            "        -7.8600e-01, -7.6016e-01, -5.7996e-01, -2.7628e-01,  1.1550e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37949:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-8.1846e-02,  1.6996e-01,  4.0654e-01,  6.4475e-01,  8.8515e-01,\n",
            "         1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,  5.8905e-01,\n",
            "         1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01, -9.9358e-01,\n",
            "        -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01,\n",
            "        -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,\n",
            "         8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,\n",
            "         3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01,\n",
            "        -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,\n",
            "         1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01,\n",
            "        -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,\n",
            "         3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01,\n",
            "        -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03,\n",
            "        -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,\n",
            "         2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01,\n",
            "        -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,\n",
            "         9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01,\n",
            "        -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01,\n",
            "        -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01,\n",
            "        -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,\n",
            "         5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,\n",
            "         9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02,\n",
            "        -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00,\n",
            "        -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01,\n",
            "        -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,\n",
            "         9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,\n",
            "         9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,\n",
            "         4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00,\n",
            "        -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01,\n",
            "        -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,\n",
            "         1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01,\n",
            "        -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,\n",
            "         8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01,\n",
            "        -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01,\n",
            "        -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01,\n",
            "         5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01,  3.0302e-01,\n",
            "         1.3249e-01,  1.9666e-02, -2.1144e-02, -9.9446e-05,  6.7880e-02,\n",
            "         1.7843e-01,  3.3524e-01,  5.3167e-01,  7.3288e-01,  8.7637e-01,\n",
            "         8.9447e-01,  7.4531e-01,  4.3306e-01,  8.4539e-03, -4.4684e-01,\n",
            "        -8.4486e-01, -1.1186e+00, -1.2427e+00, -1.2366e+00, -1.1480e+00,\n",
            "        -1.0266e+00, -9.0682e-01, -8.0169e-01, -7.0644e-01, -6.0223e-01,\n",
            "        -4.6095e-01, -2.5555e-01,  2.3599e-02,  3.5616e-01,  6.9432e-01,\n",
            "         9.8070e-01,  1.1713e+00,  1.2524e+00,  1.2458e+00,  1.1988e+00,\n",
            "         1.1586e+00,  1.1427e+00,  1.1216e+00,  1.0305e+00,  8.0576e-01,\n",
            "         4.2371e-01, -8.0183e-02, -6.2234e-01, -1.1018e+00, -1.4334e+00,\n",
            "        -1.5702e+00, -1.5117e+00, -1.2962e+00, -9.8357e-01, -6.3689e-01,\n",
            "        -3.1085e-01, -4.8778e-02,  1.1739e-01,  1.7297e-01,  1.3392e-01,\n",
            "         5.5365e-02,  1.6689e-02,  8.0910e-02,  2.5174e-01,  4.6122e-01,\n",
            "         6.0108e-01,  5.7989e-01,  3.7153e-01,  2.8285e-02, -3.4546e-01,\n",
            "        -6.4086e-01, -7.8600e-01, -7.6016e-01, -5.7996e-01, -2.7628e-01,\n",
            "         1.1550e-01,  5.4575e-01,  9.3697e-01,  1.1903e+00,  1.2226e+00])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37950:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 8.8515e-01,  1.0897e+00,  1.1940e+00,  1.1451e+00,  9.3190e-01,\n",
            "         5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01, -8.6929e-01,\n",
            "        -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01, -5.0462e-01,\n",
            "        -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,\n",
            "         4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,\n",
            "         8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01,\n",
            "        -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,\n",
            "         5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02,\n",
            "        -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,\n",
            "         3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01,\n",
            "        -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,\n",
            "         1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02,\n",
            "        -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02,\n",
            "        -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,\n",
            "         7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01,\n",
            "        -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01,\n",
            "        -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01,\n",
            "        -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,\n",
            "         2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,\n",
            "         9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01,\n",
            "        -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00,\n",
            "        -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01,\n",
            "        -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,\n",
            "         6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,\n",
            "         1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,\n",
            "         5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01,\n",
            "        -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00,\n",
            "        -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,\n",
            "         1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,\n",
            "         3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01,\n",
            "        -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01,\n",
            "        -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01,\n",
            "        -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,\n",
            "         3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01,\n",
            "         3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02, -9.9446e-05,\n",
            "         6.7880e-02,  1.7843e-01,  3.3524e-01,  5.3167e-01,  7.3288e-01,\n",
            "         8.7637e-01,  8.9447e-01,  7.4531e-01,  4.3306e-01,  8.4539e-03,\n",
            "        -4.4684e-01, -8.4486e-01, -1.1186e+00, -1.2427e+00, -1.2366e+00,\n",
            "        -1.1480e+00, -1.0266e+00, -9.0682e-01, -8.0169e-01, -7.0644e-01,\n",
            "        -6.0223e-01, -4.6095e-01, -2.5555e-01,  2.3599e-02,  3.5616e-01,\n",
            "         6.9432e-01,  9.8070e-01,  1.1713e+00,  1.2524e+00,  1.2458e+00,\n",
            "         1.1988e+00,  1.1586e+00,  1.1427e+00,  1.1216e+00,  1.0305e+00,\n",
            "         8.0576e-01,  4.2371e-01, -8.0183e-02, -6.2234e-01, -1.1018e+00,\n",
            "        -1.4334e+00, -1.5702e+00, -1.5117e+00, -1.2962e+00, -9.8357e-01,\n",
            "        -6.3689e-01, -3.1085e-01, -4.8778e-02,  1.1739e-01,  1.7297e-01,\n",
            "         1.3392e-01,  5.5365e-02,  1.6689e-02,  8.0910e-02,  2.5174e-01,\n",
            "         4.6122e-01,  6.0108e-01,  5.7989e-01,  3.7153e-01,  2.8285e-02,\n",
            "        -3.4546e-01, -6.4086e-01, -7.8600e-01, -7.6016e-01, -5.7996e-01,\n",
            "        -2.7628e-01,  1.1550e-01,  5.4575e-01,  9.3697e-01,  1.1903e+00,\n",
            "         1.2226e+00,  1.0160e+00,  6.4423e-01,  2.4919e-01, -2.5545e-02])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37951:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 9.3190e-01,  5.8905e-01,  1.7646e-01, -2.4191e-01, -6.0732e-01,\n",
            "        -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01, -6.6756e-01,\n",
            "        -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01, -1.6492e-01,\n",
            "         8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,\n",
            "         1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01,\n",
            "        -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01,\n",
            "        -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02,\n",
            "        -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,\n",
            "         1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02,\n",
            "        -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01,\n",
            "        -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02,\n",
            "        -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02,\n",
            "        -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,\n",
            "         5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,\n",
            "         2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01,\n",
            "        -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01,\n",
            "        -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,\n",
            "         1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,\n",
            "         9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,\n",
            "         3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00,\n",
            "        -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00,\n",
            "        -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,\n",
            "         4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,\n",
            "         1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,\n",
            "         5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01,\n",
            "        -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00,\n",
            "        -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,\n",
            "         9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,\n",
            "         8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01,\n",
            "        -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01,\n",
            "        -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01,\n",
            "        -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,\n",
            "         1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,\n",
            "         4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02,\n",
            "        -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01,  5.3167e-01,\n",
            "         7.3288e-01,  8.7637e-01,  8.9447e-01,  7.4531e-01,  4.3306e-01,\n",
            "         8.4539e-03, -4.4684e-01, -8.4486e-01, -1.1186e+00, -1.2427e+00,\n",
            "        -1.2366e+00, -1.1480e+00, -1.0266e+00, -9.0682e-01, -8.0169e-01,\n",
            "        -7.0644e-01, -6.0223e-01, -4.6095e-01, -2.5555e-01,  2.3599e-02,\n",
            "         3.5616e-01,  6.9432e-01,  9.8070e-01,  1.1713e+00,  1.2524e+00,\n",
            "         1.2458e+00,  1.1988e+00,  1.1586e+00,  1.1427e+00,  1.1216e+00,\n",
            "         1.0305e+00,  8.0576e-01,  4.2371e-01, -8.0183e-02, -6.2234e-01,\n",
            "        -1.1018e+00, -1.4334e+00, -1.5702e+00, -1.5117e+00, -1.2962e+00,\n",
            "        -9.8357e-01, -6.3689e-01, -3.1085e-01, -4.8778e-02,  1.1739e-01,\n",
            "         1.7297e-01,  1.3392e-01,  5.5365e-02,  1.6689e-02,  8.0910e-02,\n",
            "         2.5174e-01,  4.6122e-01,  6.0108e-01,  5.7989e-01,  3.7153e-01,\n",
            "         2.8285e-02, -3.4546e-01, -6.4086e-01, -7.8600e-01, -7.6016e-01,\n",
            "        -5.7996e-01, -2.7628e-01,  1.1550e-01,  5.4575e-01,  9.3697e-01,\n",
            "         1.1903e+00,  1.2226e+00,  1.0160e+00,  6.4423e-01,  2.4919e-01,\n",
            "        -2.5545e-02, -1.0466e-01, -1.4519e-02,  1.3798e-01,  2.2799e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37952:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-6.0732e-01, -8.6929e-01, -9.9358e-01, -9.7532e-01, -8.4640e-01,\n",
            "        -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01, -2.9058e-01,\n",
            "        -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,  1.1780e+00,\n",
            "         1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01,\n",
            "        -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01,\n",
            "        -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,\n",
            "         7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,\n",
            "         2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01,\n",
            "        -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02,\n",
            "        -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,\n",
            "         1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,\n",
            "         2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,\n",
            "         5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01,\n",
            "        -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01,\n",
            "        -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01,\n",
            "        -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,\n",
            "         8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,\n",
            "         6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01,\n",
            "        -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00,\n",
            "        -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,\n",
            "         2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,\n",
            "         1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,\n",
            "         6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01,\n",
            "        -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00,\n",
            "        -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,\n",
            "         6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,\n",
            "         1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01,\n",
            "        -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02,\n",
            "        -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01,\n",
            "        -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01,\n",
            "        -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,\n",
            "         6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02,\n",
            "        -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01,\n",
            "         5.3167e-01,  7.3288e-01,  8.7637e-01,  8.9447e-01,  7.4531e-01,\n",
            "         4.3306e-01,  8.4539e-03, -4.4684e-01, -8.4486e-01, -1.1186e+00,\n",
            "        -1.2427e+00, -1.2366e+00, -1.1480e+00, -1.0266e+00, -9.0682e-01,\n",
            "        -8.0169e-01, -7.0644e-01, -6.0223e-01, -4.6095e-01, -2.5555e-01,\n",
            "         2.3599e-02,  3.5616e-01,  6.9432e-01,  9.8070e-01,  1.1713e+00,\n",
            "         1.2524e+00,  1.2458e+00,  1.1988e+00,  1.1586e+00,  1.1427e+00,\n",
            "         1.1216e+00,  1.0305e+00,  8.0576e-01,  4.2371e-01, -8.0183e-02,\n",
            "        -6.2234e-01, -1.1018e+00, -1.4334e+00, -1.5702e+00, -1.5117e+00,\n",
            "        -1.2962e+00, -9.8357e-01, -6.3689e-01, -3.1085e-01, -4.8778e-02,\n",
            "         1.1739e-01,  1.7297e-01,  1.3392e-01,  5.5365e-02,  1.6689e-02,\n",
            "         8.0910e-02,  2.5174e-01,  4.6122e-01,  6.0108e-01,  5.7989e-01,\n",
            "         3.7153e-01,  2.8285e-02, -3.4546e-01, -6.4086e-01, -7.8600e-01,\n",
            "        -7.6016e-01, -5.7996e-01, -2.7628e-01,  1.1550e-01,  5.4575e-01,\n",
            "         9.3697e-01,  1.1903e+00,  1.2226e+00,  1.0160e+00,  6.4423e-01,\n",
            "         2.4919e-01, -2.5545e-02, -1.0466e-01, -1.4519e-02,  1.3798e-01,\n",
            "         2.2799e-01,  1.8045e-01,  3.6818e-03, -2.2875e-01, -4.3080e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37953:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-8.4640e-01, -6.6756e-01, -5.0462e-01, -3.9859e-01, -3.4434e-01,\n",
            "        -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,  8.5538e-01,\n",
            "         1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,  3.3898e-01,\n",
            "        -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01,\n",
            "        -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,\n",
            "         1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01,\n",
            "        -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,\n",
            "         1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01,\n",
            "        -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02,\n",
            "        -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,\n",
            "         4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,\n",
            "         3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,\n",
            "         8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01,\n",
            "        -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01,\n",
            "        -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01,\n",
            "        -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,\n",
            "         7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,\n",
            "         8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01,\n",
            "        -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00,\n",
            "        -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01,\n",
            "        -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,\n",
            "         1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,\n",
            "         7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,\n",
            "         2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00,\n",
            "        -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,\n",
            "         2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,\n",
            "         1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01,\n",
            "        -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,\n",
            "         1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01,\n",
            "        -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01,\n",
            "        -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,\n",
            "         6.4014e-01,  6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,\n",
            "         1.9666e-02, -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,\n",
            "         3.3524e-01,  5.3167e-01,  7.3288e-01,  8.7637e-01,  8.9447e-01,\n",
            "         7.4531e-01,  4.3306e-01,  8.4539e-03, -4.4684e-01, -8.4486e-01,\n",
            "        -1.1186e+00, -1.2427e+00, -1.2366e+00, -1.1480e+00, -1.0266e+00,\n",
            "        -9.0682e-01, -8.0169e-01, -7.0644e-01, -6.0223e-01, -4.6095e-01,\n",
            "        -2.5555e-01,  2.3599e-02,  3.5616e-01,  6.9432e-01,  9.8070e-01,\n",
            "         1.1713e+00,  1.2524e+00,  1.2458e+00,  1.1988e+00,  1.1586e+00,\n",
            "         1.1427e+00,  1.1216e+00,  1.0305e+00,  8.0576e-01,  4.2371e-01,\n",
            "        -8.0183e-02, -6.2234e-01, -1.1018e+00, -1.4334e+00, -1.5702e+00,\n",
            "        -1.5117e+00, -1.2962e+00, -9.8357e-01, -6.3689e-01, -3.1085e-01,\n",
            "        -4.8778e-02,  1.1739e-01,  1.7297e-01,  1.3392e-01,  5.5365e-02,\n",
            "         1.6689e-02,  8.0910e-02,  2.5174e-01,  4.6122e-01,  6.0108e-01,\n",
            "         5.7989e-01,  3.7153e-01,  2.8285e-02, -3.4546e-01, -6.4086e-01,\n",
            "        -7.8600e-01, -7.6016e-01, -5.7996e-01, -2.7628e-01,  1.1550e-01,\n",
            "         5.4575e-01,  9.3697e-01,  1.1903e+00,  1.2226e+00,  1.0160e+00,\n",
            "         6.4423e-01,  2.4919e-01, -2.5545e-02, -1.0466e-01, -1.4519e-02,\n",
            "         1.3798e-01,  2.2799e-01,  1.8045e-01,  3.6818e-03, -2.2875e-01,\n",
            "        -4.3080e-01, -5.5292e-01, -5.9527e-01, -5.8291e-01, -5.3018e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37954:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-3.4434e-01, -2.9058e-01, -1.6492e-01,  8.4396e-02,  4.5030e-01,\n",
            "         8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,  8.2594e-01,\n",
            "         3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01, -7.5325e-01,\n",
            "        -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,\n",
            "         1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01,\n",
            "        -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,\n",
            "         3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01,\n",
            "        -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03,\n",
            "        -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,\n",
            "         2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01,\n",
            "        -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,\n",
            "         9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01,\n",
            "        -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01,\n",
            "        -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01,\n",
            "        -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,\n",
            "         5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,\n",
            "         9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02,\n",
            "        -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00,\n",
            "        -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01,\n",
            "        -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,\n",
            "         9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,\n",
            "         9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,\n",
            "         4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00,\n",
            "        -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01,\n",
            "        -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,\n",
            "         1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01,\n",
            "        -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,\n",
            "         8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01,\n",
            "        -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01,\n",
            "        -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01,\n",
            "         5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01,  3.0302e-01,\n",
            "         1.3249e-01,  1.9666e-02, -2.1144e-02, -9.9446e-05,  6.7880e-02,\n",
            "         1.7843e-01,  3.3524e-01,  5.3167e-01,  7.3288e-01,  8.7637e-01,\n",
            "         8.9447e-01,  7.4531e-01,  4.3306e-01,  8.4539e-03, -4.4684e-01,\n",
            "        -8.4486e-01, -1.1186e+00, -1.2427e+00, -1.2366e+00, -1.1480e+00,\n",
            "        -1.0266e+00, -9.0682e-01, -8.0169e-01, -7.0644e-01, -6.0223e-01,\n",
            "        -4.6095e-01, -2.5555e-01,  2.3599e-02,  3.5616e-01,  6.9432e-01,\n",
            "         9.8070e-01,  1.1713e+00,  1.2524e+00,  1.2458e+00,  1.1988e+00,\n",
            "         1.1586e+00,  1.1427e+00,  1.1216e+00,  1.0305e+00,  8.0576e-01,\n",
            "         4.2371e-01, -8.0183e-02, -6.2234e-01, -1.1018e+00, -1.4334e+00,\n",
            "        -1.5702e+00, -1.5117e+00, -1.2962e+00, -9.8357e-01, -6.3689e-01,\n",
            "        -3.1085e-01, -4.8778e-02,  1.1739e-01,  1.7297e-01,  1.3392e-01,\n",
            "         5.5365e-02,  1.6689e-02,  8.0910e-02,  2.5174e-01,  4.6122e-01,\n",
            "         6.0108e-01,  5.7989e-01,  3.7153e-01,  2.8285e-02, -3.4546e-01,\n",
            "        -6.4086e-01, -7.8600e-01, -7.6016e-01, -5.7996e-01, -2.7628e-01,\n",
            "         1.1550e-01,  5.4575e-01,  9.3697e-01,  1.1903e+00,  1.2226e+00,\n",
            "         1.0160e+00,  6.4423e-01,  2.4919e-01, -2.5545e-02, -1.0466e-01,\n",
            "        -1.4519e-02,  1.3798e-01,  2.2799e-01,  1.8045e-01,  3.6818e-03,\n",
            "        -2.2875e-01, -4.3080e-01, -5.5292e-01, -5.9527e-01, -5.8291e-01,\n",
            "        -5.3018e-01, -4.2712e-01, -2.5819e-01, -3.3978e-02,  1.9365e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37955:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 4.5030e-01,  8.5538e-01,  1.1780e+00,  1.3045e+00,  1.1790e+00,\n",
            "         8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01, -7.3979e-01,\n",
            "        -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01, -6.3659e-02,\n",
            "         5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02,\n",
            "        -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,\n",
            "         3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01,\n",
            "        -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,\n",
            "         1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02,\n",
            "        -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02,\n",
            "        -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,\n",
            "         7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01,\n",
            "        -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01,\n",
            "        -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01,\n",
            "        -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,\n",
            "         2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,\n",
            "         9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01,\n",
            "        -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00,\n",
            "        -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01,\n",
            "        -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,\n",
            "         6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,\n",
            "         1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,\n",
            "         5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01,\n",
            "        -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00,\n",
            "        -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,\n",
            "         1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,\n",
            "         3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01,\n",
            "        -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01,\n",
            "        -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01,\n",
            "        -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,\n",
            "         3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01,\n",
            "         3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02, -9.9446e-05,\n",
            "         6.7880e-02,  1.7843e-01,  3.3524e-01,  5.3167e-01,  7.3288e-01,\n",
            "         8.7637e-01,  8.9447e-01,  7.4531e-01,  4.3306e-01,  8.4539e-03,\n",
            "        -4.4684e-01, -8.4486e-01, -1.1186e+00, -1.2427e+00, -1.2366e+00,\n",
            "        -1.1480e+00, -1.0266e+00, -9.0682e-01, -8.0169e-01, -7.0644e-01,\n",
            "        -6.0223e-01, -4.6095e-01, -2.5555e-01,  2.3599e-02,  3.5616e-01,\n",
            "         6.9432e-01,  9.8070e-01,  1.1713e+00,  1.2524e+00,  1.2458e+00,\n",
            "         1.1988e+00,  1.1586e+00,  1.1427e+00,  1.1216e+00,  1.0305e+00,\n",
            "         8.0576e-01,  4.2371e-01, -8.0183e-02, -6.2234e-01, -1.1018e+00,\n",
            "        -1.4334e+00, -1.5702e+00, -1.5117e+00, -1.2962e+00, -9.8357e-01,\n",
            "        -6.3689e-01, -3.1085e-01, -4.8778e-02,  1.1739e-01,  1.7297e-01,\n",
            "         1.3392e-01,  5.5365e-02,  1.6689e-02,  8.0910e-02,  2.5174e-01,\n",
            "         4.6122e-01,  6.0108e-01,  5.7989e-01,  3.7153e-01,  2.8285e-02,\n",
            "        -3.4546e-01, -6.4086e-01, -7.8600e-01, -7.6016e-01, -5.7996e-01,\n",
            "        -2.7628e-01,  1.1550e-01,  5.4575e-01,  9.3697e-01,  1.1903e+00,\n",
            "         1.2226e+00,  1.0160e+00,  6.4423e-01,  2.4919e-01, -2.5545e-02,\n",
            "        -1.0466e-01, -1.4519e-02,  1.3798e-01,  2.2799e-01,  1.8045e-01,\n",
            "         3.6818e-03, -2.2875e-01, -4.3080e-01, -5.5292e-01, -5.9527e-01,\n",
            "        -5.8291e-01, -5.3018e-01, -4.2712e-01, -2.5819e-01, -3.3978e-02,\n",
            "         1.9365e-01,  3.4767e-01,  3.6422e-01,  2.2963e-01, -5.9961e-03])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37956:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.1790e+00,  8.2594e-01,  3.3898e-01, -1.5478e-01, -5.3798e-01,\n",
            "        -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01, -2.3119e-01,\n",
            "        -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,  7.3724e-02,\n",
            "        -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,\n",
            "         1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02,\n",
            "        -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01,\n",
            "        -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02,\n",
            "        -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02,\n",
            "        -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,\n",
            "         5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,\n",
            "         2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01,\n",
            "        -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01,\n",
            "        -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,\n",
            "         1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,\n",
            "         9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,\n",
            "         3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00,\n",
            "        -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00,\n",
            "        -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,\n",
            "         4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,\n",
            "         1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,\n",
            "         5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01,\n",
            "        -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00,\n",
            "        -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,\n",
            "         9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,\n",
            "         8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01,\n",
            "        -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01,\n",
            "        -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01,\n",
            "        -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,\n",
            "         1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,\n",
            "         4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02,\n",
            "        -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01,  5.3167e-01,\n",
            "         7.3288e-01,  8.7637e-01,  8.9447e-01,  7.4531e-01,  4.3306e-01,\n",
            "         8.4539e-03, -4.4684e-01, -8.4486e-01, -1.1186e+00, -1.2427e+00,\n",
            "        -1.2366e+00, -1.1480e+00, -1.0266e+00, -9.0682e-01, -8.0169e-01,\n",
            "        -7.0644e-01, -6.0223e-01, -4.6095e-01, -2.5555e-01,  2.3599e-02,\n",
            "         3.5616e-01,  6.9432e-01,  9.8070e-01,  1.1713e+00,  1.2524e+00,\n",
            "         1.2458e+00,  1.1988e+00,  1.1586e+00,  1.1427e+00,  1.1216e+00,\n",
            "         1.0305e+00,  8.0576e-01,  4.2371e-01, -8.0183e-02, -6.2234e-01,\n",
            "        -1.1018e+00, -1.4334e+00, -1.5702e+00, -1.5117e+00, -1.2962e+00,\n",
            "        -9.8357e-01, -6.3689e-01, -3.1085e-01, -4.8778e-02,  1.1739e-01,\n",
            "         1.7297e-01,  1.3392e-01,  5.5365e-02,  1.6689e-02,  8.0910e-02,\n",
            "         2.5174e-01,  4.6122e-01,  6.0108e-01,  5.7989e-01,  3.7153e-01,\n",
            "         2.8285e-02, -3.4546e-01, -6.4086e-01, -7.8600e-01, -7.6016e-01,\n",
            "        -5.7996e-01, -2.7628e-01,  1.1550e-01,  5.4575e-01,  9.3697e-01,\n",
            "         1.1903e+00,  1.2226e+00,  1.0160e+00,  6.4423e-01,  2.4919e-01,\n",
            "        -2.5545e-02, -1.0466e-01, -1.4519e-02,  1.3798e-01,  2.2799e-01,\n",
            "         1.8045e-01,  3.6818e-03, -2.2875e-01, -4.3080e-01, -5.5292e-01,\n",
            "        -5.9527e-01, -5.8291e-01, -5.3018e-01, -4.2712e-01, -2.5819e-01,\n",
            "        -3.3978e-02,  1.9365e-01,  3.4767e-01,  3.6422e-01,  2.2963e-01,\n",
            "        -5.9961e-03, -2.4850e-01, -4.0502e-01, -4.3130e-01, -3.5246e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37957:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-5.3798e-01, -7.3979e-01, -7.5325e-01, -6.2617e-01, -4.3098e-01,\n",
            "        -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,  1.3055e-01,\n",
            "         7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01, -1.3733e-01,\n",
            "         2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01,\n",
            "        -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02,\n",
            "        -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,\n",
            "         1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,\n",
            "         2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,\n",
            "         5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01,\n",
            "        -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01,\n",
            "        -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01,\n",
            "        -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,\n",
            "         8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,\n",
            "         6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01,\n",
            "        -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00,\n",
            "        -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,\n",
            "         2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,\n",
            "         1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,\n",
            "         6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01,\n",
            "        -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00,\n",
            "        -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,\n",
            "         6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,\n",
            "         1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01,\n",
            "        -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02,\n",
            "        -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01,\n",
            "        -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01,\n",
            "        -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,\n",
            "         6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02,\n",
            "        -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01,\n",
            "         5.3167e-01,  7.3288e-01,  8.7637e-01,  8.9447e-01,  7.4531e-01,\n",
            "         4.3306e-01,  8.4539e-03, -4.4684e-01, -8.4486e-01, -1.1186e+00,\n",
            "        -1.2427e+00, -1.2366e+00, -1.1480e+00, -1.0266e+00, -9.0682e-01,\n",
            "        -8.0169e-01, -7.0644e-01, -6.0223e-01, -4.6095e-01, -2.5555e-01,\n",
            "         2.3599e-02,  3.5616e-01,  6.9432e-01,  9.8070e-01,  1.1713e+00,\n",
            "         1.2524e+00,  1.2458e+00,  1.1988e+00,  1.1586e+00,  1.1427e+00,\n",
            "         1.1216e+00,  1.0305e+00,  8.0576e-01,  4.2371e-01, -8.0183e-02,\n",
            "        -6.2234e-01, -1.1018e+00, -1.4334e+00, -1.5702e+00, -1.5117e+00,\n",
            "        -1.2962e+00, -9.8357e-01, -6.3689e-01, -3.1085e-01, -4.8778e-02,\n",
            "         1.1739e-01,  1.7297e-01,  1.3392e-01,  5.5365e-02,  1.6689e-02,\n",
            "         8.0910e-02,  2.5174e-01,  4.6122e-01,  6.0108e-01,  5.7989e-01,\n",
            "         3.7153e-01,  2.8285e-02, -3.4546e-01, -6.4086e-01, -7.8600e-01,\n",
            "        -7.6016e-01, -5.7996e-01, -2.7628e-01,  1.1550e-01,  5.4575e-01,\n",
            "         9.3697e-01,  1.1903e+00,  1.2226e+00,  1.0160e+00,  6.4423e-01,\n",
            "         2.4919e-01, -2.5545e-02, -1.0466e-01, -1.4519e-02,  1.3798e-01,\n",
            "         2.2799e-01,  1.8045e-01,  3.6818e-03, -2.2875e-01, -4.3080e-01,\n",
            "        -5.5292e-01, -5.9527e-01, -5.8291e-01, -5.3018e-01, -4.2712e-01,\n",
            "        -2.5819e-01, -3.3978e-02,  1.9365e-01,  3.4767e-01,  3.6422e-01,\n",
            "         2.2963e-01, -5.9961e-03, -2.4850e-01, -4.0502e-01, -4.3130e-01,\n",
            "        -3.5246e-01, -2.4315e-01, -1.7987e-01, -1.9699e-01, -2.7293e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37958:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-4.3098e-01, -2.3119e-01, -6.3659e-02,  5.7221e-02,  1.2451e-01,\n",
            "         1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01, -1.8189e-01,\n",
            "        -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,  3.2420e-01,\n",
            "         1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01,\n",
            "        -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02,\n",
            "        -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,\n",
            "         4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,\n",
            "         3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,\n",
            "         8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01,\n",
            "        -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01,\n",
            "        -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01,\n",
            "        -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,\n",
            "         7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,\n",
            "         8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01,\n",
            "        -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00,\n",
            "        -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01,\n",
            "        -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,\n",
            "         1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,\n",
            "         7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,\n",
            "         2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00,\n",
            "        -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,\n",
            "         2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,\n",
            "         1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01,\n",
            "        -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,\n",
            "         1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01,\n",
            "        -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01,\n",
            "        -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,\n",
            "         6.4014e-01,  6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,\n",
            "         1.9666e-02, -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,\n",
            "         3.3524e-01,  5.3167e-01,  7.3288e-01,  8.7637e-01,  8.9447e-01,\n",
            "         7.4531e-01,  4.3306e-01,  8.4539e-03, -4.4684e-01, -8.4486e-01,\n",
            "        -1.1186e+00, -1.2427e+00, -1.2366e+00, -1.1480e+00, -1.0266e+00,\n",
            "        -9.0682e-01, -8.0169e-01, -7.0644e-01, -6.0223e-01, -4.6095e-01,\n",
            "        -2.5555e-01,  2.3599e-02,  3.5616e-01,  6.9432e-01,  9.8070e-01,\n",
            "         1.1713e+00,  1.2524e+00,  1.2458e+00,  1.1988e+00,  1.1586e+00,\n",
            "         1.1427e+00,  1.1216e+00,  1.0305e+00,  8.0576e-01,  4.2371e-01,\n",
            "        -8.0183e-02, -6.2234e-01, -1.1018e+00, -1.4334e+00, -1.5702e+00,\n",
            "        -1.5117e+00, -1.2962e+00, -9.8357e-01, -6.3689e-01, -3.1085e-01,\n",
            "        -4.8778e-02,  1.1739e-01,  1.7297e-01,  1.3392e-01,  5.5365e-02,\n",
            "         1.6689e-02,  8.0910e-02,  2.5174e-01,  4.6122e-01,  6.0108e-01,\n",
            "         5.7989e-01,  3.7153e-01,  2.8285e-02, -3.4546e-01, -6.4086e-01,\n",
            "        -7.8600e-01, -7.6016e-01, -5.7996e-01, -2.7628e-01,  1.1550e-01,\n",
            "         5.4575e-01,  9.3697e-01,  1.1903e+00,  1.2226e+00,  1.0160e+00,\n",
            "         6.4423e-01,  2.4919e-01, -2.5545e-02, -1.0466e-01, -1.4519e-02,\n",
            "         1.3798e-01,  2.2799e-01,  1.8045e-01,  3.6818e-03, -2.2875e-01,\n",
            "        -4.3080e-01, -5.5292e-01, -5.9527e-01, -5.8291e-01, -5.3018e-01,\n",
            "        -4.2712e-01, -2.5819e-01, -3.3978e-02,  1.9365e-01,  3.4767e-01,\n",
            "         3.6422e-01,  2.2963e-01, -5.9961e-03, -2.4850e-01, -4.0502e-01,\n",
            "        -4.3130e-01, -3.5246e-01, -2.4315e-01, -1.7987e-01, -1.9699e-01,\n",
            "        -2.7293e-01, -3.5135e-01, -3.8003e-01, -3.4129e-01, -2.5651e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37959:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.2451e-01,  1.3055e-01,  7.3724e-02, -2.7908e-02, -1.3155e-01,\n",
            "        -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,  3.1922e-01,\n",
            "         3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01, -4.3933e-01,\n",
            "        -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,  1.7905e-03,\n",
            "        -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02, -3.0115e-02,\n",
            "         2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02, -1.0608e-01,\n",
            "        -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,  7.9183e-01,\n",
            "         9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01, -1.3142e-01,\n",
            "        -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01, -4.2383e-01,\n",
            "        -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01, -3.3250e-01,\n",
            "        -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,  2.8153e-01,\n",
            "         5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,  9.9938e-01,\n",
            "         9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01, -7.3960e-02,\n",
            "        -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00, -1.4707e+00,\n",
            "        -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01, -5.7223e-01,\n",
            "        -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,  6.9732e-01,\n",
            "         9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,  1.1905e+00,\n",
            "         9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,  5.6510e-01,\n",
            "         4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01, -1.3279e+00,\n",
            "        -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00, -9.1336e-01,\n",
            "        -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,  1.1359e+00,\n",
            "         1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,  3.1847e-01,\n",
            "        -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01, -1.4956e-02,\n",
            "         8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01, -6.4859e-01,\n",
            "        -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01, -3.7756e-01,\n",
            "        -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,  3.4025e-01,\n",
            "         5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01,  3.0302e-01,\n",
            "         1.3249e-01,  1.9666e-02, -2.1144e-02, -9.9446e-05,  6.7880e-02,\n",
            "         1.7843e-01,  3.3524e-01,  5.3167e-01,  7.3288e-01,  8.7637e-01,\n",
            "         8.9447e-01,  7.4531e-01,  4.3306e-01,  8.4539e-03, -4.4684e-01,\n",
            "        -8.4486e-01, -1.1186e+00, -1.2427e+00, -1.2366e+00, -1.1480e+00,\n",
            "        -1.0266e+00, -9.0682e-01, -8.0169e-01, -7.0644e-01, -6.0223e-01,\n",
            "        -4.6095e-01, -2.5555e-01,  2.3599e-02,  3.5616e-01,  6.9432e-01,\n",
            "         9.8070e-01,  1.1713e+00,  1.2524e+00,  1.2458e+00,  1.1988e+00,\n",
            "         1.1586e+00,  1.1427e+00,  1.1216e+00,  1.0305e+00,  8.0576e-01,\n",
            "         4.2371e-01, -8.0183e-02, -6.2234e-01, -1.1018e+00, -1.4334e+00,\n",
            "        -1.5702e+00, -1.5117e+00, -1.2962e+00, -9.8357e-01, -6.3689e-01,\n",
            "        -3.1085e-01, -4.8778e-02,  1.1739e-01,  1.7297e-01,  1.3392e-01,\n",
            "         5.5365e-02,  1.6689e-02,  8.0910e-02,  2.5174e-01,  4.6122e-01,\n",
            "         6.0108e-01,  5.7989e-01,  3.7153e-01,  2.8285e-02, -3.4546e-01,\n",
            "        -6.4086e-01, -7.8600e-01, -7.6016e-01, -5.7996e-01, -2.7628e-01,\n",
            "         1.1550e-01,  5.4575e-01,  9.3697e-01,  1.1903e+00,  1.2226e+00,\n",
            "         1.0160e+00,  6.4423e-01,  2.4919e-01, -2.5545e-02, -1.0466e-01,\n",
            "        -1.4519e-02,  1.3798e-01,  2.2799e-01,  1.8045e-01,  3.6818e-03,\n",
            "        -2.2875e-01, -4.3080e-01, -5.5292e-01, -5.9527e-01, -5.8291e-01,\n",
            "        -5.3018e-01, -4.2712e-01, -2.5819e-01, -3.3978e-02,  1.9365e-01,\n",
            "         3.4767e-01,  3.6422e-01,  2.2963e-01, -5.9961e-03, -2.4850e-01,\n",
            "        -4.0502e-01, -4.3130e-01, -3.5246e-01, -2.4315e-01, -1.7987e-01,\n",
            "        -1.9699e-01, -2.7293e-01, -3.5135e-01, -3.8003e-01, -3.4129e-01,\n",
            "        -2.5651e-01, -1.6550e-01, -9.7559e-02, -5.4978e-02, -1.8634e-02])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37960:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-1.3155e-01, -1.8189e-01, -1.3733e-01,  2.5258e-03,  1.8465e-01,\n",
            "         3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02, -3.1019e-01,\n",
            "        -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01, -3.1504e-02,\n",
            "         1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02, -8.2278e-02,\n",
            "        -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02, -5.5203e-02,\n",
            "        -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,  5.4228e-01,\n",
            "         7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,  2.2378e-01,\n",
            "        -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01, -5.0663e-01,\n",
            "        -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01, -2.7581e-01,\n",
            "        -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,  1.4114e-02,\n",
            "         2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,  9.7414e-01,\n",
            "         9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,  3.2316e-01,\n",
            "        -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00, -1.3691e+00,\n",
            "        -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00, -8.7931e-01,\n",
            "        -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,  4.3563e-01,\n",
            "         6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,  1.3351e+00,\n",
            "         1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,  5.8905e-01,\n",
            "         5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01, -7.3666e-01,\n",
            "        -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00, -1.4951e+00,\n",
            "        -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,  9.0031e-01,\n",
            "         1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,  8.2166e-01,\n",
            "         3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01, -2.3353e-01,\n",
            "        -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01, -4.5580e-01,\n",
            "        -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01, -4.6601e-01,\n",
            "        -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,  1.0583e-01,\n",
            "         3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,  4.8545e-01,\n",
            "         3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02, -9.9446e-05,\n",
            "         6.7880e-02,  1.7843e-01,  3.3524e-01,  5.3167e-01,  7.3288e-01,\n",
            "         8.7637e-01,  8.9447e-01,  7.4531e-01,  4.3306e-01,  8.4539e-03,\n",
            "        -4.4684e-01, -8.4486e-01, -1.1186e+00, -1.2427e+00, -1.2366e+00,\n",
            "        -1.1480e+00, -1.0266e+00, -9.0682e-01, -8.0169e-01, -7.0644e-01,\n",
            "        -6.0223e-01, -4.6095e-01, -2.5555e-01,  2.3599e-02,  3.5616e-01,\n",
            "         6.9432e-01,  9.8070e-01,  1.1713e+00,  1.2524e+00,  1.2458e+00,\n",
            "         1.1988e+00,  1.1586e+00,  1.1427e+00,  1.1216e+00,  1.0305e+00,\n",
            "         8.0576e-01,  4.2371e-01, -8.0183e-02, -6.2234e-01, -1.1018e+00,\n",
            "        -1.4334e+00, -1.5702e+00, -1.5117e+00, -1.2962e+00, -9.8357e-01,\n",
            "        -6.3689e-01, -3.1085e-01, -4.8778e-02,  1.1739e-01,  1.7297e-01,\n",
            "         1.3392e-01,  5.5365e-02,  1.6689e-02,  8.0910e-02,  2.5174e-01,\n",
            "         4.6122e-01,  6.0108e-01,  5.7989e-01,  3.7153e-01,  2.8285e-02,\n",
            "        -3.4546e-01, -6.4086e-01, -7.8600e-01, -7.6016e-01, -5.7996e-01,\n",
            "        -2.7628e-01,  1.1550e-01,  5.4575e-01,  9.3697e-01,  1.1903e+00,\n",
            "         1.2226e+00,  1.0160e+00,  6.4423e-01,  2.4919e-01, -2.5545e-02,\n",
            "        -1.0466e-01, -1.4519e-02,  1.3798e-01,  2.2799e-01,  1.8045e-01,\n",
            "         3.6818e-03, -2.2875e-01, -4.3080e-01, -5.5292e-01, -5.9527e-01,\n",
            "        -5.8291e-01, -5.3018e-01, -4.2712e-01, -2.5819e-01, -3.3978e-02,\n",
            "         1.9365e-01,  3.4767e-01,  3.6422e-01,  2.2963e-01, -5.9961e-03,\n",
            "        -2.4850e-01, -4.0502e-01, -4.3130e-01, -3.5246e-01, -2.4315e-01,\n",
            "        -1.7987e-01, -1.9699e-01, -2.7293e-01, -3.5135e-01, -3.8003e-01,\n",
            "        -3.4129e-01, -2.5651e-01, -1.6550e-01, -9.7559e-02, -5.4978e-02,\n",
            "        -1.8634e-02,  3.1857e-02,  1.0244e-01,  1.8819e-01,  2.9242e-01])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37961:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([ 1.8465e-01,  3.1922e-01,  3.2420e-01,  1.7543e-01, -7.1962e-02,\n",
            "        -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01, -1.4082e-01,\n",
            "        -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02, -9.9689e-02,\n",
            "        -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,  1.0081e-02,\n",
            "        -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,  2.6098e-01,\n",
            "         5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,  5.8509e-01,\n",
            "         2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01, -5.5323e-01,\n",
            "        -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01, -2.4644e-01,\n",
            "        -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01, -2.0535e-01,\n",
            "         1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,  8.9526e-01,\n",
            "         9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,  6.4320e-01,\n",
            "         3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01, -1.1679e+00,\n",
            "        -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00, -1.1574e+00,\n",
            "        -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,  2.0205e-01,\n",
            "         4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,  1.3456e+00,\n",
            "         1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,  6.3896e-01,\n",
            "         5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01, -1.7671e-01,\n",
            "        -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00, -1.9017e+00,\n",
            "        -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,  6.0476e-01,\n",
            "         9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,  1.1948e+00,\n",
            "         8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01, -4.1942e-01,\n",
            "        -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02, -2.0301e-01,\n",
            "        -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01, -5.8267e-01,\n",
            "        -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01, -9.7830e-02,\n",
            "         1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,  6.1597e-01,\n",
            "         4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02, -2.1144e-02,\n",
            "        -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01,  5.3167e-01,\n",
            "         7.3288e-01,  8.7637e-01,  8.9447e-01,  7.4531e-01,  4.3306e-01,\n",
            "         8.4539e-03, -4.4684e-01, -8.4486e-01, -1.1186e+00, -1.2427e+00,\n",
            "        -1.2366e+00, -1.1480e+00, -1.0266e+00, -9.0682e-01, -8.0169e-01,\n",
            "        -7.0644e-01, -6.0223e-01, -4.6095e-01, -2.5555e-01,  2.3599e-02,\n",
            "         3.5616e-01,  6.9432e-01,  9.8070e-01,  1.1713e+00,  1.2524e+00,\n",
            "         1.2458e+00,  1.1988e+00,  1.1586e+00,  1.1427e+00,  1.1216e+00,\n",
            "         1.0305e+00,  8.0576e-01,  4.2371e-01, -8.0183e-02, -6.2234e-01,\n",
            "        -1.1018e+00, -1.4334e+00, -1.5702e+00, -1.5117e+00, -1.2962e+00,\n",
            "        -9.8357e-01, -6.3689e-01, -3.1085e-01, -4.8778e-02,  1.1739e-01,\n",
            "         1.7297e-01,  1.3392e-01,  5.5365e-02,  1.6689e-02,  8.0910e-02,\n",
            "         2.5174e-01,  4.6122e-01,  6.0108e-01,  5.7989e-01,  3.7153e-01,\n",
            "         2.8285e-02, -3.4546e-01, -6.4086e-01, -7.8600e-01, -7.6016e-01,\n",
            "        -5.7996e-01, -2.7628e-01,  1.1550e-01,  5.4575e-01,  9.3697e-01,\n",
            "         1.1903e+00,  1.2226e+00,  1.0160e+00,  6.4423e-01,  2.4919e-01,\n",
            "        -2.5545e-02, -1.0466e-01, -1.4519e-02,  1.3798e-01,  2.2799e-01,\n",
            "         1.8045e-01,  3.6818e-03, -2.2875e-01, -4.3080e-01, -5.5292e-01,\n",
            "        -5.9527e-01, -5.8291e-01, -5.3018e-01, -4.2712e-01, -2.5819e-01,\n",
            "        -3.3978e-02,  1.9365e-01,  3.4767e-01,  3.6422e-01,  2.2963e-01,\n",
            "        -5.9961e-03, -2.4850e-01, -4.0502e-01, -4.3130e-01, -3.5246e-01,\n",
            "        -2.4315e-01, -1.7987e-01, -1.9699e-01, -2.7293e-01, -3.5135e-01,\n",
            "        -3.8003e-01, -3.4129e-01, -2.5651e-01, -1.6550e-01, -9.7559e-02,\n",
            "        -5.4978e-02, -1.8634e-02,  3.1857e-02,  1.0244e-01,  1.8819e-01,\n",
            "         2.9242e-01,  4.3898e-01,  6.5717e-01,  9.4499e-01,  1.2449e+00])\n",
            "Label shape: torch.Size([2])\n",
            "Sample 37962:\n",
            "Data shape: torch.Size([16, 250])\n",
            "tensor([-7.1962e-02, -3.1019e-01, -4.3933e-01, -4.2176e-01, -2.9530e-01,\n",
            "        -1.4082e-01, -3.1504e-02,  1.7905e-03, -2.6035e-02, -7.3777e-02,\n",
            "        -9.9689e-02, -8.2278e-02, -3.0115e-02,  2.3820e-02,  4.2586e-02,\n",
            "         1.0081e-02, -5.5203e-02, -1.0608e-01, -8.8150e-02,  3.4787e-02,\n",
            "         2.6098e-01,  5.4228e-01,  7.9183e-01,  9.1256e-01,  8.4120e-01,\n",
            "         5.8509e-01,  2.2378e-01, -1.3142e-01, -3.9267e-01, -5.2772e-01,\n",
            "        -5.5323e-01, -5.0663e-01, -4.2383e-01, -3.3488e-01, -2.6795e-01,\n",
            "        -2.4644e-01, -2.7581e-01, -3.3250e-01, -3.6914e-01, -3.3594e-01,\n",
            "        -2.0535e-01,  1.4114e-02,  2.8153e-01,  5.4243e-01,  7.5299e-01,\n",
            "         8.9526e-01,  9.7414e-01,  9.9938e-01,  9.6723e-01,  8.5652e-01,\n",
            "         6.4320e-01,  3.2316e-01, -7.3960e-02, -4.9165e-01, -8.6992e-01,\n",
            "        -1.1679e+00, -1.3691e+00, -1.4707e+00, -1.4697e+00, -1.3630e+00,\n",
            "        -1.1574e+00, -8.7931e-01, -5.7223e-01, -2.8036e-01, -2.5933e-02,\n",
            "         2.0205e-01,  4.3563e-01,  6.9732e-01,  9.7335e-01,  1.2113e+00,\n",
            "         1.3456e+00,  1.3351e+00,  1.1905e+00,  9.7391e-01,  7.6938e-01,\n",
            "         6.3896e-01,  5.8905e-01,  5.6510e-01,  4.7682e-01,  2.4096e-01,\n",
            "        -1.7671e-01, -7.3666e-01, -1.3279e+00, -1.7995e+00, -2.0137e+00,\n",
            "        -1.9017e+00, -1.4951e+00, -9.1336e-01, -3.0676e-01,  2.1147e-01,\n",
            "         6.0476e-01,  9.0031e-01,  1.1359e+00,  1.3065e+00,  1.3509e+00,\n",
            "         1.1948e+00,  8.2166e-01,  3.1847e-01, -1.4750e-01, -4.1449e-01,\n",
            "        -4.1942e-01, -2.3353e-01, -1.4956e-02,  8.7236e-02,  1.1170e-02,\n",
            "        -2.0301e-01, -4.5580e-01, -6.4859e-01, -7.2604e-01, -6.8908e-01,\n",
            "        -5.8267e-01, -4.6601e-01, -3.7756e-01, -3.1342e-01, -2.3429e-01,\n",
            "        -9.7830e-02,  1.0583e-01,  3.4025e-01,  5.3908e-01,  6.4014e-01,\n",
            "         6.1597e-01,  4.8545e-01,  3.0302e-01,  1.3249e-01,  1.9666e-02,\n",
            "        -2.1144e-02, -9.9446e-05,  6.7880e-02,  1.7843e-01,  3.3524e-01,\n",
            "         5.3167e-01,  7.3288e-01,  8.7637e-01,  8.9447e-01,  7.4531e-01,\n",
            "         4.3306e-01,  8.4539e-03, -4.4684e-01, -8.4486e-01, -1.1186e+00,\n",
            "        -1.2427e+00, -1.2366e+00, -1.1480e+00, -1.0266e+00, -9.0682e-01,\n",
            "        -8.0169e-01, -7.0644e-01, -6.0223e-01, -4.6095e-01, -2.5555e-01,\n",
            "         2.3599e-02,  3.5616e-01,  6.9432e-01,  9.8070e-01,  1.1713e+00,\n",
            "         1.2524e+00,  1.2458e+00,  1.1988e+00,  1.1586e+00,  1.1427e+00,\n",
            "         1.1216e+00,  1.0305e+00,  8.0576e-01,  4.2371e-01, -8.0183e-02,\n",
            "        -6.2234e-01, -1.1018e+00, -1.4334e+00, -1.5702e+00, -1.5117e+00,\n",
            "        -1.2962e+00, -9.8357e-01, -6.3689e-01, -3.1085e-01, -4.8778e-02,\n",
            "         1.1739e-01,  1.7297e-01,  1.3392e-01,  5.5365e-02,  1.6689e-02,\n",
            "         8.0910e-02,  2.5174e-01,  4.6122e-01,  6.0108e-01,  5.7989e-01,\n",
            "         3.7153e-01,  2.8285e-02, -3.4546e-01, -6.4086e-01, -7.8600e-01,\n",
            "        -7.6016e-01, -5.7996e-01, -2.7628e-01,  1.1550e-01,  5.4575e-01,\n",
            "         9.3697e-01,  1.1903e+00,  1.2226e+00,  1.0160e+00,  6.4423e-01,\n",
            "         2.4919e-01, -2.5545e-02, -1.0466e-01, -1.4519e-02,  1.3798e-01,\n",
            "         2.2799e-01,  1.8045e-01,  3.6818e-03, -2.2875e-01, -4.3080e-01,\n",
            "        -5.5292e-01, -5.9527e-01, -5.8291e-01, -5.3018e-01, -4.2712e-01,\n",
            "        -2.5819e-01, -3.3978e-02,  1.9365e-01,  3.4767e-01,  3.6422e-01,\n",
            "         2.2963e-01, -5.9961e-03, -2.4850e-01, -4.0502e-01, -4.3130e-01,\n",
            "        -3.5246e-01, -2.4315e-01, -1.7987e-01, -1.9699e-01, -2.7293e-01,\n",
            "        -3.5135e-01, -3.8003e-01, -3.4129e-01, -2.5651e-01, -1.6550e-01,\n",
            "        -9.7559e-02, -5.4978e-02, -1.8634e-02,  3.1857e-02,  1.0244e-01,\n",
            "         1.8819e-01,  2.9242e-01,  4.3898e-01,  6.5717e-01,  9.4499e-01,\n",
            "         1.2449e+00,  1.4608e+00,  1.5072e+00,  1.3521e+00,  1.0216e+00])\n",
            "Label shape: torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6YQ7_BxdwCmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d9ac62-d00f-4358-ddb4-ca29ff786a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "['EEGMouse_Nathan_3_54_1329.npy', 'EEGMouse_Nathan_1_29_867.npy', 'EEGMouse_Nathan_1_26_799.npy', 'EEGMouse_Nathan_3_19_684.npy', 'EEGMouse_Nathan_1_13_560.npy', 'EEGMouse_Nathan_1_16_624.npy', 'EEGMouse_Nathan_3_19_674.npy', 'EEGMouse_Nathan_3_4_370.npy', 'EEGMouse_Nathan_3_56_1377.npy', 'EEGMouse_Nathan_1_50_1246.npy', 'EEGMouse_Nathan_3_47_1174.npy', 'EEGMouse_Nathan_1_52_1290.npy', 'EEGMouse_Nathan_1_27_817.npy', 'EEGMouse_Nathan_1_57_1398.npy', 'EEGMouse_Nathan_3_37_1028.npy', 'EEGMouse_Nathan_3_19_680.npy', 'EEGMouse_Nathan_3_22_730.npy', 'EEGMouse_Nathan_3_40_1063.npy', 'EEGMouse_Nathan_3_36_994.npy', 'EEGMouse_Nathan_1_37_1017.npy', 'EEGMouse_Nathan_1_5_385.npy', 'EEGMouse_Nathan_3_35_976.npy', 'EEGMouse_Nathan_3_10_495.npy', 'EEGMouse_Nathan_3_7_451.npy', 'EEGMouse_Nathan_3_32_924.npy', 'EEGMouse_Nathan_1_30_885.npy', 'EEGMouse_Nathan_3_32_922.npy', 'EEGMouse_Nathan_1_21_707.npy', 'EEGMouse_Nathan_3_1_338.npy', 'EEGMouse_Nathan_1_44_1125.npy', 'EEGMouse_Nathan_1_54_1338.npy', 'EEGMouse_Nathan_3_16_625.npy', 'EEGMouse_Nathan_3_26_806.npy', 'EEGMouse_Nathan_1_52_1288.npy', 'EEGMouse_Nathan_3_28_848.npy', 'EEGMouse_Nathan_3_4_374.npy', 'EEGMouse_Nathan_1_25_789.npy', 'EEGMouse_Nathan_3_43_1108.npy', 'EEGMouse_Nathan_3_12_543.npy', 'EEGMouse_Nathan_1_56_1372.npy', 'EEGMouse_Nathan_1_56_1362.npy', 'EEGMouse_Nathan_3_18_668.npy', 'EEGMouse_Nathan_1_25_783.npy', 'EEGMouse_Nathan_1_48_1209.npy', 'EEGMouse_Nathan_1_35_979.npy', 'EEGMouse_Nathan_1_29_869.npy', 'EEGMouse_Nathan_3_46_1149.npy', 'EEGMouse_Nathan_1_54_1336.npy', 'EEGMouse_Nathan_1_42_1097.npy', 'EEGMouse_Nathan_3_48_1208.npy', 'EEGMouse_Nathan_3_55_1355.npy', 'EEGMouse_Nathan_1_35_977.npy', 'EEGMouse_Nathan_1_47_1183.npy', 'EEGMouse_Nathan_3_25_788.npy', 'EEGMouse_Nathan_3_17_651.npy', 'EEGMouse_Nathan_3_20_643.npy', 'EEGMouse_Nathan_3_39_1060.npy', 'EEGMouse_Nathan_1_10_492.npy', 'EEGMouse_Nathan_1_1_334.npy', 'EEGMouse_Nathan_1_40_1064.npy', 'EEGMouse_Nathan_3_9_473.npy', 'EEGMouse_Nathan_1_51_1266.npy', 'EEGMouse_Nathan_1_36_997.npy', 'EEGMouse_Nathan_3_40_1075.npy', 'EEGMouse_Nathan_1_55_1346.npy', 'EEGMouse_Nathan_3_18_664.npy', 'EEGMouse_Nathan_1_30_873.npy', 'EEGMouse_Nathan_1_55_1342.npy', 'EEGMouse_Nathan_3_16_621.npy', 'EEGMouse_Nathan_3_19_690.npy', 'EEGMouse_Nathan_1_55_1340.npy', 'EEGMouse_Nathan_3_38_1034.npy', 'EEGMouse_Nathan_1_18_661.npy', 'EEGMouse_Nathan_3_15_603.npy', 'EEGMouse_Nathan_3_51_1279.npy', 'EEGMouse_Nathan_3_19_682.npy', 'EEGMouse_Nathan_3_52_1297.npy', 'EEGMouse_Nathan_1_56_1364.npy', 'EEGMouse_Nathan_3_38_1038.npy', 'EEGMouse_Nathan_3_24_772.npy', 'EEGMouse_Nathan_3_42_1100.npy', 'EEGMouse_Nathan_1_27_823.npy', 'EEGMouse_Nathan_3_11_519.npy', 'EEGMouse_Nathan_1_3_360.npy', 'EEGMouse_Nathan_3_24_754.npy', 'EEGMouse_Nathan_3_35_982.npy', 'EEGMouse_Nathan_3_14_581.npy', 'EEGMouse_Nathan_1_30_889.npy', 'EEGMouse_Nathan_1_2_334.npy', 'EEGMouse_Nathan_3_48_1202.npy', 'EEGMouse_Nathan_1_6_406.npy', 'EEGMouse_Nathan_1_53_1316.npy', 'EEGMouse_Nathan_3_48_1204.npy', 'EEGMouse_Nathan_3_7_463.npy', 'EEGMouse_Nathan_1_9_469.npy', 'EEGMouse_Nathan_1_14_588.npy', 'EEGMouse_Nathan_3_20_637.npy', 'EEGMouse_Nathan_1_16_626.npy', 'EEGMouse_Nathan_1_57_1382.npy', 'EEGMouse_Nathan_1_35_975.npy', 'EEGMouse_Nathan_3_56_1379.npy', 'EEGMouse_Nathan_3_9_479.npy', 'EEGMouse_Nathan_3_38_1052.npy', 'EEGMouse_Nathan_1_22_727.npy', 'EEGMouse_Nathan_1_43_1117.npy', 'EEGMouse_Nathan_3_10_507.npy', 'EEGMouse_Nathan_1_9_474.npy', 'EEGMouse_Nathan_1_48_1203.npy', 'EEGMouse_Nathan_3_53_1301.npy', 'EEGMouse_Nathan_1_29_859.npy', 'EEGMouse_Nathan_1_28_833.npy', 'EEGMouse_Nathan_3_9_487.npy', 'EEGMouse_Nathan_3_27_824.npy', 'EEGMouse_Nathan_3_46_1153.npy', 'EEGMouse_Nathan_1_48_1211.npy', 'EEGMouse_Nathan_1_46_1150.npy', 'EEGMouse_Nathan_1_33_941.npy', 'EEGMouse_Nathan_3_11_523.npy', 'EEGMouse_Nathan_1_6_423.npy', 'EEGMouse_Nathan_3_49_1231.npy', 'EEGMouse_Nathan_1_3_363.npy', 'EEGMouse_Nathan_3_19_692.npy', 'EEGMouse_Nathan_1_47_1191.npy', 'EEGMouse_Nathan_3_27_826.npy', 'EEGMouse_Nathan_3_56_1371.npy', 'EEGMouse_Nathan_1_42_1085.npy', 'EEGMouse_Nathan_3_31_912.npy', 'EEGMouse_Nathan_1_43_1115.npy', 'EEGMouse_Nathan_1_56_1370.npy', 'EEGMouse_Nathan_3_26_800.npy', 'EEGMouse_Nathan_1_20_444.npy', 'EEGMouse_Nathan_3_2_327.npy', 'EEGMouse_Nathan_1_23_741.npy', 'EEGMouse_Nathan_3_43_1114.npy', 'EEGMouse_Nathan_3_38_1046.npy', 'EEGMouse_Nathan_1_35_989.npy', 'EEGMouse_Nathan_3_3_351.npy', 'EEGMouse_Nathan_1_30_891.npy', 'EEGMouse_Nathan_1_28_837.npy', 'EEGMouse_Nathan_1_1_343.npy', 'EEGMouse_Nathan_3_49_1235.npy', 'EEGMouse_Nathan_1_51_1258.npy', 'EEGMouse_Nathan_3_44_1130.npy', 'EEGMouse_Nathan_3_46_1165.npy', 'EEGMouse_Nathan_3_51_1275.npy', 'EEGMouse_Nathan_3_51_1273.npy', 'EEGMouse_Nathan_1_26_805.npy', 'EEGMouse_Nathan_3_53_1317.npy', 'EEGMouse_Nathan_1_41_1082.npy', 'EEGMouse_Nathan_1_50_1236.npy', 'EEGMouse_Nathan_1_3_347.npy', 'EEGMouse_Nathan_3_9_472.npy', 'EEGMouse_Nathan_3_40_1079.npy', 'EEGMouse_Nathan_1_32_929.npy', 'EEGMouse_Nathan_3_29_870.npy', 'EEGMouse_Nathan_1_28_841.npy', 'EEGMouse_Nathan_3_48_1198.npy', 'EEGMouse_Nathan_1_26_809.npy', 'EEGMouse_Nathan_1_15_590.npy', 'EEGMouse_Nathan_3_15_605.npy', 'EEGMouse_Nathan_3_28_842.npy', 'EEGMouse_Nathan_3_3_356.npy', 'EEGMouse_Nathan_3_6_410.npy', 'EEGMouse_Nathan_1_55_1344.npy', 'EEGMouse_Nathan_1_43_1119.npy', 'EEGMouse_Nathan_3_15_593.npy', 'EEGMouse_Nathan_3_34_962.npy', 'EEGMouse_Nathan_1_26_793.npy', 'EEGMouse_Nathan_3_32_920.npy', 'EEGMouse_Nathan_1_29_863.npy', 'EEGMouse_Nathan_3_34_960.npy', 'EEGMouse_Nathan_1_22_729.npy', 'EEGMouse_Nathan_1_13_568.npy', 'EEGMouse_Nathan_1_20_638.npy', 'EEGMouse_Nathan_1_13_566.npy', 'EEGMouse_Nathan_1_9_475.npy', 'EEGMouse_Nathan_3_49_1220.npy', 'EEGMouse_Nathan_1_55_1348.npy', 'EEGMouse_Nathan_3_3_361.npy', 'EEGMouse_Nathan_1_44_1123.npy', 'EEGMouse_Nathan_3_47_1184.npy', 'EEGMouse_Nathan_3_21_702.npy', 'EEGMouse_Nathan_1_7_457.npy', 'EEGMouse_Nathan_1_9_485.npy', 'EEGMouse_Nathan_1_25_777.npy', 'EEGMouse_Nathan_1_18_663.npy', 'EEGMouse_Nathan_3_35_990.npy', 'EEGMouse_Nathan_3_5_384.npy', 'EEGMouse_Nathan_3_31_894.npy', 'EEGMouse_Nathan_3_12_537.npy', 'EEGMouse_Nathan_1_24_763.npy', 'EEGMouse_Nathan_1_47_1170.npy', 'EEGMouse_Nathan_3_23_736.npy', 'EEGMouse_Nathan_1_46_1162.npy', 'EEGMouse_Nathan_1_32_931.npy', 'EEGMouse_Nathan_3_16_615.npy', 'EEGMouse_Nathan_1_38_1043.npy', 'EEGMouse_Nathan_1_37_1015.npy', 'EEGMouse_Nathan_1_9_468.npy', 'EEGMouse_Nathan_3_51_1265.npy', 'EEGMouse_Nathan_3_52_1295.npy', 'EEGMouse_Nathan_1_31_893.npy', 'EEGMouse_Nathan_3_11_521.npy', 'EEGMouse_Nathan_3_47_1182.npy', 'EEGMouse_Nathan_1_55_1350.npy', 'EEGMouse_Nathan_3_43_1122.npy', 'EEGMouse_Nathan_1_10_502.npy', 'EEGMouse_Nathan_1_4_376.npy', 'EEGMouse_Nathan_3_46_1157.npy', 'EEGMouse_Nathan_3_34_954.npy', 'EEGMouse_Nathan_3_42_1098.npy', 'EEGMouse_Nathan_1_46_1166.npy', 'EEGMouse_Nathan_3_20_440.npy', 'EEGMouse_Nathan_1_6_413.npy', 'EEGMouse_Nathan_3_23_750.npy', 'EEGMouse_Nathan_3_57_1387.npy', 'EEGMouse_Nathan_3_10_509.npy', 'EEGMouse_Nathan_3_14_575.npy', 'EEGMouse_Nathan_1_27_831.npy', 'EEGMouse_Nathan_1_20_644.npy', 'EEGMouse_Nathan_3_22_722.npy', 'EEGMouse_Nathan_3_53_1309.npy', 'EEGMouse_Nathan_1_29_871.npy', 'EEGMouse_Nathan_1_53_1314.npy', 'EEGMouse_Nathan_1_55_1358.npy', 'EEGMouse_Nathan_1_7_452.npy', 'EEGMouse_Nathan_1_12_546.npy', 'EEGMouse_Nathan_1_34_969.npy', 'EEGMouse_Nathan_3_13_557.npy', 'EEGMouse_Nathan_1_44_1141.npy', 'EEGMouse_Nathan_3_35_986.npy', 'EEGMouse_Nathan_1_32_921.npy', 'EEGMouse_Nathan_3_31_900.npy', 'EEGMouse_Nathan_1_7_447.npy', 'EEGMouse_Nathan_1_51_1270.npy', 'EEGMouse_Nathan_1_18_659.npy', 'EEGMouse_Nathan_1_46_1154.npy', 'EEGMouse_Nathan_1_6_411.npy', 'EEGMouse_Nathan_3_57_1391.npy', 'EEGMouse_Nathan_1_12_544.npy', 'EEGMouse_Nathan_1_21_703.npy', 'EEGMouse_Nathan_1_15_592.npy', 'EEGMouse_Nathan_3_55_1353.npy', 'EEGMouse_Nathan_1_27_821.npy', 'EEGMouse_Nathan_1_3_350.npy', 'EEGMouse_Nathan_1_3_357.npy', 'EEGMouse_Nathan_3_21_712.npy', 'EEGMouse_Nathan_1_14_582.npy', 'EEGMouse_Nathan_1_10_496.npy', 'EEGMouse_Nathan_1_49_1219.npy', 'EEGMouse_Nathan_3_48_1200.npy', 'EEGMouse_Nathan_3_22_726.npy', 'EEGMouse_Nathan_1_28_847.npy', 'EEGMouse_Nathan_1_13_550.npy', 'EEGMouse_Nathan_3_50_1241.npy', 'EEGMouse_Nathan_3_12_545.npy', 'EEGMouse_Nathan_3_49_1214.npy', 'EEGMouse_Nathan_3_40_1073.npy', 'EEGMouse_Nathan_1_39_1059.npy', 'EEGMouse_Nathan_1_15_608.npy', 'EEGMouse_Nathan_1_9_483.npy', 'EEGMouse_Nathan_1_48_1205.npy', 'EEGMouse_Nathan_1_50_1252.npy', 'EEGMouse_Nathan_1_20_442.npy', 'EEGMouse_Nathan_3_46_1151.npy', 'EEGMouse_Nathan_1_2_343.npy', 'EEGMouse_Nathan_3_13_555.npy', 'EEGMouse_Nathan_3_10_493.npy', 'EEGMouse_Nathan_3_52_1299.npy', 'EEGMouse_Nathan_1_50_1254.npy', 'EEGMouse_Nathan_1_40_1072.npy', 'EEGMouse_Nathan_1_20_426.npy', 'EEGMouse_Nathan_1_53_1310.npy', 'EEGMouse_Nathan_1_6_421.npy', 'EEGMouse_Nathan_1_47_1189.npy', 'EEGMouse_Nathan_3_28_834.npy', 'EEGMouse_Nathan_1_49_1215.npy', 'EEGMouse_Nathan_3_54_1327.npy', 'EEGMouse_Nathan_1_23_739.npy', 'EEGMouse_Nathan_3_53_1315.npy', 'EEGMouse_Nathan_3_18_662.npy', 'EEGMouse_Nathan_3_50_1249.npy', 'EEGMouse_Nathan_1_49_1213.npy', 'EEGMouse_Nathan_3_14_585.npy', 'EEGMouse_Nathan_1_26_801.npy', 'EEGMouse_Nathan_3_22_718.npy', 'EEGMouse_Nathan_1_18_669.npy', 'EEGMouse_Nathan_1_49_1223.npy', 'EEGMouse_Nathan_3_26_810.npy', 'EEGMouse_Nathan_3_6_415.npy', 'EEGMouse_Nathan_1_27_815.npy', 'EEGMouse_Nathan_1_16_610.npy', 'EEGMouse_Nathan_3_42_1086.npy', 'EEGMouse_Nathan_1_52_1292.npy', 'EEGMouse_Nathan_1_32_923.npy', 'EEGMouse_Nathan_3_27_816.npy', 'EEGMouse_Nathan_3_26_804.npy', 'EEGMouse_Nathan_3_54_1335.npy', 'EEGMouse_Nathan_3_55_1345.npy', 'EEGMouse_Nathan_3_4_367.npy', 'EEGMouse_Nathan_1_30_887.npy', 'EEGMouse_Nathan_1_15_602.npy', 'EEGMouse_Nathan_1_48_1199.npy', 'EEGMouse_Nathan_1_18_657.npy', 'EEGMouse_Nathan_1_52_1282.npy', 'EEGMouse_Nathan_3_20_629.npy', 'EEGMouse_Nathan_1_4_379.npy', 'EEGMouse_Nathan_1_20_435.npy', 'EEGMouse_Nathan_1_25_773.npy', 'EEGMouse_Nathan_3_44_1124.npy', 'EEGMouse_Nathan_1_15_600.npy', 'EEGMouse_Nathan_3_18_666.npy', 'EEGMouse_Nathan_1_15_596.npy', 'EEGMouse_Nathan_3_37_1014.npy', 'EEGMouse_Nathan_1_25_775.npy', 'EEGMouse_Nathan_3_23_734.npy', 'EEGMouse_Nathan_1_21_697.npy', 'EEGMouse_Nathan_1_30_875.npy', 'EEGMouse_Nathan_3_33_934.npy', 'EEGMouse_Nathan_3_37_1030.npy', 'EEGMouse_Nathan_3_20_647.npy', 'EEGMouse_Nathan_1_24_769.npy', 'EEGMouse_Nathan_1_19_675.npy', 'EEGMouse_Nathan_3_7_459.npy', 'EEGMouse_Nathan_1_15_606.npy', 'EEGMouse_Nathan_3_30_878.npy', 'EEGMouse_Nathan_1_47_1179.npy', 'EEGMouse_Nathan_3_44_1132.npy', 'EEGMouse_Nathan_1_47_1187.npy', 'EEGMouse_Nathan_3_36_1004.npy', 'EEGMouse_Nathan_3_48_1194.npy', 'EEGMouse_Nathan_3_12_539.npy', 'EEGMouse_Nathan_1_24_767.npy', 'EEGMouse_Nathan_1_11_520.npy', 'EEGMouse_Nathan_3_10_497.npy', 'EEGMouse_Nathan_1_44_1129.npy', 'EEGMouse_Nathan_3_1_331.npy', 'EEGMouse_Nathan_3_38_1050.npy', 'EEGMouse_Nathan_1_26_811.npy', 'EEGMouse_Nathan_3_51_1269.npy', 'EEGMouse_Nathan_3_34_968.npy', 'EEGMouse_Nathan_3_2_328.npy', 'EEGMouse_Nathan_3_18_656.npy', 'EEGMouse_Nathan_1_57_1396.npy', 'EEGMouse_Nathan_3_1_330.npy', 'EEGMouse_Nathan_1_17_648.npy', 'EEGMouse_Nathan_3_16_617.npy', 'EEGMouse_Nathan_1_24_761.npy', 'EEGMouse_Nathan_1_1_339.npy', 'EEGMouse_Nathan_3_37_1022.npy', 'EEGMouse_Nathan_1_11_528.npy', 'EEGMouse_Nathan_1_51_1272.npy', 'EEGMouse_Nathan_1_49_1230.npy', 'EEGMouse_Nathan_3_14_583.npy', 'EEGMouse_Nathan_1_7_460.npy', 'EEGMouse_Nathan_3_4_378.npy', 'EEGMouse_Nathan_1_36_993.npy', 'EEGMouse_Nathan_3_15_597.npy', 'EEGMouse_Nathan_3_38_1040.npy', 'EEGMouse_Nathan_1_31_907.npy', 'EEGMouse_Nathan_1_20_632.npy', 'EEGMouse_Nathan_1_24_753.npy', 'EEGMouse_Nathan_3_29_868.npy', 'EEGMouse_Nathan_1_35_985.npy', 'EEGMouse_Nathan_1_19_681.npy', 'EEGMouse_Nathan_1_11_510.npy', 'EEGMouse_Nathan_3_15_601.npy', 'EEGMouse_Nathan_3_33_950.npy', 'EEGMouse_Nathan_3_25_790.npy', 'EEGMouse_Nathan_1_23_747.npy', 'EEGMouse_Nathan_3_12_547.npy', 'EEGMouse_Nathan_3_33_940.npy', 'EEGMouse_Nathan_3_9_476.npy', 'EEGMouse_Nathan_1_36_1009.npy', 'EEGMouse_Nathan_3_34_970.npy', 'EEGMouse_Nathan_3_44_1134.npy', 'EEGMouse_Nathan_1_16_622.npy', 'EEGMouse_Nathan_3_27_818.npy', 'EEGMouse_Nathan_3_25_786.npy', 'EEGMouse_Nathan_3_12_533.npy', 'EEGMouse_Nathan_1_27_827.npy', 'EEGMouse_Nathan_3_34_956.npy', 'EEGMouse_Nathan_3_2_341.npy', 'EEGMouse_Nathan_1_47_1175.npy', 'EEGMouse_Nathan_1_54_1324.npy', 'EEGMouse_Nathan_1_24_771.npy', 'EEGMouse_Nathan_3_34_964.npy', 'EEGMouse_Nathan_3_53_1311.npy', 'EEGMouse_Nathan_3_48_1206.npy', 'EEGMouse_Nathan_3_5_399.npy', 'EEGMouse_Nathan_3_25_778.npy', 'EEGMouse_Nathan_3_20_431.npy', 'EEGMouse_Nathan_3_29_858.npy', 'EEGMouse_Nathan_3_7_446.npy', 'EEGMouse_Nathan_3_49_1222.npy', 'EEGMouse_Nathan_3_51_1271.npy', 'EEGMouse_Nathan_1_39_1053.npy', 'EEGMouse_Nathan_1_31_897.npy', 'EEGMouse_Nathan_1_51_1262.npy', 'EEGMouse_Nathan_1_50_1240.npy', 'EEGMouse_Nathan_1_47_1168.npy', 'EEGMouse_Nathan_3_18_658.npy', 'EEGMouse_Nathan_3_40_1081.npy', 'EEGMouse_Nathan_3_22_716.npy', 'EEGMouse_Nathan_3_53_1319.npy', 'EEGMouse_Nathan_3_52_1293.npy', 'EEGMouse_Nathan_3_43_1106.npy', 'EEGMouse_Nathan_1_7_450.npy', 'EEGMouse_Nathan_3_21_704.npy', 'EEGMouse_Nathan_3_10_501.npy', 'EEGMouse_Nathan_1_39_1055.npy', 'EEGMouse_Nathan_1_20_634.npy', 'EEGMouse_Nathan_3_20_633.npy', 'EEGMouse_Nathan_1_52_1280.npy', 'EEGMouse_Nathan_1_46_1156.npy', 'EEGMouse_Nathan_1_37_1013.npy', 'EEGMouse_Nathan_3_29_862.npy', 'EEGMouse_Nathan_1_20_432.npy', 'EEGMouse_Nathan_1_4_366.npy', 'EEGMouse_Nathan_1_11_518.npy', 'EEGMouse_Nathan_3_5_398.npy', 'EEGMouse_Nathan_1_51_1264.npy', 'EEGMouse_Nathan_1_14_584.npy', 'EEGMouse_Nathan_3_30_884.npy', 'EEGMouse_Nathan_3_8_466.npy', 'EEGMouse_Nathan_1_32_913.npy', 'EEGMouse_Nathan_3_20_441.npy', 'EEGMouse_Nathan_3_8_467.npy', 'EEGMouse_Nathan_1_18_667.npy', 'EEGMouse_Nathan_3_19_686.npy', 'EEGMouse_Nathan_1_33_951.npy', 'EEGMouse_Nathan_3_38_1044.npy', 'EEGMouse_Nathan_1_43_1121.npy', 'EEGMouse_Nathan_1_44_1137.npy', 'EEGMouse_Nathan_3_44_1142.npy', 'EEGMouse_Nathan_1_2_342.npy', 'EEGMouse_Nathan_1_35_987.npy', 'EEGMouse_Nathan_1_10_494.npy', 'EEGMouse_Nathan_3_31_898.npy', 'EEGMouse_Nathan_3_55_1349.npy', 'EEGMouse_Nathan_1_2_331.npy', 'EEGMouse_Nathan_3_40_1071.npy', 'EEGMouse_Nathan_3_18_654.npy', 'EEGMouse_Nathan_3_36_1006.npy', 'EEGMouse_Nathan_3_28_840.npy', 'EEGMouse_Nathan_3_22_724.npy', 'EEGMouse_Nathan_3_16_619.npy', 'EEGMouse_Nathan_1_21_701.npy', 'EEGMouse_Nathan_1_10_506.npy', 'EEGMouse_Nathan_3_32_930.npy', 'EEGMouse_Nathan_1_53_1302.npy', 'EEGMouse_Nathan_1_34_971.npy', 'EEGMouse_Nathan_3_24_766.npy', 'EEGMouse_Nathan_1_52_1286.npy', 'EEGMouse_Nathan_1_29_857.npy', 'EEGMouse_Nathan_1_9_486.npy', 'EEGMouse_Nathan_3_53_1303.npy', 'EEGMouse_Nathan_3_38_1048.npy', 'EEGMouse_Nathan_3_56_1361.npy', 'EEGMouse_Nathan_3_7_455.npy', 'EEGMouse_Nathan_1_48_1207.npy', 'EEGMouse_Nathan_3_46_1159.npy', 'EEGMouse_Nathan_1_26_797.npy', 'EEGMouse_Nathan_1_12_548.npy', 'EEGMouse_Nathan_1_55_1354.npy', 'EEGMouse_Nathan_1_38_1049.npy', 'EEGMouse_Nathan_3_16_627.npy', 'EEGMouse_Nathan_1_11_516.npy', 'EEGMouse_Nathan_1_4_383.npy', 'EEGMouse_Nathan_3_24_762.npy', 'EEGMouse_Nathan_1_14_570.npy', 'EEGMouse_Nathan_3_57_1381.npy', 'EEGMouse_Nathan_1_18_653.npy', 'EEGMouse_Nathan_1_19_687.npy', 'EEGMouse_Nathan_1_46_1152.npy', 'EEGMouse_Nathan_3_19_678.npy', 'EEGMouse_Nathan_1_34_967.npy', 'EEGMouse_Nathan_3_37_1018.npy', 'EEGMouse_Nathan_3_40_1067.npy', 'EEGMouse_Nathan_1_33_935.npy', 'EEGMouse_Nathan_3_4_382.npy', 'EEGMouse_Nathan_3_28_846.npy', 'EEGMouse_Nathan_3_23_748.npy', 'EEGMouse_Nathan_3_16_611.npy', 'EEGMouse_Nathan_3_15_595.npy', 'EEGMouse_Nathan_1_28_851.npy', 'EEGMouse_Nathan_1_7_464.npy', 'EEGMouse_Nathan_3_54_1333.npy', 'EEGMouse_Nathan_3_12_549.npy', 'EEGMouse_Nathan_1_4_372.npy', 'EEGMouse_Nathan_1_37_1027.npy', 'EEGMouse_Nathan_3_22_732.npy', 'EEGMouse_Nathan_3_44_1128.npy', 'EEGMouse_Nathan_1_52_1296.npy', 'EEGMouse_Nathan_1_34_955.npy', 'EEGMouse_Nathan_3_26_798.npy', 'EEGMouse_Nathan_3_1_328.npy', 'EEGMouse_Nathan_3_14_571.npy', 'EEGMouse_Nathan_1_32_915.npy', 'EEGMouse_Nathan_1_46_1160.npy', 'EEGMouse_Nathan_1_36_1011.npy', 'EEGMouse_Nathan_1_29_855.npy', 'EEGMouse_Nathan_3_55_1351.npy', 'EEGMouse_Nathan_1_18_655.npy', 'EEGMouse_Nathan_1_1_340.npy', 'EEGMouse_Nathan_1_9_484.npy', 'EEGMouse_Nathan_3_34_958.npy', 'EEGMouse_Nathan_3_54_1331.npy', 'EEGMouse_Nathan_1_14_578.npy', 'EEGMouse_Nathan_3_56_1363.npy', 'EEGMouse_Nathan_3_30_880.npy', 'EEGMouse_Nathan_1_29_853.npy', 'EEGMouse_Nathan_1_38_1039.npy', 'EEGMouse_Nathan_1_38_1035.npy', 'EEGMouse_Nathan_3_30_876.npy', 'EEGMouse_Nathan_3_42_1088.npy', 'EEGMouse_Nathan_3_48_1212.npy', 'EEGMouse_Nathan_1_7_458.npy', 'EEGMouse_Nathan_1_7_453.npy', 'EEGMouse_Nathan_3_47_1176.npy', 'EEGMouse_Nathan_1_23_733.npy', 'EEGMouse_Nathan_3_13_551.npy', 'EEGMouse_Nathan_1_12_530.npy', 'EEGMouse_Nathan_1_14_586.npy', 'EEGMouse_Nathan_3_44_1136.npy', 'EEGMouse_Nathan_3_21_694.npy', 'EEGMouse_Nathan_1_43_1111.npy', 'EEGMouse_Nathan_3_35_992.npy', 'EEGMouse_Nathan_3_34_972.npy', 'EEGMouse_Nathan_3_53_1307.npy', 'EEGMouse_Nathan_3_6_404.npy', 'EEGMouse_Nathan_3_13_567.npy', 'EEGMouse_Nathan_3_3_355.npy', 'EEGMouse_Nathan_1_56_1378.npy', 'EEGMouse_Nathan_3_24_770.npy', 'EEGMouse_Nathan_1_14_580.npy', 'EEGMouse_Nathan_3_7_449.npy', 'EEGMouse_Nathan_1_36_995.npy', 'EEGMouse_Nathan_3_3_349.npy', 'EEGMouse_Nathan_3_51_1259.npy', 'EEGMouse_Nathan_1_10_490.npy', 'EEGMouse_Nathan_1_37_1031.npy', 'EEGMouse_Nathan_3_36_998.npy', 'EEGMouse_Nathan_1_57_1392.npy', 'EEGMouse_Nathan_3_6_409.npy', 'EEGMouse_Nathan_1_49_1221.npy', 'EEGMouse_Nathan_3_54_1339.npy', 'EEGMouse_Nathan_3_31_906.npy', 'EEGMouse_Nathan_1_12_534.npy', 'EEGMouse_Nathan_1_44_1127.npy', 'EEGMouse_Nathan_3_25_774.npy', 'EEGMouse_Nathan_1_5_392.npy', 'EEGMouse_Nathan_3_21_696.npy', 'EEGMouse_Nathan_1_39_1057.npy', 'EEGMouse_Nathan_3_36_1010.npy', 'EEGMouse_Nathan_1_23_751.npy', 'EEGMouse_Nathan_1_45_1145.npy', 'EEGMouse_Nathan_3_25_784.npy', 'EEGMouse_Nathan_1_51_1278.npy', 'EEGMouse_Nathan_1_10_508.npy', 'EEGMouse_Nathan_3_33_948.npy', 'EEGMouse_Nathan_3_25_776.npy', 'EEGMouse_Nathan_3_47_1190.npy', 'EEGMouse_Nathan_1_42_1095.npy', 'EEGMouse_Nathan_1_43_1107.npy', 'EEGMouse_Nathan_3_5_396.npy', 'EEGMouse_Nathan_1_32_927.npy', 'EEGMouse_Nathan_1_34_961.npy', 'EEGMouse_Nathan_1_36_1005.npy', 'EEGMouse_Nathan_1_4_381.npy', 'EEGMouse_Nathan_1_48_1201.npy', 'EEGMouse_Nathan_3_10_505.npy', 'EEGMouse_Nathan_3_6_420.npy', 'EEGMouse_Nathan_1_7_465.npy', 'EEGMouse_Nathan_1_12_542.npy', 'EEGMouse_Nathan_1_43_1113.npy', 'EEGMouse_Nathan_3_29_872.npy', 'EEGMouse_Nathan_1_49_1232.npy', 'EEGMouse_Nathan_1_6_412.npy', 'EEGMouse_Nathan_1_20_636.npy', 'EEGMouse_Nathan_3_52_1283.npy', 'EEGMouse_Nathan_3_21_710.npy', 'EEGMouse_Nathan_3_51_1257.npy', 'EEGMouse_Nathan_3_20_438.npy', 'EEGMouse_Nathan_1_47_1177.npy', 'EEGMouse_Nathan_1_56_1376.npy', 'EEGMouse_Nathan_1_42_1083.npy', 'EEGMouse_Nathan_3_12_541.npy', 'EEGMouse_Nathan_3_55_1341.npy', 'EEGMouse_Nathan_1_31_905.npy', 'EEGMouse_Nathan_3_20_641.npy', 'EEGMouse_Nathan_3_44_1140.npy', 'EEGMouse_Nathan_3_46_1163.npy', 'EEGMouse_Nathan_3_52_1289.npy', 'EEGMouse_Nathan_3_57_1389.npy', 'EEGMouse_Nathan_3_54_1337.npy', 'EEGMouse_Nathan_1_40_1062.npy', 'EEGMouse_Nathan_3_14_589.npy', 'EEGMouse_Nathan_1_51_1268.npy', 'EEGMouse_Nathan_1_6_419.npy', 'EEGMouse_Nathan_3_27_832.npy', 'EEGMouse_Nathan_1_37_1029.npy', 'EEGMouse_Nathan_3_37_1026.npy', 'EEGMouse_Nathan_3_2_329.npy', 'EEGMouse_Nathan_1_27_819.npy', 'EEGMouse_Nathan_3_2_338.npy', 'EEGMouse_Nathan_3_13_563.npy', 'EEGMouse_Nathan_3_38_1042.npy', 'EEGMouse_Nathan_1_1_342.npy', 'EEGMouse_Nathan_1_15_598.npy', 'EEGMouse_Nathan_3_32_926.npy', 'EEGMouse_Nathan_1_35_983.npy', 'EEGMouse_Nathan_3_34_966.npy', 'EEGMouse_Nathan_1_3_346.npy', 'EEGMouse_Nathan_3_7_462.npy', 'EEGMouse_Nathan_3_43_1116.npy', 'EEGMouse_Nathan_1_56_1366.npy', 'EEGMouse_Nathan_3_47_1169.npy', 'EEGMouse_Nathan_1_42_1091.npy', 'EEGMouse_Nathan_1_2_330.npy', 'EEGMouse_Nathan_1_37_1019.npy', 'EEGMouse_Nathan_3_7_454.npy', 'EEGMouse_Nathan_3_55_1347.npy', 'EEGMouse_Nathan_3_48_1196.npy', 'EEGMouse_Nathan_3_42_1094.npy', 'EEGMouse_Nathan_1_25_787.npy', 'EEGMouse_Nathan_1_40_1080.npy', 'EEGMouse_Nathan_1_49_1225.npy', 'EEGMouse_Nathan_3_26_808.npy', 'EEGMouse_Nathan_3_4_377.npy', 'EEGMouse_Nathan_1_51_1276.npy', 'EEGMouse_Nathan_1_46_1164.npy', 'EEGMouse_Nathan_3_31_902.npy', 'EEGMouse_Nathan_3_29_860.npy', 'EEGMouse_Nathan_3_17_649.npy', 'EEGMouse_Nathan_1_14_576.npy', 'EEGMouse_Nathan_3_50_1243.npy', 'EEGMouse_Nathan_3_49_1218.npy', 'EEGMouse_Nathan_1_20_434.npy', 'EEGMouse_Nathan_1_13_564.npy', 'EEGMouse_Nathan_1_47_1173.npy', 'EEGMouse_Nathan_3_37_1016.npy', 'EEGMouse_Nathan_3_33_952.npy', 'EEGMouse_Nathan_1_52_1284.npy', 'EEGMouse_Nathan_3_38_1036.npy', 'EEGMouse_Nathan_1_57_1388.npy', 'EEGMouse_Nathan_3_35_988.npy', 'EEGMouse_Nathan_3_28_852.npy', 'EEGMouse_Nathan_3_1_333.npy', 'EEGMouse_Nathan_1_56_1368.npy', 'EEGMouse_Nathan_3_33_944.npy', 'EEGMouse_Nathan_3_29_856.npy', 'EEGMouse_Nathan_1_17_652.npy', 'EEGMouse_Nathan_3_49_1229.npy', 'EEGMouse_Nathan_3_37_1024.npy', 'EEGMouse_Nathan_3_15_591.npy', 'EEGMouse_Nathan_3_16_623.npy', 'EEGMouse_Nathan_3_39_1054.npy', 'EEGMouse_Nathan_3_18_672.npy', 'EEGMouse_Nathan_1_25_779.npy', 'EEGMouse_Nathan_1_13_552.npy', 'EEGMouse_Nathan_1_23_743.npy', 'EEGMouse_Nathan_1_2_325.npy', 'EEGMouse_Nathan_1_12_540.npy', 'EEGMouse_Nathan_1_34_965.npy', 'EEGMouse_Nathan_1_21_709.npy', 'EEGMouse_Nathan_1_9_482.npy', 'EEGMouse_Nathan_3_28_836.npy', 'EEGMouse_Nathan_1_42_1089.npy', 'EEGMouse_Nathan_1_27_829.npy', 'EEGMouse_Nathan_1_4_375.npy', 'EEGMouse_Nathan_3_36_1012.npy', 'EEGMouse_Nathan_3_20_433.npy', 'EEGMouse_Nathan_1_15_604.npy', 'EEGMouse_Nathan_3_26_794.npy', 'EEGMouse_Nathan_1_22_721.npy', 'EEGMouse_Nathan_1_11_514.npy', 'EEGMouse_Nathan_3_20_439.npy', 'EEGMouse_Nathan_3_43_1104.npy', 'EEGMouse_Nathan_3_39_1058.npy', 'EEGMouse_Nathan_3_5_394.npy', 'EEGMouse_Nathan_1_31_901.npy', 'EEGMouse_Nathan_3_46_1161.npy', 'EEGMouse_Nathan_1_1_337.npy', 'EEGMouse_Nathan_3_14_587.npy', 'EEGMouse_Nathan_3_48_1210.npy', 'EEGMouse_Nathan_3_4_371.npy', 'EEGMouse_Nathan_1_9_470.npy', 'EEGMouse_Nathan_1_32_917.npy', 'EEGMouse_Nathan_3_11_517.npy', 'EEGMouse_Nathan_1_12_532.npy', 'EEGMouse_Nathan_3_57_1397.npy', 'EEGMouse_Nathan_3_52_1285.npy', 'EEGMouse_Nathan_3_20_427.npy', 'EEGMouse_Nathan_3_30_874.npy', 'EEGMouse_Nathan_1_20_436.npy', 'EEGMouse_Nathan_3_51_1261.npy', 'EEGMouse_Nathan_1_24_759.npy', 'EEGMouse_Nathan_3_54_1325.npy', 'EEGMouse_Nathan_3_22_720.npy', 'EEGMouse_Nathan_1_49_1226.npy', 'EEGMouse_Nathan_1_33_939.npy', 'EEGMouse_Nathan_3_36_1000.npy', 'EEGMouse_Nathan_1_56_1360.npy', 'EEGMouse_Nathan_1_36_1003.npy', 'EEGMouse_Nathan_3_3_359.npy', 'EEGMouse_Nathan_3_29_864.npy', 'EEGMouse_Nathan_1_6_407.npy', 'EEGMouse_Nathan_1_50_1238.npy', 'EEGMouse_Nathan_3_5_386.npy', 'EEGMouse_Nathan_1_50_1242.npy', 'EEGMouse_Nathan_3_50_1245.npy', 'EEGMouse_Nathan_3_57_1383.npy', 'EEGMouse_Nathan_1_36_999.npy', 'EEGMouse_Nathan_3_47_1180.npy', 'EEGMouse_Nathan_3_42_1090.npy', 'EEGMouse_Nathan_1_51_1256.npy', 'EEGMouse_Nathan_1_42_1101.npy', 'EEGMouse_Nathan_1_17_650.npy', 'EEGMouse_Nathan_3_14_573.npy', 'EEGMouse_Nathan_3_2_333.npy', 'EEGMouse_Nathan_3_47_1192.npy', 'EEGMouse_Nathan_3_20_443.npy', 'EEGMouse_Nathan_1_4_380.npy', 'EEGMouse_Nathan_3_33_946.npy', 'EEGMouse_Nathan_3_15_609.npy', 'EEGMouse_Nathan_3_1_335.npy', 'EEGMouse_Nathan_3_40_1077.npy', 'EEGMouse_Nathan_1_1_336.npy', 'EEGMouse_Nathan_3_23_744.npy', 'EEGMouse_Nathan_3_51_1263.npy', 'EEGMouse_Nathan_3_55_1343.npy', 'EEGMouse_Nathan_3_50_1239.npy', 'EEGMouse_Nathan_3_32_914.npy', 'EEGMouse_Nathan_3_24_758.npy', 'EEGMouse_Nathan_3_52_1281.npy', 'EEGMouse_Nathan_3_1_326.npy', 'EEGMouse_Nathan_1_18_665.npy', 'EEGMouse_Nathan_1_50_1244.npy', 'EEGMouse_Nathan_1_25_785.npy', 'EEGMouse_Nathan_3_56_1365.npy', 'EEGMouse_Nathan_1_53_1300.npy', 'EEGMouse_Nathan_3_16_613.npy', 'EEGMouse_Nathan_3_23_738.npy', 'EEGMouse_Nathan_1_5_390.npy', 'EEGMouse_Nathan_1_52_1298.npy', 'EEGMouse_Nathan_1_57_1384.npy', 'EEGMouse_Nathan_3_3_348.npy', 'EEGMouse_Nathan_3_6_408.npy', 'EEGMouse_Nathan_1_37_1025.npy', 'EEGMouse_Nathan_3_25_792.npy', 'EEGMouse_Nathan_3_5_397.npy', 'EEGMouse_Nathan_1_10_500.npy', 'EEGMouse_Nathan_3_27_830.npy', 'EEGMouse_Nathan_3_30_892.npy', 'EEGMouse_Nathan_1_21_695.npy', 'EEGMouse_Nathan_1_37_1023.npy', 'EEGMouse_Nathan_1_39_1061.npy', 'EEGMouse_Nathan_3_18_660.npy', 'EEGMouse_Nathan_1_16_618.npy', 'EEGMouse_Nathan_1_49_1217.npy', 'EEGMouse_Nathan_1_27_813.npy', 'EEGMouse_Nathan_1_22_715.npy', 'EEGMouse_Nathan_1_10_498.npy', 'EEGMouse_Nathan_3_27_814.npy', 'EEGMouse_Nathan_1_43_1103.npy', 'EEGMouse_Nathan_1_28_843.npy', 'EEGMouse_Nathan_1_33_933.npy', 'EEGMouse_Nathan_3_23_746.npy', 'EEGMouse_Nathan_3_39_1056.npy', 'EEGMouse_Nathan_3_6_422.npy', 'EEGMouse_Nathan_3_32_928.npy', 'EEGMouse_Nathan_1_5_403.npy', 'EEGMouse_Nathan_3_13_559.npy', 'EEGMouse_Nathan_1_24_755.npy', 'EEGMouse_Nathan_1_20_630.npy', 'EEGMouse_Nathan_3_49_1216.npy', 'EEGMouse_Nathan_1_21_705.npy', 'EEGMouse_Nathan_3_37_1020.npy', 'EEGMouse_Nathan_3_9_471.npy', 'EEGMouse_Nathan_1_23_737.npy', 'EEGMouse_Nathan_3_50_1253.npy', 'EEGMouse_Nathan_3_30_886.npy', 'EEGMouse_Nathan_3_10_499.npy', 'EEGMouse_Nathan_1_33_937.npy', 'EEGMouse_Nathan_1_50_1250.npy', 'EEGMouse_Nathan_3_15_599.npy', 'EEGMouse_Nathan_3_11_511.npy', 'EEGMouse_Nathan_1_47_1185.npy', 'EEGMouse_Nathan_3_5_388.npy', 'EEGMouse_Nathan_1_5_393.npy', 'EEGMouse_Nathan_3_36_996.npy', 'EEGMouse_Nathan_1_19_691.npy', 'EEGMouse_Nathan_1_13_554.npy', 'EEGMouse_Nathan_3_9_478.npy', 'EEGMouse_Nathan_3_29_854.npy', 'EEGMouse_Nathan_3_6_418.npy', 'EEGMouse_Nathan_1_2_332.npy', 'EEGMouse_Nathan_1_13_562.npy', 'EEGMouse_Nathan_1_45_1143.npy', 'EEGMouse_Nathan_1_54_1334.npy', 'EEGMouse_Nathan_3_14_577.npy', 'EEGMouse_Nathan_3_27_820.npy', 'EEGMouse_Nathan_1_28_835.npy', 'EEGMouse_Nathan_1_52_1294.npy', 'EEGMouse_Nathan_3_25_780.npy', 'EEGMouse_Nathan_3_56_1369.npy', 'EEGMouse_Nathan_3_24_768.npy', 'EEGMouse_Nathan_1_40_1068.npy', 'EEGMouse_Nathan_3_42_1084.npy', 'EEGMouse_Nathan_3_57_1393.npy', 'EEGMouse_Nathan_1_18_671.npy', 'EEGMouse_Nathan_1_37_1021.npy', 'EEGMouse_Nathan_3_56_1373.npy', 'EEGMouse_Nathan_3_20_639.npy', 'EEGMouse_Nathan_3_32_916.npy', 'EEGMouse_Nathan_1_31_899.npy', 'EEGMouse_Nathan_3_31_896.npy', 'EEGMouse_Nathan_3_21_708.npy', 'EEGMouse_Nathan_1_30_881.npy', 'EEGMouse_Nathan_3_44_1126.npy', 'EEGMouse_Nathan_1_43_1105.npy', 'EEGMouse_Nathan_1_22_719.npy', 'EEGMouse_Nathan_1_22_725.npy', 'EEGMouse_Nathan_3_54_1321.npy', 'EEGMouse_Nathan_1_16_616.npy', 'EEGMouse_Nathan_1_13_558.npy', 'EEGMouse_Nathan_1_31_895.npy', 'EEGMouse_Nathan_1_40_1076.npy', 'EEGMouse_Nathan_1_19_677.npy', 'EEGMouse_Nathan_1_5_389.npy', 'EEGMouse_Nathan_1_31_909.npy', 'EEGMouse_Nathan_3_20_430.npy', 'EEGMouse_Nathan_1_30_879.npy', 'EEGMouse_Nathan_3_13_561.npy', 'EEGMouse_Nathan_1_26_807.npy', 'EEGMouse_Nathan_1_42_1087.npy', 'EEGMouse_Nathan_1_3_354.npy', 'EEGMouse_Nathan_1_33_949.npy', 'EEGMouse_Nathan_1_12_538.npy', 'EEGMouse_Nathan_1_20_642.npy', 'EEGMouse_Nathan_1_44_1135.npy', 'EEGMouse_Nathan_3_3_353.npy', 'EEGMouse_Nathan_3_2_335.npy', 'EEGMouse_Nathan_3_57_1385.npy', 'EEGMouse_Nathan_1_51_1260.npy', 'EEGMouse_Nathan_3_57_1399.npy', 'EEGMouse_Nathan_1_19_685.npy', 'EEGMouse_Nathan_1_38_1045.npy', 'EEGMouse_Nathan_1_53_1304.npy', 'EEGMouse_Nathan_3_45_1146.npy', 'EEGMouse_Nathan_3_5_402.npy', 'EEGMouse_Nathan_1_34_957.npy', 'EEGMouse_Nathan_1_4_368.npy', 'EEGMouse_Nathan_3_2_336.npy', 'EEGMouse_Nathan_3_50_1247.npy', 'EEGMouse_Nathan_1_22_713.npy', 'EEGMouse_Nathan_1_48_1197.npy', 'EEGMouse_Nathan_1_53_1312.npy', 'EEGMouse_Nathan_1_22_723.npy', 'EEGMouse_Nathan_3_37_1032.npy', 'EEGMouse_Nathan_1_36_1001.npy', 'EEGMouse_Nathan_3_2_326.npy', 'EEGMouse_Nathan_3_4_364.npy', 'EEGMouse_Nathan_3_50_1237.npy', 'EEGMouse_Nathan_3_11_529.npy', 'EEGMouse_Nathan_1_2_340.npy', 'EEGMouse_Nathan_3_43_1118.npy', 'EEGMouse_Nathan_3_6_405.npy', 'EEGMouse_Nathan_1_38_1037.npy', 'EEGMouse_Nathan_1_44_1131.npy', 'EEGMouse_Nathan_1_4_369.npy', 'EEGMouse_Nathan_1_38_1047.npy', 'EEGMouse_Nathan_3_33_942.npy', 'EEGMouse_Nathan_1_33_945.npy', 'EEGMouse_Nathan_1_21_711.npy', 'EEGMouse_Nathan_3_14_579.npy', 'EEGMouse_Nathan_1_27_825.npy', 'EEGMouse_Nathan_3_31_908.npy', 'EEGMouse_Nathan_1_5_391.npy', 'EEGMouse_Nathan_3_22_714.npy', 'EEGMouse_Nathan_1_54_1330.npy', 'EEGMouse_Nathan_1_44_1133.npy', 'EEGMouse_Nathan_1_3_344.npy', 'EEGMouse_Nathan_3_20_631.npy', 'EEGMouse_Nathan_1_19_689.npy', 'EEGMouse_Nathan_3_21_698.npy', 'EEGMouse_Nathan_1_40_1066.npy', 'EEGMouse_Nathan_1_54_1322.npy', 'EEGMouse_Nathan_1_26_795.npy', 'EEGMouse_Nathan_3_28_838.npy', 'EEGMouse_Nathan_1_36_1007.npy', 'EEGMouse_Nathan_1_46_1148.npy', 'EEGMouse_Nathan_1_45_1147.npy', 'EEGMouse_Nathan_3_26_802.npy', 'EEGMouse_Nathan_1_28_839.npy', 'EEGMouse_Nathan_1_57_1394.npy', 'EEGMouse_Nathan_3_42_1102.npy', 'EEGMouse_Nathan_1_34_953.npy', 'EEGMouse_Nathan_3_33_936.npy', 'EEGMouse_Nathan_1_46_1158.npy', 'EEGMouse_Nathan_1_28_849.npy', 'EEGMouse_Nathan_3_55_1359.npy', 'EEGMouse_Nathan_1_2_324.npy', 'EEGMouse_Nathan_1_40_1074.npy', 'EEGMouse_Nathan_3_45_1144.npy', 'EEGMouse_Nathan_1_33_943.npy', 'EEGMouse_Nathan_1_11_512.npy', 'EEGMouse_Nathan_3_30_882.npy', 'EEGMouse_Nathan_1_3_362.npy', 'EEGMouse_Nathan_1_19_673.npy', 'EEGMouse_Nathan_1_53_1308.npy', 'EEGMouse_Nathan_1_28_845.npy', 'EEGMouse_Nathan_1_50_1248.npy', 'EEGMouse_Nathan_3_24_764.npy', 'EEGMouse_Nathan_1_57_1380.npy', 'EEGMouse_Nathan_3_1_329.npy', 'EEGMouse_Nathan_3_43_1112.npy', 'EEGMouse_Nathan_3_15_607.npy', 'EEGMouse_Nathan_1_49_1228.npy', 'EEGMouse_Nathan_3_1_324.npy', 'EEGMouse_Nathan_3_40_1065.npy', 'EEGMouse_Nathan_1_54_1320.npy', 'EEGMouse_Nathan_1_5_387.npy', 'EEGMouse_Nathan_3_30_888.npy', 'EEGMouse_Nathan_3_20_445.npy', 'EEGMouse_Nathan_3_32_932.npy', 'EEGMouse_Nathan_3_35_978.npy', 'EEGMouse_Nathan_1_31_911.npy', 'EEGMouse_Nathan_3_36_1008.npy', 'EEGMouse_Nathan_3_31_904.npy', 'EEGMouse_Nathan_3_9_480.npy', 'EEGMouse_Nathan_1_38_1051.npy', 'EEGMouse_Nathan_3_23_742.npy', 'EEGMouse_Nathan_1_21_693.npy', 'EEGMouse_Nathan_1_53_1318.npy', 'EEGMouse_Nathan_3_19_676.npy', 'EEGMouse_Nathan_1_10_489.npy', 'EEGMouse_Nathan_3_28_844.npy', 'EEGMouse_Nathan_3_40_1069.npy', 'EEGMouse_Nathan_1_47_1181.npy', 'EEGMouse_Nathan_1_35_981.npy', 'EEGMouse_Nathan_1_20_425.npy', 'EEGMouse_Nathan_3_13_565.npy', 'EEGMouse_Nathan_1_10_504.npy', 'EEGMouse_Nathan_3_26_796.npy', 'EEGMouse_Nathan_3_3_358.npy', 'EEGMouse_Nathan_3_24_756.npy', 'EEGMouse_Nathan_3_23_740.npy', 'EEGMouse_Nathan_1_55_1352.npy', 'EEGMouse_Nathan_3_6_416.npy', 'EEGMouse_Nathan_3_18_670.npy', 'EEGMouse_Nathan_3_36_1002.npy', 'EEGMouse_Nathan_1_54_1326.npy', 'EEGMouse_Nathan_1_44_1139.npy', 'EEGMouse_Nathan_3_11_527.npy', 'EEGMouse_Nathan_1_54_1332.npy', 'EEGMouse_Nathan_1_40_1070.npy', 'EEGMouse_Nathan_3_7_456.npy', 'EEGMouse_Nathan_1_26_803.npy', 'EEGMouse_Nathan_1_15_594.npy', 'EEGMouse_Nathan_3_20_429.npy', 'EEGMouse_Nathan_1_16_620.npy', 'EEGMouse_Nathan_3_53_1313.npy', 'EEGMouse_Nathan_3_56_1375.npy', 'EEGMouse_Nathan_1_42_1099.npy', 'EEGMouse_Nathan_1_34_963.npy', 'EEGMouse_Nathan_3_27_828.npy', 'EEGMouse_Nathan_1_48_1193.npy', 'EEGMouse_Nathan_3_4_365.npy', 'EEGMouse_Nathan_1_11_522.npy', 'EEGMouse_Nathan_1_1_325.npy', 'EEGMouse_Nathan_1_56_1374.npy', 'EEGMouse_Nathan_3_28_850.npy', 'EEGMouse_Nathan_1_38_1033.npy', 'EEGMouse_Nathan_3_42_1096.npy', 'EEGMouse_Nathan_3_20_635.npy', 'EEGMouse_Nathan_3_20_645.npy', 'EEGMouse_Nathan_3_27_822.npy', 'EEGMouse_Nathan_1_20_424.npy', 'EEGMouse_Nathan_3_4_373.npy', 'EEGMouse_Nathan_3_55_1357.npy', 'EEGMouse_Nathan_1_30_883.npy', 'EEGMouse_Nathan_3_47_1178.npy', 'EEGMouse_Nathan_1_20_646.npy', 'EEGMouse_Nathan_1_57_1386.npy', 'EEGMouse_Nathan_1_6_417.npy', 'EEGMouse_Nathan_1_25_791.npy', 'EEGMouse_Nathan_1_2_339.npy', 'EEGMouse_Nathan_1_12_536.npy', 'EEGMouse_Nathan_3_12_531.npy', 'EEGMouse_Nathan_1_14_574.npy', 'EEGMouse_Nathan_3_11_515.npy', 'EEGMouse_Nathan_1_21_699.npy', 'EEGMouse_Nathan_1_30_877.npy', 'EEGMouse_Nathan_3_32_918.npy', 'EEGMouse_Nathan_1_55_1356.npy', 'EEGMouse_Nathan_1_20_628.npy', 'EEGMouse_Nathan_3_46_1167.npy', 'EEGMouse_Nathan_1_20_437.npy', 'EEGMouse_Nathan_1_5_400.npy', 'EEGMouse_Nathan_3_10_503.npy', 'EEGMouse_Nathan_3_30_890.npy', 'EEGMouse_Nathan_3_21_706.npy', 'EEGMouse_Nathan_3_19_688.npy', 'EEGMouse_Nathan_1_19_683.npy', 'EEGMouse_Nathan_3_22_728.npy', 'EEGMouse_Nathan_1_23_749.npy', 'EEGMouse_Nathan_1_3_352.npy', 'EEGMouse_Nathan_3_43_1120.npy', 'EEGMouse_Nathan_3_26_812.npy', 'EEGMouse_Nathan_3_44_1138.npy', 'EEGMouse_Nathan_3_51_1267.npy', 'EEGMouse_Nathan_1_11_524.npy', 'EEGMouse_Nathan_1_54_1328.npy', 'EEGMouse_Nathan_3_49_1233.npy', 'EEGMouse_Nathan_1_49_1234.npy', 'EEGMouse_Nathan_1_34_959.npy', 'EEGMouse_Nathan_1_53_1306.npy', 'EEGMouse_Nathan_3_50_1251.npy', 'EEGMouse_Nathan_1_19_679.npy', 'EEGMouse_Nathan_3_12_535.npy', 'EEGMouse_Nathan_1_6_414.npy', 'EEGMouse_Nathan_3_50_1255.npy', 'EEGMouse_Nathan_1_23_745.npy', 'EEGMouse_Nathan_3_2_337.npy', 'EEGMouse_Nathan_3_29_866.npy', 'EEGMouse_Nathan_1_32_919.npy', 'EEGMouse_Nathan_1_51_1274.npy', 'EEGMouse_Nathan_1_5_401.npy', 'EEGMouse_Nathan_3_1_341.npy', 'EEGMouse_Nathan_1_35_991.npy', 'EEGMouse_Nathan_1_23_735.npy', 'EEGMouse_Nathan_3_47_1186.npy', 'EEGMouse_Nathan_1_33_947.npy', 'EEGMouse_Nathan_3_5_395.npy', 'EEGMouse_Nathan_3_11_525.npy', 'EEGMouse_Nathan_3_42_1092.npy', 'EEGMouse_Nathan_1_24_765.npy', 'EEGMouse_Nathan_3_31_910.npy', 'EEGMouse_Nathan_3_9_481.npy', 'EEGMouse_Nathan_1_16_614.npy', 'EEGMouse_Nathan_3_35_980.npy', 'EEGMouse_Nathan_1_57_1390.npy', 'EEGMouse_Nathan_1_22_731.npy', 'EEGMouse_Nathan_1_20_640.npy', 'EEGMouse_Nathan_3_24_760.npy', 'EEGMouse_Nathan_1_1_327.npy', 'EEGMouse_Nathan_1_25_781.npy', 'EEGMouse_Nathan_3_35_974.npy', 'EEGMouse_Nathan_3_33_938.npy', 'EEGMouse_Nathan_3_3_345.npy', 'EEGMouse_Nathan_1_10_488.npy', 'EEGMouse_Nathan_1_16_612.npy', 'EEGMouse_Nathan_3_11_513.npy', 'EEGMouse_Nathan_1_40_1078.npy', 'EEGMouse_Nathan_1_42_1093.npy', 'EEGMouse_Nathan_1_47_1172.npy', 'EEGMouse_Nathan_1_43_1109.npy', 'EEGMouse_Nathan_1_31_903.npy', 'EEGMouse_Nathan_1_14_572.npy', 'EEGMouse_Nathan_1_38_1041.npy', 'EEGMouse_Nathan_1_1_332.npy', 'EEGMouse_Nathan_1_29_861.npy', 'EEGMouse_Nathan_1_32_925.npy', 'EEGMouse_Nathan_3_51_1277.npy', 'EEGMouse_Nathan_3_25_782.npy', 'EEGMouse_Nathan_3_52_1287.npy', 'EEGMouse_Nathan_3_10_491.npy', 'EEGMouse_Nathan_3_47_1188.npy', 'EEGMouse_Nathan_1_7_461.npy', 'EEGMouse_Nathan_3_43_1110.npy', 'EEGMouse_Nathan_3_23_752.npy', 'EEGMouse_Nathan_3_49_1227.npy', 'EEGMouse_Nathan_1_13_556.npy', 'EEGMouse_Nathan_1_24_757.npy', 'EEGMouse_Nathan_3_13_569.npy', 'EEGMouse_Nathan_3_57_1395.npy', 'EEGMouse_Nathan_1_11_526.npy', 'EEGMouse_Nathan_3_9_477.npy', 'EEGMouse_Nathan_1_29_865.npy', 'EEGMouse_Nathan_1_35_973.npy', 'EEGMouse_Nathan_3_52_1291.npy', 'EEGMouse_Nathan_3_21_700.npy', 'EEGMouse_Nathan_3_53_1305.npy', 'EEGMouse_Nathan_3_35_984.npy', 'EEGMouse_Nathan_1_48_1195.npy', 'EEGMouse_Nathan_3_56_1367.npy', 'EEGMouse_Nathan_3_46_1155.npy', 'EEGMouse_Nathan_3_47_1171.npy', 'EEGMouse_Nathan_1_20_428.npy', 'EEGMouse_Nathan_3_7_448.npy', 'EEGMouse_Nathan_3_54_1323.npy', 'EEGMouse_Nathan_1_22_717.npy', 'EEGMouse_Nathan_3_13_553.npy']\n",
            "Sorted sessions: [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57]\n",
            "[9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57]\n",
            "[17, 48, 46, 53, 22, 10] [45, 54, 42, 18, 19, 21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3bad1c063c7e>:92: RuntimeWarning: invalid value encountered in divide\n",
            "  normed_sig = (filtered_sig - np.mean(filtered_sig, 1, keepdims=True)) / np.std(filtered_sig, 1, keepdims=True) # standard scaling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EEGMouse_Nathan_1_51_1262.npy\n",
            "EEGMouse_Nathan_1_50_1240.npy\n",
            "EEGMouse_Nathan_1_47_1173.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b, l = next(iter(train_dl))"
      ],
      "metadata": {
        "id": "-RP3A5bsYfhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the model code, which you have already gone through"
      ],
      "metadata": {
        "id": "wMVYnxjlrZ1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class Squash(nn.Module):\n",
        "    def __init__(self, eps=1e-20):\n",
        "        super(Squash, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        norm = torch.linalg.norm(x, ord=2, dim=-1, keepdim=True)\n",
        "        coef = 1 - 1 / (torch.exp(norm) + self.eps)\n",
        "        unit = x / (norm + self.eps)\n",
        "        return coef * unit\n",
        "\n",
        "class Routing(nn.Module):\n",
        "    def __init__(self, groups, in_dims, out_dims):\n",
        "        super(Routing, self).__init__()\n",
        "        N0, D0 = in_dims\n",
        "        N1, self.D1 = out_dims\n",
        "        self.W = nn.Parameter(torch.Tensor(groups, N1, N0, D0, self.D1))\n",
        "        nn.init.kaiming_normal_(self.W)\n",
        "        self.b = nn.Parameter(torch.zeros(groups, N1, N0, 1))\n",
        "        self.squash = Squash()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        u = torch.einsum('...gni,gknid->...gknd', x, self.W) # shape: (B, G, N1, N0, D1)\n",
        "\n",
        "        c = torch.einsum(\"...ij,...kj->...i\", u, u) # shape: (B, N1, N0)\n",
        "\n",
        "        c = c[..., None]  # (B, N1, N0, 1) for bias broadcasting\n",
        "        c = c / torch.sqrt(torch.tensor(self.D1).float())  # stabilize\n",
        "        c = torch.softmax(c, axis=1) + self.b\n",
        "\n",
        "        ## new capsules\n",
        "        s = torch.sum(u * c, dim=-2)\n",
        "\n",
        "        return self.squash(s)\n",
        "\n",
        "\n",
        "class ReconstructionNet(nn.Module):\n",
        "    def __init__(self, input_size=(1, 28, 28), num_classes=2, num_capsules=64):\n",
        "        super(ReconstructionNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.fc1 = nn.Linear(in_features=num_capsules * num_classes, out_features=512)\n",
        "        self.fc2 = nn.Linear(512, 1024)\n",
        "        self.fc3 = nn.Linear(1024, np.prod(input_size) * 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        gain = nn.init.calculate_gain('relu')\n",
        "        nn.init.xavier_normal_(self.fc1.weight, gain=gain)\n",
        "        nn.init.xavier_normal_(self.fc2.weight, gain=gain)\n",
        "        nn.init.xavier_normal_(self.fc3.weight, gain=gain)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = x.view(x.size(0), 2, *self.input_size).squeeze(1)\n",
        "        complex_x = torch.complex(x[:, 0], x[:, 1]) # create complex tensor to reflext fourier transform\n",
        "        return complex_x\n",
        "\n",
        "\n",
        "class CapsMask(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CapsMask, self).__init__()\n",
        "\n",
        "    def forward(self, x, y_true=None):\n",
        "        if y_true is not None:  # training mode\n",
        "            mask = y_true\n",
        "        else:  # testing mode\n",
        "            # convert list of maximum value's indices to one-hot tensor\n",
        "            temp = torch.sqrt(torch.sum(x**2, dim=-1))\n",
        "            mask = F.one_hot(torch.argmax(temp, dim=1), num_classes=temp.shape[1])\n",
        "\n",
        "        masked = x * mask.unsqueeze(-1)\n",
        "\n",
        "        return masked.view(x.shape[0], -1)  # reshape\n",
        "\n",
        "\n",
        "class CapsLen(nn.Module):\n",
        "    def __init__(self, eps=1e-7):\n",
        "        super(CapsLen, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sqrt(\n",
        "            torch.sum(x**2, dim=-1) + self.eps\n",
        "        )  # (batch_size, num_capsules)\n"
      ],
      "metadata": {
        "id": "NxbrV4uswE3p"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class EEGCapsNet(nn.Module):\n",
        "    def __init__(self, input_size=(1, 16, 192), num_classes=2):\n",
        "        super(EEGCapsNet, self).__init__()\n",
        "        self.channelCapsTemporal_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=128, kernel_size=(1,64), groups=16, padding=0),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(1,input_size[2]-63), groups=128), # collapse to 1 point\n",
        "            #nn.Dropout(p=0.3)\n",
        "        )\n",
        "        self.channelCapsTemporal_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=128, kernel_size=(1, 24), groups=16, padding=0),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(1,input_size[2]-23), groups=128), # collapse to 1 point\n",
        "            #nn.Dropout(p=0.3)\n",
        "        )\n",
        "        # channel caps will eventually be transformed from 8x4 capsules to 4x8 higher level capsules\n",
        "\n",
        "        self.channelRouting = Routing(16, (8, 4), (4, 8))\n",
        "        self.channelShrink = Routing(8, (8, 8), (4, 8))\n",
        "        self.channelDeepSuper = Routing(1, (64, 8), (2, 32))\n",
        "        self.channel_align = Routing(16, (4, 8), (1, 8))\n",
        "\n",
        "        self.localCapsSpatial_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=64, kernel_size=(2, 36), groups=8, padding=0),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1, input_size[2]-35), groups=64), # collapse to 1 point\n",
        "            #nn.Dropout(p=0.3)\n",
        "        )\n",
        "\n",
        "        self.localCapsSpatial_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=64, kernel_size=(2, 16), groups=8),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1, input_size[2]-15), groups=64), # collapse to 1 point\n",
        "            nn.Dropout(p=0.3)\n",
        "        )\n",
        "\n",
        "        self.localRouting = Routing(8, (8, 4), (4, 8))\n",
        "        self.localShrink = Routing(8, (8, 8), (4, 16))\n",
        "        self.localRegion = Routing(4, (8, 16), (4, 16))\n",
        "        self.localDeepSuper = Routing(1, (32, 8), (2, 64))\n",
        "        self.local_align = Routing(8, (4, 8), (2, 8))\n",
        "\n",
        "        # local spatial caps will be transformed from 8x4 capsules to 8x8 higher level capsules\n",
        "        # local caps will be 16x8 (with addition from channel caps) this will be reduced to 8x8\n",
        "\n",
        "\n",
        "        self.regionCapsSpatial_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=4, out_channels=32, kernel_size=(4, 24), groups=4),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1, input_size[2]-23), groups=32) # collapse to 1 point\n",
        "        )\n",
        "\n",
        "        self.regionCapsSpatial_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=4, out_channels=32, kernel_size=(4, 32), groups=4),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1, input_size[2]-31), groups=32) # collapse to 1 point\n",
        "        )\n",
        "\n",
        "        # region caps will be transformed from 8x4 capsules to 16x8 higher level capsules\n",
        "        # region caps will be 32x8 (with addition from local caps) this will be reduced to 16x8\n",
        "\n",
        "        self.regionRouting = Routing(4, (8, 4), (4, 16))\n",
        "        self.regionShrink = Routing(4, (8, 16), (4, 16))\n",
        "        self.regionHemi = Routing(2, (8, 16), (4, 16))\n",
        "        self.regionDeepSuper = Routing(1, (16, 16), (2, 64))\n",
        "        self.region_align = Routing(4, (4, 16), (4, 8))\n",
        "\n",
        "        self.hemiCapsSpatial_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=2, out_channels=16, kernel_size=(8, 30), groups=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(1, input_size[2]-29), groups=16) # collapse to 1 point\n",
        "        )\n",
        "\n",
        "        self.hemiCapsSpatial_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=2, out_channels=16, kernel_size=(8, 60), groups=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(1, input_size[2]-59), groups=16) # collapse to 1 point\n",
        "        )\n",
        "\n",
        "        # hemi caps will be transformed from 8x4 capsules to 32x8 higher level capsules\n",
        "        # hemi caps will be 64x8 (with addition from region caps) this will be reduced to 32x8\n",
        "\n",
        "        self.hemiRouting = Routing(2, (8, 4), (4, 16))\n",
        "        self.hemiShrink = Routing(2, (8, 16), (4, 16))\n",
        "        self.hemi_align = Routing(2, (4, 16), (8, 8))\n",
        "\n",
        "        self.out = Routing(1, (64, 8), (num_classes, 64)) #changed from (1, (8, 16), (num_classes, 64))\n",
        "        self.generator = ReconstructionNet(input_size, num_classes)\n",
        "        self.channel_generator = ReconstructionNet(input_size, num_classes, num_capsules=32)\n",
        "        self.local_generator = ReconstructionNet(input_size, num_classes, num_capsules=64)\n",
        "        self.region_generator = ReconstructionNet(input_size, num_classes, num_capsules=64)\n",
        "        self.mask = CapsMask()\n",
        "        self.capsLen = CapsLen()\n",
        "\n",
        "\n",
        "    def forward(self, x, y_true=None, mode='train'):\n",
        "        x = x.permute(0, 2, 1, 3)\n",
        "        data = x\n",
        "        x1 = self.channelCapsTemporal_1(data).view(data.size(0), 16, 16)\n",
        "        x2 = self.channelCapsTemporal_2(data).view(data.size(0), 16, 16)\n",
        "        channels = torch.cat((x1, x2), dim=2).view(data.size(0), 16, 8, 4)\n",
        "        channels = self.channelRouting(channels) #shape (16, 4, 8)\n",
        "        channelsAlign = self.channel_align(channels).view(data.size(0), 1, 16, 8)\n",
        "        deep_channels = self.channelDeepSuper(channels.view(data.size(0), 1, 64, 8))\n",
        "        #new_locals = self.channelShrink(channels.view(data.size(0), 8, 8, 8))\n",
        "\n",
        "        x1 = self.localCapsSpatial_1(data.view(data.size(0), 8, 2, 192)).view(data.size(0), 8, 16)\n",
        "        x2 = self.localCapsSpatial_2(data.view(data.size(0), 8, 2, 192)).view(data.size(0), 8, 16)\n",
        "        local = torch.cat((x1, x2), dim=2).view(data.size(0), 8, 8, 4)\n",
        "        local = self.localRouting(local) #shape (8, 4, 8)\n",
        "        localsAlign = self.local_align(local).view(data.size(0), 1, 16, 8)\n",
        "        deep_locals = self.localDeepSuper(local.view(data.size(0), 1, 32, 8))\n",
        "\n",
        "        #local = torch.cat((local, new_locals), dim=2)\n",
        "        #local = self.localShrink(local)\n",
        "        #new_regions = self.localRegion(local.view(data.size(0), 4, 8, 16))\n",
        "\n",
        "        x1 = self.regionCapsSpatial_1(data.view(data.size(0), 4, 4, 192)).view(data.size(0), 4, 16)\n",
        "        x2 = self.regionCapsSpatial_2(data.view(data.size(0), 4, 4, 192)).view(data.size(0), 4, 16)\n",
        "        regions = torch.cat((x1, x2), dim=2).view(data.size(0), 4, 8, 4)\n",
        "        regions = self.regionRouting(regions) #shape (4, 4, 16)\n",
        "        regionsAlign = self.region_align(regions).view(data.size(0), 1, 16, 8)\n",
        "        deep_regions = self.regionDeepSuper(regions.view(data.size(0), 1, 16, 16))\n",
        "        #regions = torch.cat((regions, new_regions), dim=2)\n",
        "        #regions = self.regionShrink(regions)\n",
        "        #new_hemis = self.regionHemi(regions.view(data.size(0), 2, 8, 16))\n",
        "\n",
        "        x1 = self.hemiCapsSpatial_1(data.view(data.size(0), 2, 8, 192)).view(data.size(0), 2, 16)\n",
        "        x2 = self.hemiCapsSpatial_2(data.view(data.size(0), 2, 8, 192)).view(data.size(0), 2, 16)\n",
        "        hemis = torch.cat((x1, x2), dim=2).view(data.size(0), 2, 8, 4)\n",
        "        hemis = self.hemiRouting(hemis) #shape (2, 4, 16)\n",
        "        hemisAlign = self.hemi_align(hemis).view(data.size(0), 1, 16, 8)\n",
        "        #hemisDeep = self.hemiDeepSuper(hemis.view(data.size(0), 1, 64, 8))\n",
        "        #hemis = torch.cat((hemis, new_hemis), dim=2)\n",
        "        #hemis = self.hemiShrink(hemis).view(data.size(0), 1, 8, 16)\n",
        "\n",
        "        #First trying with only one layer between convolution and output\n",
        "        #Essentially no layer combining and of the separate CNN information\n",
        "\n",
        "        concatenated = torch.cat((channelsAlign, localsAlign, regionsAlign, hemisAlign), dim=2)\n",
        "        out = self.out(concatenated)\n",
        "\n",
        "\n",
        "        #out = self.out(hemis)\n",
        "        out = out.squeeze(1)\n",
        "\n",
        "        pred = self.capsLen(out)\n",
        "\n",
        "        if mode == \"train\":\n",
        "            masked = self.mask(out, y_true)\n",
        "            deep_channels = deep_channels.squeeze(1)\n",
        "            deep_locals = deep_locals.squeeze(1)         #removing these to also remove residuals\n",
        "            deep_regions = deep_regions.squeeze(1)\n",
        "            masked_channels = self.mask(deep_channels, y_true)\n",
        "            masked_locals = self.mask(deep_locals, y_true)\n",
        "            masked_regions = self.mask(deep_regions, y_true)\n",
        "        elif mode == \"eval\":\n",
        "            masked = self.mask(out)\n",
        "            x = self.generator(masked)\n",
        "            return pred, x\n",
        "        elif mode == \"test\":\n",
        "            return pred\n",
        "        x = self.generator(masked)\n",
        "        x_channels = self.channel_generator(masked_channels)\n",
        "        x_locals = self.local_generator(masked_locals)\n",
        "        x_regions = self.region_generator(masked_regions)\n",
        "        pred_channels = self.capsLen(deep_channels)\n",
        "        pred_locals = self.capsLen(deep_locals)\n",
        "        pred_regions = self.capsLen(deep_regions)\n",
        "\n",
        "\n",
        "        return pred, x, pred_regions, x_regions, pred_locals, x_locals, pred_channels, x_channels"
      ],
      "metadata": {
        "id": "9vN7yOhxwG4h"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "Xsd1uawprnQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the custom loss function for training the model"
      ],
      "metadata": {
        "id": "-g1x5OUyrvgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class MarginLoss(nn.Module):\n",
        "    def __init__(self, m_pos=0.9, m_neg=0.1, lambda_=0.5):\n",
        "        super(MarginLoss, self).__init__()\n",
        "        self.m_pos = m_pos\n",
        "        self.m_neg = m_neg\n",
        "        self.lambda_ = lambda_\n",
        "\n",
        "    def forward(self, targets, digit_probs):\n",
        "        assert targets.shape is not digit_probs.shape\n",
        "        present_losses = (\n",
        "            targets * torch.clamp_min(self.m_pos - digit_probs, min=0.0) ** 2\n",
        "        )\n",
        "        absent_losses = (1 - targets) * torch.clamp_min(\n",
        "            digit_probs - self.m_neg, min=0.0\n",
        "        ) ** 2\n",
        "        losses = present_losses + self.lambda_ * absent_losses\n",
        "        return torch.mean(torch.sum(losses, dim=1))\n",
        "\n",
        "\n",
        "class ReconstructionLoss(nn.Module):\n",
        "    def forward(self, reconstructions, input_images):\n",
        "        if reconstructions[0].dtype not in [torch.float32, torch.float64]:\n",
        "            magnitude_recon = torch.abs(reconstructions)\n",
        "            magnitude_input = torch.abs(input_images)\n",
        "            phase_recon = torch.angle(reconstructions)\n",
        "            phase_input = torch.angle(input_images)\n",
        "            return torch.nn.MSELoss(reduction=\"mean\")(magnitude_recon, magnitude_input) + torch.nn.MSELoss(reduction=\"mean\")(phase_recon, phase_input)\n",
        "        return torch.nn.MSELoss(reduction=\"mean\")(reconstructions, input_images)\n",
        "\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "    def __init__(self, m_pos=0.9, m_neg=0.1, lambda_=0.5, recon_factor=0.0005):\n",
        "        super(TotalLoss, self).__init__()\n",
        "        self.margin_loss = MarginLoss(m_pos, m_neg, lambda_)\n",
        "        self.recon_loss = ReconstructionLoss()\n",
        "        self.recon_factor = recon_factor\n",
        "\n",
        "    def forward(self, input_images, targets, reconstructions, digit_probs):\n",
        "        margin = self.margin_loss(targets.squeeze(), digit_probs)\n",
        "        recon = self.recon_loss(reconstructions, input_images)\n",
        "        return margin + self.recon_factor * recon\n"
      ],
      "metadata": {
        "id": "-4DyDd2uwJLJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this training loop. It may take a while even with the T4 Runtime!"
      ],
      "metadata": {
        "id": "dEkByUHhrz_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade sympy"
      ],
      "metadata": {
        "id": "7R1beAnw1xPs",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258aacbb-ac1c-4cfe-ca94-3833859a4680"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy) (1.3.0)\n",
            "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds[0][0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38-T9NM-AP97",
        "outputId": "9dd29939-c61c-4254-c60e-f112d9080a38"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 250])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "deep_super_weights = [1/(1.5**i) for i in range(4)]\n",
        "deep_super_weights = deep_super_weights / np.sum(deep_super_weights)\n",
        "model = EEGCapsNet().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)\n",
        "criterion = TotalLoss()\n",
        "num_epochs = 10\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "accs = []\n",
        "max_acc = 0\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    pbar_batch = tqdm(range(len(train_dl)))\n",
        "    total_loss = 0\n",
        "    for batch, (data, labels) in enumerate(train_dl):\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        x_fft = torch.fft.fft(data, dim=-1).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        data = data.unsqueeze(1).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outs = model(data)\n",
        "        full_loss = 0\n",
        "        for k in range(0, 8, 2):\n",
        "            loss = criterion(x_fft, labels, outs[k+1], outs[k])\n",
        "            loss *= deep_super_weights[k // 2]\n",
        "            full_loss += loss\n",
        "        full_loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm = 5)\n",
        "        optimizer.step()\n",
        "        total_loss += full_loss.item()\n",
        "        predicted = torch.argmax(outs[0], -1)\n",
        "        labels = torch.argmax(labels, -1)\n",
        "        correct_train += (predicted == labels).float().sum().item()\n",
        "        total_train += labels.shape[0]\n",
        "        pbar_batch.set_description(f\"Batch {batch + 1}    loss={total_loss / (batch + 1):0.4f}      accuracy={correct_train/total_train:04f}\")\n",
        "        pbar_batch.update(1)\n",
        "    pbar_batch.close()\n",
        "    train_losses.append(total_loss / len(train_dl))\n",
        "    total_val_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "    # set model to evaluation mode, which changes the behavior\n",
        "    # of some layers like dropout and batch normalization\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(total=len(valid_dl))\n",
        "        for j, (x, y) in enumerate(valid_dl):\n",
        "            x = x.float().cuda()\n",
        "            y = y.cuda()\n",
        "            x = x.unsqueeze(1)\n",
        "            outs = model(x, mode='eval')\n",
        "            pred = outs[0]\n",
        "            img = outs[1]\n",
        "            y = y.squeeze(1)\n",
        "            x_fft = torch.fft.fft(x, dim=-1)\n",
        "            loss = criterion(x_fft, y, img, pred)\n",
        "            total_val_loss += loss.item()\n",
        "            predicted = torch.argmax(pred, -1)\n",
        "            labels = torch.argmax(y, -1)\n",
        "            accuracy = (predicted == labels).float().mean().item()\n",
        "            total_accuracy += accuracy\n",
        "            pbar.set_description(f\"val loss={total_val_loss / (j + 1):0.4f}    val acc={total_accuracy / (j + 1):0.4f}\")\n",
        "            pbar.update(1)\n",
        "        pbar.close()\n",
        "        val_losses.append(total_val_loss/len(valid_dl))\n",
        "        accs.append(total_accuracy/len(valid_dl))\n",
        "    # save model if accuracy is best seen\n",
        "    if accs[-1] > max_acc:\n",
        "      # dictionary with model state dict, optimizer state dict, and best accuracy\n",
        "      checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(), 'best_acc': accs[-1]}\n",
        "      # save dictionary to specified file path if it exists or create new one otherwise\n",
        "      torch.save(checkpoint, 'SepConv2.pth.tar')\n",
        "      print('Model Saved')\n",
        "      max_acc = accs[-1]\n",
        "#pbar_epoch.close()"
      ],
      "metadata": {
        "id": "uq7xQhe6wLgo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "ae8ad2ee-f34b-4090-e030-872827c3834e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'TensorDataset' object has no attribute 'size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-2449b4658ecb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TensorDataset' object has no attribute 'size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure()\n",
        "plt.plot(train_losses, label = 'train loss')\n",
        "plt.plot(val_losses, label = 'val loss')\n",
        "plt.legend()\n",
        "plt.ylabel('Categorical Crossentropy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Loss over Epochs')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(accs)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')"
      ],
      "metadata": {
        "id": "iAyOwmMOVXkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretability\n"
      ],
      "metadata": {
        "id": "Tf1exY3cehoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captum\n",
        "from captum.attr import LayerGradCam, LayerAttribution\n",
        "\n",
        "def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True, axis_title=\"Features\"):\n",
        "    print(title)\n",
        "    for i in range(len(feature_names)):\n",
        "        print(feature_names[i], \": \", '%.3f'%(importances[i]))\n",
        "    x_pos = (np.arange(len(feature_names)))\n",
        "    if plot:\n",
        "        plt.figure(figsize=(12,6))\n",
        "        plt.bar(x_pos, importances, align='center')\n",
        "        plt.xticks(x_pos, feature_names, wrap=True)\n",
        "        plt.xlabel(axis_title)\n",
        "        plt.title(title)\n",
        "conductance = LayerConductance(model, model.out)\n",
        "#test_input_tensor = torch.from_numpy(test_features).type(torch.FloatTensor)\n",
        "#conductance_vals = conductance.attribute(data.to(device), target=1).detach().numpy()\n",
        "#visualize_importances(range(12),np.mean(cond_vals, axis=0),title=\"Average Neuron Importances\", axis_title=\"Neurons\")\n",
        "\n",
        "\n",
        "# Assuming 'data' is your EEG input tensor\n",
        "layer_gradcam = LayerGradCam(model, model.out)\n",
        "\n",
        "attr = layer_gradcam.attribute(data.to(device), target=1, additional_forward_args=(labels.to(device), 'test'))\n",
        "attr = attr.squeeze()"
      ],
      "metadata": {
        "id": "BJt39GBfehUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'attr' contains the attributions and has shape (channels, time)\n",
        "attr_abs = torch.abs(attr) # taking the absolute values\n",
        "attr_mean = torch.mean(attr_abs, dim=1) #Averaging over the channels to represent the attributions as a single scalar value per input data point.\n",
        "# assuming attr_mean has shape (batch_size, height, width)\n",
        "plt.plot(attr_mean.cpu().detach().numpy())\n",
        "plt.xlabel('Data Point Index')\n",
        "plt.ylabel('Attribution')\n",
        "plt.title('LayerGradCAM Attributions')\n",
        "\n",
        "\n",
        "#INPROGRESS: get the color key to work\n",
        "# Get the colormap\n",
        "cmap = plt.cm.get_cmap('viridis')\n",
        "\n",
        "# Define the number of color patches in the key\n",
        "num_patches = 5\n",
        "\n",
        "# Generate color patches and value ranges\n",
        "values = np.linspace(attr_mean.min().item(), attr_mean.max().item(), num_patches)\n",
        "colors = cmap(np.linspace(0, 1, num_patches))\n",
        "\n",
        "# Create a custom legend with color patches and labels\n",
        "patches = [\n",
        "    plt.Rectangle((0, 0), 1, 1, color=colors[i], label=f'{values[i]:.2f} - {values[i+1]:.2f}' if i < num_patches - 1 else f'{values[i]:.2f}+')\n",
        "    for i in range(num_patches)\n",
        "]\n",
        "\n",
        "plt.legend(handles=patches, loc='best', title='Attribution Values')\n",
        "\n",
        "plt.show()\n",
        "# for i in range(attr_mean.shape[0]):\n",
        "#     plt.figure()\n",
        "#     plt.imshow(attr_mean[i].cpu().detach().numpy(), cmap='viridis', aspect='auto', interpolation='nearest')\n",
        "#     plt.colorbar(label='Attribution')\n",
        "#     plt.xlabel('Time')\n",
        "#     plt.ylabel('Channels')\n",
        "#     plt.title(f'LayerGradCAM Attributions for Sample {i}')\n",
        "#     plt.show()\n"
      ],
      "metadata": {
        "id": "Dtgqo1cLvqtT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}